{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aMS1</th>\n",
       "      <th>aMS2</th>\n",
       "      <th>aMS3</th>\n",
       "      <th>aMS4</th>\n",
       "      <th>aMS5</th>\n",
       "      <th>sMS1</th>\n",
       "      <th>sMS2</th>\n",
       "      <th>sMS4</th>\n",
       "      <th>sMS5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.64</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.92</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.81</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.04</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aMS1  aMS2  aMS3  aMS4  aMS5  sMS1  sMS2  sMS4  sMS5\n",
       "0  1.64  1.94  1.61  2.33  1.49  2.26  1.48  1.84  1.88\n",
       "1  1.92  2.14  2.00  1.84  1.88  1.72  2.08  1.78  1.92\n",
       "2  1.81  1.97  2.17  1.76  1.73  1.77  1.93  1.67  1.81\n",
       "3  2.00  1.92  2.17  2.12  2.15  1.88  2.09  2.47  1.96\n",
       "4  2.04  1.87  2.17  2.12  2.33  1.88  1.96  2.47  2.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "df1 = pd.read_excel(\n",
    "    \"/home/gddaslab/mxp140/sclerosis_project/miRNA_signal_hsa_number2.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    sheet_name=\"Sheet1\",\n",
    ")\n",
    "\n",
    "# Drop non-feature columns\n",
    "ams_cols = np.array(list(df1.columns), dtype=object)[\n",
    "    [\"aMS\" in elem for elem in list(df1.columns)]\n",
    "]\n",
    "sms_cols = np.array(list(df1.columns), dtype=object)[\n",
    "    [\"sMS\" in elem for elem in list(df1.columns)]\n",
    "]\n",
    "df = df1[list(ams_cols) + list(sms_cols)]\n",
    "display(df.head(5))\n",
    "\n",
    "# Label the columns based on their types\n",
    "labels = {\"aMS\": 0, \"sMS\": 1}\n",
    "\n",
    "# Create target labels for each column\n",
    "y = []\n",
    "for col in df.columns:\n",
    "    for key in labels.keys():\n",
    "        if col.startswith(key):\n",
    "            y.append(labels[key])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to tensor\n",
    "X = df.T.values\n",
    "y = y\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class ElasticNetLoss(nn.Module):\n",
    "    def __init__(self, model, alpha=1.0, l1_ratio=0.5):\n",
    "        super(ElasticNetLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        ce_loss = self.cross_entropy_loss(outputs, targets)\n",
    "        l1_norm = sum(param.abs().sum() for param in self.model.parameters())\n",
    "        l2_norm = sum(param.pow(2).sum() for param in self.model.parameters())\n",
    "        elastic_net_penalty = self.alpha * (\n",
    "            self.l1_ratio * l1_norm + (1 - self.l1_ratio) * l2_norm\n",
    "        )\n",
    "        return ce_loss + elastic_net_penalty\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(torch.unique(y_train_tensor))\n",
    "model = SoftmaxRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftmaxRegression(\n",
       "  (linear): Linear(in_features=4570, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = ElasticNetLoss(model, alpha=0.01, l1_ratio=0.5)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10000], Loss: 0.0389\n",
      "Epoch [20/10000], Loss: 0.0389\n",
      "Epoch [30/10000], Loss: 0.0389\n",
      "Epoch [40/10000], Loss: 0.0389\n",
      "Epoch [50/10000], Loss: 0.0389\n",
      "Epoch [60/10000], Loss: 0.0389\n",
      "Epoch [70/10000], Loss: 0.0389\n",
      "Epoch [80/10000], Loss: 0.0389\n",
      "Epoch [90/10000], Loss: 0.0388\n",
      "Epoch [100/10000], Loss: 0.0389\n",
      "Epoch [110/10000], Loss: 0.0389\n",
      "Epoch [120/10000], Loss: 0.0389\n",
      "Epoch [130/10000], Loss: 0.0389\n",
      "Epoch [140/10000], Loss: 0.0388\n",
      "Epoch [150/10000], Loss: 0.0389\n",
      "Epoch [160/10000], Loss: 0.0389\n",
      "Epoch [170/10000], Loss: 0.0388\n",
      "Epoch [180/10000], Loss: 0.0389\n",
      "Epoch [190/10000], Loss: 0.0388\n",
      "Epoch [200/10000], Loss: 0.0388\n",
      "Epoch [210/10000], Loss: 0.0388\n",
      "Epoch [220/10000], Loss: 0.0388\n",
      "Epoch [230/10000], Loss: 0.0388\n",
      "Epoch [240/10000], Loss: 0.0388\n",
      "Epoch [250/10000], Loss: 0.0388\n",
      "Epoch [260/10000], Loss: 0.0388\n",
      "Epoch [270/10000], Loss: 0.0388\n",
      "Epoch [280/10000], Loss: 0.0388\n",
      "Epoch [290/10000], Loss: 0.0388\n",
      "Epoch [300/10000], Loss: 0.0388\n",
      "Epoch [310/10000], Loss: 0.0388\n",
      "Epoch [320/10000], Loss: 0.0388\n",
      "Epoch [330/10000], Loss: 0.0388\n",
      "Epoch [340/10000], Loss: 0.0388\n",
      "Epoch [350/10000], Loss: 0.0388\n",
      "Epoch [360/10000], Loss: 0.0388\n",
      "Epoch [370/10000], Loss: 0.0388\n",
      "Epoch [380/10000], Loss: 0.0388\n",
      "Epoch [390/10000], Loss: 0.0388\n",
      "Epoch [400/10000], Loss: 0.0388\n",
      "Epoch [410/10000], Loss: 0.0388\n",
      "Epoch [420/10000], Loss: 0.0388\n",
      "Epoch [430/10000], Loss: 0.0388\n",
      "Epoch [440/10000], Loss: 0.0388\n",
      "Epoch [450/10000], Loss: 0.0388\n",
      "Epoch [460/10000], Loss: 0.0388\n",
      "Epoch [470/10000], Loss: 0.0388\n",
      "Epoch [480/10000], Loss: 0.0388\n",
      "Epoch [490/10000], Loss: 0.0388\n",
      "Epoch [500/10000], Loss: 0.0388\n",
      "Epoch [510/10000], Loss: 0.0388\n",
      "Epoch [520/10000], Loss: 0.0388\n",
      "Epoch [530/10000], Loss: 0.0388\n",
      "Epoch [540/10000], Loss: 0.0388\n",
      "Epoch [550/10000], Loss: 0.0388\n",
      "Epoch [560/10000], Loss: 0.0388\n",
      "Epoch [570/10000], Loss: 0.0388\n",
      "Epoch [580/10000], Loss: 0.0388\n",
      "Epoch [590/10000], Loss: 0.0388\n",
      "Epoch [600/10000], Loss: 0.0388\n",
      "Epoch [610/10000], Loss: 0.0388\n",
      "Epoch [620/10000], Loss: 0.0388\n",
      "Epoch [630/10000], Loss: 0.0388\n",
      "Epoch [640/10000], Loss: 0.0388\n",
      "Epoch [650/10000], Loss: 0.0388\n",
      "Epoch [660/10000], Loss: 0.0388\n",
      "Epoch [670/10000], Loss: 0.0388\n",
      "Epoch [680/10000], Loss: 0.0388\n",
      "Epoch [690/10000], Loss: 0.0388\n",
      "Epoch [700/10000], Loss: 0.0388\n",
      "Epoch [710/10000], Loss: 0.0388\n",
      "Epoch [720/10000], Loss: 0.0388\n",
      "Epoch [730/10000], Loss: 0.0388\n",
      "Epoch [740/10000], Loss: 0.0388\n",
      "Epoch [750/10000], Loss: 0.0388\n",
      "Epoch [760/10000], Loss: 0.0388\n",
      "Epoch [770/10000], Loss: 0.0388\n",
      "Epoch [780/10000], Loss: 0.0388\n",
      "Epoch [790/10000], Loss: 0.0388\n",
      "Epoch [800/10000], Loss: 0.0388\n",
      "Epoch [810/10000], Loss: 0.0388\n",
      "Epoch [820/10000], Loss: 0.0388\n",
      "Epoch [830/10000], Loss: 0.0388\n",
      "Epoch [840/10000], Loss: 0.0388\n",
      "Epoch [850/10000], Loss: 0.0388\n",
      "Epoch [860/10000], Loss: 0.0388\n",
      "Epoch [870/10000], Loss: 0.0388\n",
      "Epoch [880/10000], Loss: 0.0388\n",
      "Epoch [890/10000], Loss: 0.0388\n",
      "Epoch [900/10000], Loss: 0.0388\n",
      "Epoch [910/10000], Loss: 0.0388\n",
      "Epoch [920/10000], Loss: 0.0388\n",
      "Epoch [930/10000], Loss: 0.0388\n",
      "Epoch [940/10000], Loss: 0.0388\n",
      "Epoch [950/10000], Loss: 0.0388\n",
      "Epoch [960/10000], Loss: 0.0388\n",
      "Epoch [970/10000], Loss: 0.0388\n",
      "Epoch [980/10000], Loss: 0.0388\n",
      "Epoch [990/10000], Loss: 0.0388\n",
      "Epoch [1000/10000], Loss: 0.0387\n",
      "Epoch [1010/10000], Loss: 0.0388\n",
      "Epoch [1020/10000], Loss: 0.0387\n",
      "Epoch [1030/10000], Loss: 0.0387\n",
      "Epoch [1040/10000], Loss: 0.0387\n",
      "Epoch [1050/10000], Loss: 0.0387\n",
      "Epoch [1060/10000], Loss: 0.0387\n",
      "Epoch [1070/10000], Loss: 0.0387\n",
      "Epoch [1080/10000], Loss: 0.0387\n",
      "Epoch [1090/10000], Loss: 0.0387\n",
      "Epoch [1100/10000], Loss: 0.0388\n",
      "Epoch [1110/10000], Loss: 0.0387\n",
      "Epoch [1120/10000], Loss: 0.0387\n",
      "Epoch [1130/10000], Loss: 0.0387\n",
      "Epoch [1140/10000], Loss: 0.0387\n",
      "Epoch [1150/10000], Loss: 0.0387\n",
      "Epoch [1160/10000], Loss: 0.0387\n",
      "Epoch [1170/10000], Loss: 0.0387\n",
      "Epoch [1180/10000], Loss: 0.0387\n",
      "Epoch [1190/10000], Loss: 0.0387\n",
      "Epoch [1200/10000], Loss: 0.0387\n",
      "Epoch [1210/10000], Loss: 0.0387\n",
      "Epoch [1220/10000], Loss: 0.0387\n",
      "Epoch [1230/10000], Loss: 0.0387\n",
      "Epoch [1240/10000], Loss: 0.0387\n",
      "Epoch [1250/10000], Loss: 0.0387\n",
      "Epoch [1260/10000], Loss: 0.0387\n",
      "Epoch [1270/10000], Loss: 0.0387\n",
      "Epoch [1280/10000], Loss: 0.0387\n",
      "Epoch [1290/10000], Loss: 0.0387\n",
      "Epoch [1300/10000], Loss: 0.0387\n",
      "Epoch [1310/10000], Loss: 0.0387\n",
      "Epoch [1320/10000], Loss: 0.0387\n",
      "Epoch [1330/10000], Loss: 0.0387\n",
      "Epoch [1340/10000], Loss: 0.0387\n",
      "Epoch [1350/10000], Loss: 0.0387\n",
      "Epoch [1360/10000], Loss: 0.0387\n",
      "Epoch [1370/10000], Loss: 0.0387\n",
      "Epoch [1380/10000], Loss: 0.0387\n",
      "Epoch [1390/10000], Loss: 0.0387\n",
      "Epoch [1400/10000], Loss: 0.0387\n",
      "Epoch [1410/10000], Loss: 0.0387\n",
      "Epoch [1420/10000], Loss: 0.0387\n",
      "Epoch [1430/10000], Loss: 0.0387\n",
      "Epoch [1440/10000], Loss: 0.0387\n",
      "Epoch [1450/10000], Loss: 0.0387\n",
      "Epoch [1460/10000], Loss: 0.0387\n",
      "Epoch [1470/10000], Loss: 0.0387\n",
      "Epoch [1480/10000], Loss: 0.0387\n",
      "Epoch [1490/10000], Loss: 0.0387\n",
      "Epoch [1500/10000], Loss: 0.0387\n",
      "Epoch [1510/10000], Loss: 0.0387\n",
      "Epoch [1520/10000], Loss: 0.0387\n",
      "Epoch [1530/10000], Loss: 0.0387\n",
      "Epoch [1540/10000], Loss: 0.0387\n",
      "Epoch [1550/10000], Loss: 0.0387\n",
      "Epoch [1560/10000], Loss: 0.0387\n",
      "Epoch [1570/10000], Loss: 0.0387\n",
      "Epoch [1580/10000], Loss: 0.0387\n",
      "Epoch [1590/10000], Loss: 0.0387\n",
      "Epoch [1600/10000], Loss: 0.0387\n",
      "Epoch [1610/10000], Loss: 0.0387\n",
      "Epoch [1620/10000], Loss: 0.0387\n",
      "Epoch [1630/10000], Loss: 0.0387\n",
      "Epoch [1640/10000], Loss: 0.0387\n",
      "Epoch [1650/10000], Loss: 0.0387\n",
      "Epoch [1660/10000], Loss: 0.0387\n",
      "Epoch [1670/10000], Loss: 0.0387\n",
      "Epoch [1680/10000], Loss: 0.0387\n",
      "Epoch [1690/10000], Loss: 0.0387\n",
      "Epoch [1700/10000], Loss: 0.0387\n",
      "Epoch [1710/10000], Loss: 0.0387\n",
      "Epoch [1720/10000], Loss: 0.0387\n",
      "Epoch [1730/10000], Loss: 0.0387\n",
      "Epoch [1740/10000], Loss: 0.0387\n",
      "Epoch [1750/10000], Loss: 0.0387\n",
      "Epoch [1760/10000], Loss: 0.0387\n",
      "Epoch [1770/10000], Loss: 0.0387\n",
      "Epoch [1780/10000], Loss: 0.0387\n",
      "Epoch [1790/10000], Loss: 0.0387\n",
      "Epoch [1800/10000], Loss: 0.0387\n",
      "Epoch [1810/10000], Loss: 0.0387\n",
      "Epoch [1820/10000], Loss: 0.0387\n",
      "Epoch [1830/10000], Loss: 0.0387\n",
      "Epoch [1840/10000], Loss: 0.0387\n",
      "Epoch [1850/10000], Loss: 0.0387\n",
      "Epoch [1860/10000], Loss: 0.0387\n",
      "Epoch [1870/10000], Loss: 0.0387\n",
      "Epoch [1880/10000], Loss: 0.0387\n",
      "Epoch [1890/10000], Loss: 0.0387\n",
      "Epoch [1900/10000], Loss: 0.0387\n",
      "Epoch [1910/10000], Loss: 0.0387\n",
      "Epoch [1920/10000], Loss: 0.0387\n",
      "Epoch [1930/10000], Loss: 0.0387\n",
      "Epoch [1940/10000], Loss: 0.0387\n",
      "Epoch [1950/10000], Loss: 0.0387\n",
      "Epoch [1960/10000], Loss: 0.0387\n",
      "Epoch [1970/10000], Loss: 0.0387\n",
      "Epoch [1980/10000], Loss: 0.0387\n",
      "Epoch [1990/10000], Loss: 0.0387\n",
      "Epoch [2000/10000], Loss: 0.0387\n",
      "Epoch [2010/10000], Loss: 0.0387\n",
      "Epoch [2020/10000], Loss: 0.0387\n",
      "Epoch [2030/10000], Loss: 0.0387\n",
      "Epoch [2040/10000], Loss: 0.0387\n",
      "Epoch [2050/10000], Loss: 0.0387\n",
      "Epoch [2060/10000], Loss: 0.0387\n",
      "Epoch [2070/10000], Loss: 0.0387\n",
      "Epoch [2080/10000], Loss: 0.0387\n",
      "Epoch [2090/10000], Loss: 0.0387\n",
      "Epoch [2100/10000], Loss: 0.0387\n",
      "Epoch [2110/10000], Loss: 0.0386\n",
      "Epoch [2120/10000], Loss: 0.0387\n",
      "Epoch [2130/10000], Loss: 0.0386\n",
      "Epoch [2140/10000], Loss: 0.0387\n",
      "Epoch [2150/10000], Loss: 0.0387\n",
      "Epoch [2160/10000], Loss: 0.0387\n",
      "Epoch [2170/10000], Loss: 0.0386\n",
      "Epoch [2180/10000], Loss: 0.0387\n",
      "Epoch [2190/10000], Loss: 0.0386\n",
      "Epoch [2200/10000], Loss: 0.0387\n",
      "Epoch [2210/10000], Loss: 0.0386\n",
      "Epoch [2220/10000], Loss: 0.0386\n",
      "Epoch [2230/10000], Loss: 0.0386\n",
      "Epoch [2240/10000], Loss: 0.0386\n",
      "Epoch [2250/10000], Loss: 0.0387\n",
      "Epoch [2260/10000], Loss: 0.0386\n",
      "Epoch [2270/10000], Loss: 0.0386\n",
      "Epoch [2280/10000], Loss: 0.0386\n",
      "Epoch [2290/10000], Loss: 0.0386\n",
      "Epoch [2300/10000], Loss: 0.0386\n",
      "Epoch [2310/10000], Loss: 0.0386\n",
      "Epoch [2320/10000], Loss: 0.0386\n",
      "Epoch [2330/10000], Loss: 0.0386\n",
      "Epoch [2340/10000], Loss: 0.0386\n",
      "Epoch [2350/10000], Loss: 0.0386\n",
      "Epoch [2360/10000], Loss: 0.0386\n",
      "Epoch [2370/10000], Loss: 0.0386\n",
      "Epoch [2380/10000], Loss: 0.0386\n",
      "Epoch [2390/10000], Loss: 0.0387\n",
      "Epoch [2400/10000], Loss: 0.0386\n",
      "Epoch [2410/10000], Loss: 0.0386\n",
      "Epoch [2420/10000], Loss: 0.0386\n",
      "Epoch [2430/10000], Loss: 0.0386\n",
      "Epoch [2440/10000], Loss: 0.0386\n",
      "Epoch [2450/10000], Loss: 0.0386\n",
      "Epoch [2460/10000], Loss: 0.0386\n",
      "Epoch [2470/10000], Loss: 0.0386\n",
      "Epoch [2480/10000], Loss: 0.0386\n",
      "Epoch [2490/10000], Loss: 0.0386\n",
      "Epoch [2500/10000], Loss: 0.0386\n",
      "Epoch [2510/10000], Loss: 0.0386\n",
      "Epoch [2520/10000], Loss: 0.0386\n",
      "Epoch [2530/10000], Loss: 0.0386\n",
      "Epoch [2540/10000], Loss: 0.0386\n",
      "Epoch [2550/10000], Loss: 0.0386\n",
      "Epoch [2560/10000], Loss: 0.0386\n",
      "Epoch [2570/10000], Loss: 0.0386\n",
      "Epoch [2580/10000], Loss: 0.0386\n",
      "Epoch [2590/10000], Loss: 0.0386\n",
      "Epoch [2600/10000], Loss: 0.0386\n",
      "Epoch [2610/10000], Loss: 0.0386\n",
      "Epoch [2620/10000], Loss: 0.0386\n",
      "Epoch [2630/10000], Loss: 0.0386\n",
      "Epoch [2640/10000], Loss: 0.0386\n",
      "Epoch [2650/10000], Loss: 0.0386\n",
      "Epoch [2660/10000], Loss: 0.0386\n",
      "Epoch [2670/10000], Loss: 0.0386\n",
      "Epoch [2680/10000], Loss: 0.0386\n",
      "Epoch [2690/10000], Loss: 0.0386\n",
      "Epoch [2700/10000], Loss: 0.0386\n",
      "Epoch [2710/10000], Loss: 0.0386\n",
      "Epoch [2720/10000], Loss: 0.0386\n",
      "Epoch [2730/10000], Loss: 0.0386\n",
      "Epoch [2740/10000], Loss: 0.0386\n",
      "Epoch [2750/10000], Loss: 0.0386\n",
      "Epoch [2760/10000], Loss: 0.0386\n",
      "Epoch [2770/10000], Loss: 0.0386\n",
      "Epoch [2780/10000], Loss: 0.0386\n",
      "Epoch [2790/10000], Loss: 0.0386\n",
      "Epoch [2800/10000], Loss: 0.0386\n",
      "Epoch [2810/10000], Loss: 0.0386\n",
      "Epoch [2820/10000], Loss: 0.0386\n",
      "Epoch [2830/10000], Loss: 0.0386\n",
      "Epoch [2840/10000], Loss: 0.0386\n",
      "Epoch [2850/10000], Loss: 0.0386\n",
      "Epoch [2860/10000], Loss: 0.0386\n",
      "Epoch [2870/10000], Loss: 0.0386\n",
      "Epoch [2880/10000], Loss: 0.0386\n",
      "Epoch [2890/10000], Loss: 0.0386\n",
      "Epoch [2900/10000], Loss: 0.0386\n",
      "Epoch [2910/10000], Loss: 0.0386\n",
      "Epoch [2920/10000], Loss: 0.0386\n",
      "Epoch [2930/10000], Loss: 0.0386\n",
      "Epoch [2940/10000], Loss: 0.0386\n",
      "Epoch [2950/10000], Loss: 0.0386\n",
      "Epoch [2960/10000], Loss: 0.0386\n",
      "Epoch [2970/10000], Loss: 0.0386\n",
      "Epoch [2980/10000], Loss: 0.0386\n",
      "Epoch [2990/10000], Loss: 0.0386\n",
      "Epoch [3000/10000], Loss: 0.0386\n",
      "Epoch [3010/10000], Loss: 0.0386\n",
      "Epoch [3020/10000], Loss: 0.0386\n",
      "Epoch [3030/10000], Loss: 0.0386\n",
      "Epoch [3040/10000], Loss: 0.0386\n",
      "Epoch [3050/10000], Loss: 0.0386\n",
      "Epoch [3060/10000], Loss: 0.0386\n",
      "Epoch [3070/10000], Loss: 0.0386\n",
      "Epoch [3080/10000], Loss: 0.0386\n",
      "Epoch [3090/10000], Loss: 0.0386\n",
      "Epoch [3100/10000], Loss: 0.0386\n",
      "Epoch [3110/10000], Loss: 0.0386\n",
      "Epoch [3120/10000], Loss: 0.0386\n",
      "Epoch [3130/10000], Loss: 0.0386\n",
      "Epoch [3140/10000], Loss: 0.0386\n",
      "Epoch [3150/10000], Loss: 0.0386\n",
      "Epoch [3160/10000], Loss: 0.0386\n",
      "Epoch [3170/10000], Loss: 0.0386\n",
      "Epoch [3180/10000], Loss: 0.0386\n",
      "Epoch [3190/10000], Loss: 0.0386\n",
      "Epoch [3200/10000], Loss: 0.0386\n",
      "Epoch [3210/10000], Loss: 0.0386\n",
      "Epoch [3220/10000], Loss: 0.0386\n",
      "Epoch [3230/10000], Loss: 0.0386\n",
      "Epoch [3240/10000], Loss: 0.0386\n",
      "Epoch [3250/10000], Loss: 0.0386\n",
      "Epoch [3260/10000], Loss: 0.0386\n",
      "Epoch [3270/10000], Loss: 0.0386\n",
      "Epoch [3280/10000], Loss: 0.0386\n",
      "Epoch [3290/10000], Loss: 0.0386\n",
      "Epoch [3300/10000], Loss: 0.0386\n",
      "Epoch [3310/10000], Loss: 0.0386\n",
      "Epoch [3320/10000], Loss: 0.0386\n",
      "Epoch [3330/10000], Loss: 0.0386\n",
      "Epoch [3340/10000], Loss: 0.0386\n",
      "Epoch [3350/10000], Loss: 0.0386\n",
      "Epoch [3360/10000], Loss: 0.0386\n",
      "Epoch [3370/10000], Loss: 0.0386\n",
      "Epoch [3380/10000], Loss: 0.0386\n",
      "Epoch [3390/10000], Loss: 0.0386\n",
      "Epoch [3400/10000], Loss: 0.0386\n",
      "Epoch [3410/10000], Loss: 0.0386\n",
      "Epoch [3420/10000], Loss: 0.0386\n",
      "Epoch [3430/10000], Loss: 0.0386\n",
      "Epoch [3440/10000], Loss: 0.0386\n",
      "Epoch [3450/10000], Loss: 0.0386\n",
      "Epoch [3460/10000], Loss: 0.0386\n",
      "Epoch [3470/10000], Loss: 0.0386\n",
      "Epoch [3480/10000], Loss: 0.0386\n",
      "Epoch [3490/10000], Loss: 0.0386\n",
      "Epoch [3500/10000], Loss: 0.0386\n",
      "Epoch [3510/10000], Loss: 0.0386\n",
      "Epoch [3520/10000], Loss: 0.0386\n",
      "Epoch [3530/10000], Loss: 0.0386\n",
      "Epoch [3540/10000], Loss: 0.0386\n",
      "Epoch [3550/10000], Loss: 0.0386\n",
      "Epoch [3560/10000], Loss: 0.0386\n",
      "Epoch [3570/10000], Loss: 0.0386\n",
      "Epoch [3580/10000], Loss: 0.0386\n",
      "Epoch [3590/10000], Loss: 0.0386\n",
      "Epoch [3600/10000], Loss: 0.0386\n",
      "Epoch [3610/10000], Loss: 0.0386\n",
      "Epoch [3620/10000], Loss: 0.0386\n",
      "Epoch [3630/10000], Loss: 0.0386\n",
      "Epoch [3640/10000], Loss: 0.0386\n",
      "Epoch [3650/10000], Loss: 0.0386\n",
      "Epoch [3660/10000], Loss: 0.0386\n",
      "Epoch [3670/10000], Loss: 0.0386\n",
      "Epoch [3680/10000], Loss: 0.0386\n",
      "Epoch [3690/10000], Loss: 0.0386\n",
      "Epoch [3700/10000], Loss: 0.0386\n",
      "Epoch [3710/10000], Loss: 0.0386\n",
      "Epoch [3720/10000], Loss: 0.0386\n",
      "Epoch [3730/10000], Loss: 0.0386\n",
      "Epoch [3740/10000], Loss: 0.0386\n",
      "Epoch [3750/10000], Loss: 0.0386\n",
      "Epoch [3760/10000], Loss: 0.0386\n",
      "Epoch [3770/10000], Loss: 0.0386\n",
      "Epoch [3780/10000], Loss: 0.0386\n",
      "Epoch [3790/10000], Loss: 0.0386\n",
      "Epoch [3800/10000], Loss: 0.0386\n",
      "Epoch [3810/10000], Loss: 0.0386\n",
      "Epoch [3820/10000], Loss: 0.0386\n",
      "Epoch [3830/10000], Loss: 0.0386\n",
      "Epoch [3840/10000], Loss: 0.0386\n",
      "Epoch [3850/10000], Loss: 0.0386\n",
      "Epoch [3860/10000], Loss: 0.0386\n",
      "Epoch [3870/10000], Loss: 0.0386\n",
      "Epoch [3880/10000], Loss: 0.0386\n",
      "Epoch [3890/10000], Loss: 0.0386\n",
      "Epoch [3900/10000], Loss: 0.0386\n",
      "Epoch [3910/10000], Loss: 0.0386\n",
      "Epoch [3920/10000], Loss: 0.0386\n",
      "Epoch [3930/10000], Loss: 0.0386\n",
      "Epoch [3940/10000], Loss: 0.0386\n",
      "Epoch [3950/10000], Loss: 0.0386\n",
      "Epoch [3960/10000], Loss: 0.0386\n",
      "Epoch [3970/10000], Loss: 0.0386\n",
      "Epoch [3980/10000], Loss: 0.0386\n",
      "Epoch [3990/10000], Loss: 0.0386\n",
      "Epoch [4000/10000], Loss: 0.0386\n",
      "Epoch [4010/10000], Loss: 0.0386\n",
      "Epoch [4020/10000], Loss: 0.0386\n",
      "Epoch [4030/10000], Loss: 0.0386\n",
      "Epoch [4040/10000], Loss: 0.0386\n",
      "Epoch [4050/10000], Loss: 0.0386\n",
      "Epoch [4060/10000], Loss: 0.0386\n",
      "Epoch [4070/10000], Loss: 0.0385\n",
      "Epoch [4080/10000], Loss: 0.0386\n",
      "Epoch [4090/10000], Loss: 0.0386\n",
      "Epoch [4100/10000], Loss: 0.0386\n",
      "Epoch [4110/10000], Loss: 0.0385\n",
      "Epoch [4120/10000], Loss: 0.0385\n",
      "Epoch [4130/10000], Loss: 0.0386\n",
      "Epoch [4140/10000], Loss: 0.0386\n",
      "Epoch [4150/10000], Loss: 0.0385\n",
      "Epoch [4160/10000], Loss: 0.0386\n",
      "Epoch [4170/10000], Loss: 0.0385\n",
      "Epoch [4180/10000], Loss: 0.0385\n",
      "Epoch [4190/10000], Loss: 0.0386\n",
      "Epoch [4200/10000], Loss: 0.0386\n",
      "Epoch [4210/10000], Loss: 0.0385\n",
      "Epoch [4220/10000], Loss: 0.0386\n",
      "Epoch [4230/10000], Loss: 0.0385\n",
      "Epoch [4240/10000], Loss: 0.0386\n",
      "Epoch [4250/10000], Loss: 0.0385\n",
      "Epoch [4260/10000], Loss: 0.0386\n",
      "Epoch [4270/10000], Loss: 0.0386\n",
      "Epoch [4280/10000], Loss: 0.0385\n",
      "Epoch [4290/10000], Loss: 0.0385\n",
      "Epoch [4300/10000], Loss: 0.0385\n",
      "Epoch [4310/10000], Loss: 0.0385\n",
      "Epoch [4320/10000], Loss: 0.0385\n",
      "Epoch [4330/10000], Loss: 0.0385\n",
      "Epoch [4340/10000], Loss: 0.0386\n",
      "Epoch [4350/10000], Loss: 0.0385\n",
      "Epoch [4360/10000], Loss: 0.0385\n",
      "Epoch [4370/10000], Loss: 0.0385\n",
      "Epoch [4380/10000], Loss: 0.0385\n",
      "Epoch [4390/10000], Loss: 0.0385\n",
      "Epoch [4400/10000], Loss: 0.0385\n",
      "Epoch [4410/10000], Loss: 0.0385\n",
      "Epoch [4420/10000], Loss: 0.0385\n",
      "Epoch [4430/10000], Loss: 0.0385\n",
      "Epoch [4440/10000], Loss: 0.0385\n",
      "Epoch [4450/10000], Loss: 0.0385\n",
      "Epoch [4460/10000], Loss: 0.0385\n",
      "Epoch [4470/10000], Loss: 0.0385\n",
      "Epoch [4480/10000], Loss: 0.0385\n",
      "Epoch [4490/10000], Loss: 0.0385\n",
      "Epoch [4500/10000], Loss: 0.0385\n",
      "Epoch [4510/10000], Loss: 0.0385\n",
      "Epoch [4520/10000], Loss: 0.0385\n",
      "Epoch [4530/10000], Loss: 0.0386\n",
      "Epoch [4540/10000], Loss: 0.0385\n",
      "Epoch [4550/10000], Loss: 0.0385\n",
      "Epoch [4560/10000], Loss: 0.0385\n",
      "Epoch [4570/10000], Loss: 0.0385\n",
      "Epoch [4580/10000], Loss: 0.0385\n",
      "Epoch [4590/10000], Loss: 0.0385\n",
      "Epoch [4600/10000], Loss: 0.0385\n",
      "Epoch [4610/10000], Loss: 0.0385\n",
      "Epoch [4620/10000], Loss: 0.0385\n",
      "Epoch [4630/10000], Loss: 0.0385\n",
      "Epoch [4640/10000], Loss: 0.0385\n",
      "Epoch [4650/10000], Loss: 0.0385\n",
      "Epoch [4660/10000], Loss: 0.0385\n",
      "Epoch [4670/10000], Loss: 0.0385\n",
      "Epoch [4680/10000], Loss: 0.0385\n",
      "Epoch [4690/10000], Loss: 0.0385\n",
      "Epoch [4700/10000], Loss: 0.0385\n",
      "Epoch [4710/10000], Loss: 0.0385\n",
      "Epoch [4720/10000], Loss: 0.0385\n",
      "Epoch [4730/10000], Loss: 0.0385\n",
      "Epoch [4740/10000], Loss: 0.0385\n",
      "Epoch [4750/10000], Loss: 0.0385\n",
      "Epoch [4760/10000], Loss: 0.0385\n",
      "Epoch [4770/10000], Loss: 0.0385\n",
      "Epoch [4780/10000], Loss: 0.0385\n",
      "Epoch [4790/10000], Loss: 0.0385\n",
      "Epoch [4800/10000], Loss: 0.0385\n",
      "Epoch [4810/10000], Loss: 0.0385\n",
      "Epoch [4820/10000], Loss: 0.0385\n",
      "Epoch [4830/10000], Loss: 0.0385\n",
      "Epoch [4840/10000], Loss: 0.0385\n",
      "Epoch [4850/10000], Loss: 0.0385\n",
      "Epoch [4860/10000], Loss: 0.0385\n",
      "Epoch [4870/10000], Loss: 0.0385\n",
      "Epoch [4880/10000], Loss: 0.0385\n",
      "Epoch [4890/10000], Loss: 0.0385\n",
      "Epoch [4900/10000], Loss: 0.0385\n",
      "Epoch [4910/10000], Loss: 0.0385\n",
      "Epoch [4920/10000], Loss: 0.0385\n",
      "Epoch [4930/10000], Loss: 0.0385\n",
      "Epoch [4940/10000], Loss: 0.0385\n",
      "Epoch [4950/10000], Loss: 0.0385\n",
      "Epoch [4960/10000], Loss: 0.0385\n",
      "Epoch [4970/10000], Loss: 0.0385\n",
      "Epoch [4980/10000], Loss: 0.0385\n",
      "Epoch [4990/10000], Loss: 0.0385\n",
      "Epoch [5000/10000], Loss: 0.0385\n",
      "Epoch [5010/10000], Loss: 0.0385\n",
      "Epoch [5020/10000], Loss: 0.0385\n",
      "Epoch [5030/10000], Loss: 0.0385\n",
      "Epoch [5040/10000], Loss: 0.0385\n",
      "Epoch [5050/10000], Loss: 0.0385\n",
      "Epoch [5060/10000], Loss: 0.0385\n",
      "Epoch [5070/10000], Loss: 0.0385\n",
      "Epoch [5080/10000], Loss: 0.0385\n",
      "Epoch [5090/10000], Loss: 0.0385\n",
      "Epoch [5100/10000], Loss: 0.0385\n",
      "Epoch [5110/10000], Loss: 0.0385\n",
      "Epoch [5120/10000], Loss: 0.0385\n",
      "Epoch [5130/10000], Loss: 0.0385\n",
      "Epoch [5140/10000], Loss: 0.0385\n",
      "Epoch [5150/10000], Loss: 0.0385\n",
      "Epoch [5160/10000], Loss: 0.0385\n",
      "Epoch [5170/10000], Loss: 0.0385\n",
      "Epoch [5180/10000], Loss: 0.0385\n",
      "Epoch [5190/10000], Loss: 0.0385\n",
      "Epoch [5200/10000], Loss: 0.0385\n",
      "Epoch [5210/10000], Loss: 0.0385\n",
      "Epoch [5220/10000], Loss: 0.0385\n",
      "Epoch [5230/10000], Loss: 0.0385\n",
      "Epoch [5240/10000], Loss: 0.0385\n",
      "Epoch [5250/10000], Loss: 0.0385\n",
      "Epoch [5260/10000], Loss: 0.0385\n",
      "Epoch [5270/10000], Loss: 0.0385\n",
      "Epoch [5280/10000], Loss: 0.0385\n",
      "Epoch [5290/10000], Loss: 0.0385\n",
      "Epoch [5300/10000], Loss: 0.0385\n",
      "Epoch [5310/10000], Loss: 0.0385\n",
      "Epoch [5320/10000], Loss: 0.0385\n",
      "Epoch [5330/10000], Loss: 0.0385\n",
      "Epoch [5340/10000], Loss: 0.0385\n",
      "Epoch [5350/10000], Loss: 0.0385\n",
      "Epoch [5360/10000], Loss: 0.0385\n",
      "Epoch [5370/10000], Loss: 0.0385\n",
      "Epoch [5380/10000], Loss: 0.0385\n",
      "Epoch [5390/10000], Loss: 0.0385\n",
      "Epoch [5400/10000], Loss: 0.0385\n",
      "Epoch [5410/10000], Loss: 0.0385\n",
      "Epoch [5420/10000], Loss: 0.0385\n",
      "Epoch [5430/10000], Loss: 0.0385\n",
      "Epoch [5440/10000], Loss: 0.0385\n",
      "Epoch [5450/10000], Loss: 0.0385\n",
      "Epoch [5460/10000], Loss: 0.0385\n",
      "Epoch [5470/10000], Loss: 0.0385\n",
      "Epoch [5480/10000], Loss: 0.0385\n",
      "Epoch [5490/10000], Loss: 0.0385\n",
      "Epoch [5500/10000], Loss: 0.0385\n",
      "Epoch [5510/10000], Loss: 0.0385\n",
      "Epoch [5520/10000], Loss: 0.0385\n",
      "Epoch [5530/10000], Loss: 0.0385\n",
      "Epoch [5540/10000], Loss: 0.0385\n",
      "Epoch [5550/10000], Loss: 0.0385\n",
      "Epoch [5560/10000], Loss: 0.0385\n",
      "Epoch [5570/10000], Loss: 0.0385\n",
      "Epoch [5580/10000], Loss: 0.0385\n",
      "Epoch [5590/10000], Loss: 0.0385\n",
      "Epoch [5600/10000], Loss: 0.0385\n",
      "Epoch [5610/10000], Loss: 0.0385\n",
      "Epoch [5620/10000], Loss: 0.0385\n",
      "Epoch [5630/10000], Loss: 0.0385\n",
      "Epoch [5640/10000], Loss: 0.0385\n",
      "Epoch [5650/10000], Loss: 0.0385\n",
      "Epoch [5660/10000], Loss: 0.0385\n",
      "Epoch [5670/10000], Loss: 0.0385\n",
      "Epoch [5680/10000], Loss: 0.0385\n",
      "Epoch [5690/10000], Loss: 0.0385\n",
      "Epoch [5700/10000], Loss: 0.0385\n",
      "Epoch [5710/10000], Loss: 0.0385\n",
      "Epoch [5720/10000], Loss: 0.0385\n",
      "Epoch [5730/10000], Loss: 0.0385\n",
      "Epoch [5740/10000], Loss: 0.0385\n",
      "Epoch [5750/10000], Loss: 0.0385\n",
      "Epoch [5760/10000], Loss: 0.0385\n",
      "Epoch [5770/10000], Loss: 0.0385\n",
      "Epoch [5780/10000], Loss: 0.0385\n",
      "Epoch [5790/10000], Loss: 0.0385\n",
      "Epoch [5800/10000], Loss: 0.0385\n",
      "Epoch [5810/10000], Loss: 0.0385\n",
      "Epoch [5820/10000], Loss: 0.0385\n",
      "Epoch [5830/10000], Loss: 0.0385\n",
      "Epoch [5840/10000], Loss: 0.0385\n",
      "Epoch [5850/10000], Loss: 0.0385\n",
      "Epoch [5860/10000], Loss: 0.0385\n",
      "Epoch [5870/10000], Loss: 0.0385\n",
      "Epoch [5880/10000], Loss: 0.0385\n",
      "Epoch [5890/10000], Loss: 0.0385\n",
      "Epoch [5900/10000], Loss: 0.0385\n",
      "Epoch [5910/10000], Loss: 0.0385\n",
      "Epoch [5920/10000], Loss: 0.0385\n",
      "Epoch [5930/10000], Loss: 0.0385\n",
      "Epoch [5940/10000], Loss: 0.0385\n",
      "Epoch [5950/10000], Loss: 0.0385\n",
      "Epoch [5960/10000], Loss: 0.0385\n",
      "Epoch [5970/10000], Loss: 0.0385\n",
      "Epoch [5980/10000], Loss: 0.0385\n",
      "Epoch [5990/10000], Loss: 0.0385\n",
      "Epoch [6000/10000], Loss: 0.0385\n",
      "Epoch [6010/10000], Loss: 0.0385\n",
      "Epoch [6020/10000], Loss: 0.0385\n",
      "Epoch [6030/10000], Loss: 0.0385\n",
      "Epoch [6040/10000], Loss: 0.0385\n",
      "Epoch [6050/10000], Loss: 0.0385\n",
      "Epoch [6060/10000], Loss: 0.0385\n",
      "Epoch [6070/10000], Loss: 0.0385\n",
      "Epoch [6080/10000], Loss: 0.0385\n",
      "Epoch [6090/10000], Loss: 0.0385\n",
      "Epoch [6100/10000], Loss: 0.0385\n",
      "Epoch [6110/10000], Loss: 0.0385\n",
      "Epoch [6120/10000], Loss: 0.0385\n",
      "Epoch [6130/10000], Loss: 0.0385\n",
      "Epoch [6140/10000], Loss: 0.0385\n",
      "Epoch [6150/10000], Loss: 0.0385\n",
      "Epoch [6160/10000], Loss: 0.0385\n",
      "Epoch [6170/10000], Loss: 0.0385\n",
      "Epoch [6180/10000], Loss: 0.0385\n",
      "Epoch [6190/10000], Loss: 0.0385\n",
      "Epoch [6200/10000], Loss: 0.0385\n",
      "Epoch [6210/10000], Loss: 0.0385\n",
      "Epoch [6220/10000], Loss: 0.0385\n",
      "Epoch [6230/10000], Loss: 0.0385\n",
      "Epoch [6240/10000], Loss: 0.0385\n",
      "Epoch [6250/10000], Loss: 0.0385\n",
      "Epoch [6260/10000], Loss: 0.0385\n",
      "Epoch [6270/10000], Loss: 0.0385\n",
      "Epoch [6280/10000], Loss: 0.0385\n",
      "Epoch [6290/10000], Loss: 0.0385\n",
      "Epoch [6300/10000], Loss: 0.0385\n",
      "Epoch [6310/10000], Loss: 0.0385\n",
      "Epoch [6320/10000], Loss: 0.0385\n",
      "Epoch [6330/10000], Loss: 0.0385\n",
      "Epoch [6340/10000], Loss: 0.0385\n",
      "Epoch [6350/10000], Loss: 0.0385\n",
      "Epoch [6360/10000], Loss: 0.0385\n",
      "Epoch [6370/10000], Loss: 0.0385\n",
      "Epoch [6380/10000], Loss: 0.0385\n",
      "Epoch [6390/10000], Loss: 0.0385\n",
      "Epoch [6400/10000], Loss: 0.0385\n",
      "Epoch [6410/10000], Loss: 0.0385\n",
      "Epoch [6420/10000], Loss: 0.0385\n",
      "Epoch [6430/10000], Loss: 0.0385\n",
      "Epoch [6440/10000], Loss: 0.0385\n",
      "Epoch [6450/10000], Loss: 0.0385\n",
      "Epoch [6460/10000], Loss: 0.0385\n",
      "Epoch [6470/10000], Loss: 0.0385\n",
      "Epoch [6480/10000], Loss: 0.0385\n",
      "Epoch [6490/10000], Loss: 0.0385\n",
      "Epoch [6500/10000], Loss: 0.0385\n",
      "Epoch [6510/10000], Loss: 0.0385\n",
      "Epoch [6520/10000], Loss: 0.0385\n",
      "Epoch [6530/10000], Loss: 0.0385\n",
      "Epoch [6540/10000], Loss: 0.0385\n",
      "Epoch [6550/10000], Loss: 0.0385\n",
      "Epoch [6560/10000], Loss: 0.0385\n",
      "Epoch [6570/10000], Loss: 0.0385\n",
      "Epoch [6580/10000], Loss: 0.0385\n",
      "Epoch [6590/10000], Loss: 0.0385\n",
      "Epoch [6600/10000], Loss: 0.0385\n",
      "Epoch [6610/10000], Loss: 0.0385\n",
      "Epoch [6620/10000], Loss: 0.0385\n",
      "Epoch [6630/10000], Loss: 0.0385\n",
      "Epoch [6640/10000], Loss: 0.0385\n",
      "Epoch [6650/10000], Loss: 0.0385\n",
      "Epoch [6660/10000], Loss: 0.0385\n",
      "Epoch [6670/10000], Loss: 0.0385\n",
      "Epoch [6680/10000], Loss: 0.0385\n",
      "Epoch [6690/10000], Loss: 0.0385\n",
      "Epoch [6700/10000], Loss: 0.0385\n",
      "Epoch [6710/10000], Loss: 0.0385\n",
      "Epoch [6720/10000], Loss: 0.0385\n",
      "Epoch [6730/10000], Loss: 0.0385\n",
      "Epoch [6740/10000], Loss: 0.0385\n",
      "Epoch [6750/10000], Loss: 0.0385\n",
      "Epoch [6760/10000], Loss: 0.0385\n",
      "Epoch [6770/10000], Loss: 0.0385\n",
      "Epoch [6780/10000], Loss: 0.0385\n",
      "Epoch [6790/10000], Loss: 0.0385\n",
      "Epoch [6800/10000], Loss: 0.0385\n",
      "Epoch [6810/10000], Loss: 0.0385\n",
      "Epoch [6820/10000], Loss: 0.0385\n",
      "Epoch [6830/10000], Loss: 0.0385\n",
      "Epoch [6840/10000], Loss: 0.0385\n",
      "Epoch [6850/10000], Loss: 0.0385\n",
      "Epoch [6860/10000], Loss: 0.0385\n",
      "Epoch [6870/10000], Loss: 0.0385\n",
      "Epoch [6880/10000], Loss: 0.0385\n",
      "Epoch [6890/10000], Loss: 0.0385\n",
      "Epoch [6900/10000], Loss: 0.0385\n",
      "Epoch [6910/10000], Loss: 0.0385\n",
      "Epoch [6920/10000], Loss: 0.0385\n",
      "Epoch [6930/10000], Loss: 0.0385\n",
      "Epoch [6940/10000], Loss: 0.0385\n",
      "Epoch [6950/10000], Loss: 0.0385\n",
      "Epoch [6960/10000], Loss: 0.0385\n",
      "Epoch [6970/10000], Loss: 0.0385\n",
      "Epoch [6980/10000], Loss: 0.0385\n",
      "Epoch [6990/10000], Loss: 0.0385\n",
      "Epoch [7000/10000], Loss: 0.0385\n",
      "Epoch [7010/10000], Loss: 0.0385\n",
      "Epoch [7020/10000], Loss: 0.0385\n",
      "Epoch [7030/10000], Loss: 0.0385\n",
      "Epoch [7040/10000], Loss: 0.0385\n",
      "Epoch [7050/10000], Loss: 0.0385\n",
      "Epoch [7060/10000], Loss: 0.0385\n",
      "Epoch [7070/10000], Loss: 0.0385\n",
      "Epoch [7080/10000], Loss: 0.0385\n",
      "Epoch [7090/10000], Loss: 0.0385\n",
      "Epoch [7100/10000], Loss: 0.0385\n",
      "Epoch [7110/10000], Loss: 0.0385\n",
      "Epoch [7120/10000], Loss: 0.0385\n",
      "Epoch [7130/10000], Loss: 0.0385\n",
      "Epoch [7140/10000], Loss: 0.0385\n",
      "Epoch [7150/10000], Loss: 0.0385\n",
      "Epoch [7160/10000], Loss: 0.0385\n",
      "Epoch [7170/10000], Loss: 0.0385\n",
      "Epoch [7180/10000], Loss: 0.0385\n",
      "Epoch [7190/10000], Loss: 0.0385\n",
      "Epoch [7200/10000], Loss: 0.0385\n",
      "Epoch [7210/10000], Loss: 0.0385\n",
      "Epoch [7220/10000], Loss: 0.0385\n",
      "Epoch [7230/10000], Loss: 0.0385\n",
      "Epoch [7240/10000], Loss: 0.0385\n",
      "Epoch [7250/10000], Loss: 0.0385\n",
      "Epoch [7260/10000], Loss: 0.0385\n",
      "Epoch [7270/10000], Loss: 0.0385\n",
      "Epoch [7280/10000], Loss: 0.0385\n",
      "Epoch [7290/10000], Loss: 0.0385\n",
      "Epoch [7300/10000], Loss: 0.0385\n",
      "Epoch [7310/10000], Loss: 0.0385\n",
      "Epoch [7320/10000], Loss: 0.0385\n",
      "Epoch [7330/10000], Loss: 0.0385\n",
      "Epoch [7340/10000], Loss: 0.0385\n",
      "Epoch [7350/10000], Loss: 0.0385\n",
      "Epoch [7360/10000], Loss: 0.0385\n",
      "Epoch [7370/10000], Loss: 0.0385\n",
      "Epoch [7380/10000], Loss: 0.0385\n",
      "Epoch [7390/10000], Loss: 0.0385\n",
      "Epoch [7400/10000], Loss: 0.0385\n",
      "Epoch [7410/10000], Loss: 0.0385\n",
      "Epoch [7420/10000], Loss: 0.0385\n",
      "Epoch [7430/10000], Loss: 0.0385\n",
      "Epoch [7440/10000], Loss: 0.0385\n",
      "Epoch [7450/10000], Loss: 0.0385\n",
      "Epoch [7460/10000], Loss: 0.0385\n",
      "Epoch [7470/10000], Loss: 0.0385\n",
      "Epoch [7480/10000], Loss: 0.0385\n",
      "Epoch [7490/10000], Loss: 0.0385\n",
      "Epoch [7500/10000], Loss: 0.0385\n",
      "Epoch [7510/10000], Loss: 0.0385\n",
      "Epoch [7520/10000], Loss: 0.0385\n",
      "Epoch [7530/10000], Loss: 0.0385\n",
      "Epoch [7540/10000], Loss: 0.0385\n",
      "Epoch [7550/10000], Loss: 0.0385\n",
      "Epoch [7560/10000], Loss: 0.0385\n",
      "Epoch [7570/10000], Loss: 0.0385\n",
      "Epoch [7580/10000], Loss: 0.0385\n",
      "Epoch [7590/10000], Loss: 0.0385\n",
      "Epoch [7600/10000], Loss: 0.0385\n",
      "Epoch [7610/10000], Loss: 0.0385\n",
      "Epoch [7620/10000], Loss: 0.0385\n",
      "Epoch [7630/10000], Loss: 0.0385\n",
      "Epoch [7640/10000], Loss: 0.0385\n",
      "Epoch [7650/10000], Loss: 0.0385\n",
      "Epoch [7660/10000], Loss: 0.0385\n",
      "Epoch [7670/10000], Loss: 0.0385\n",
      "Epoch [7680/10000], Loss: 0.0385\n",
      "Epoch [7690/10000], Loss: 0.0385\n",
      "Epoch [7700/10000], Loss: 0.0385\n",
      "Epoch [7710/10000], Loss: 0.0385\n",
      "Epoch [7720/10000], Loss: 0.0385\n",
      "Epoch [7730/10000], Loss: 0.0385\n",
      "Epoch [7740/10000], Loss: 0.0385\n",
      "Epoch [7750/10000], Loss: 0.0385\n",
      "Epoch [7760/10000], Loss: 0.0385\n",
      "Epoch [7770/10000], Loss: 0.0385\n",
      "Epoch [7780/10000], Loss: 0.0385\n",
      "Epoch [7790/10000], Loss: 0.0385\n",
      "Epoch [7800/10000], Loss: 0.0385\n",
      "Epoch [7810/10000], Loss: 0.0385\n",
      "Epoch [7820/10000], Loss: 0.0385\n",
      "Epoch [7830/10000], Loss: 0.0385\n",
      "Epoch [7840/10000], Loss: 0.0385\n",
      "Epoch [7850/10000], Loss: 0.0385\n",
      "Epoch [7860/10000], Loss: 0.0385\n",
      "Epoch [7870/10000], Loss: 0.0385\n",
      "Epoch [7880/10000], Loss: 0.0385\n",
      "Epoch [7890/10000], Loss: 0.0385\n",
      "Epoch [7900/10000], Loss: 0.0385\n",
      "Epoch [7910/10000], Loss: 0.0385\n",
      "Epoch [7920/10000], Loss: 0.0385\n",
      "Epoch [7930/10000], Loss: 0.0385\n",
      "Epoch [7940/10000], Loss: 0.0385\n",
      "Epoch [7950/10000], Loss: 0.0385\n",
      "Epoch [7960/10000], Loss: 0.0385\n",
      "Epoch [7970/10000], Loss: 0.0385\n",
      "Epoch [7980/10000], Loss: 0.0385\n",
      "Epoch [7990/10000], Loss: 0.0385\n",
      "Epoch [8000/10000], Loss: 0.0385\n",
      "Epoch [8010/10000], Loss: 0.0385\n",
      "Epoch [8020/10000], Loss: 0.0385\n",
      "Epoch [8030/10000], Loss: 0.0385\n",
      "Epoch [8040/10000], Loss: 0.0385\n",
      "Epoch [8050/10000], Loss: 0.0385\n",
      "Epoch [8060/10000], Loss: 0.0385\n",
      "Epoch [8070/10000], Loss: 0.0385\n",
      "Epoch [8080/10000], Loss: 0.0385\n",
      "Epoch [8090/10000], Loss: 0.0385\n",
      "Epoch [8100/10000], Loss: 0.0385\n",
      "Epoch [8110/10000], Loss: 0.0385\n",
      "Epoch [8120/10000], Loss: 0.0385\n",
      "Epoch [8130/10000], Loss: 0.0385\n",
      "Epoch [8140/10000], Loss: 0.0385\n",
      "Epoch [8150/10000], Loss: 0.0385\n",
      "Epoch [8160/10000], Loss: 0.0385\n",
      "Epoch [8170/10000], Loss: 0.0385\n",
      "Epoch [8180/10000], Loss: 0.0385\n",
      "Epoch [8190/10000], Loss: 0.0385\n",
      "Epoch [8200/10000], Loss: 0.0385\n",
      "Epoch [8210/10000], Loss: 0.0385\n",
      "Epoch [8220/10000], Loss: 0.0385\n",
      "Epoch [8230/10000], Loss: 0.0385\n",
      "Epoch [8240/10000], Loss: 0.0385\n",
      "Epoch [8250/10000], Loss: 0.0385\n",
      "Epoch [8260/10000], Loss: 0.0385\n",
      "Epoch [8270/10000], Loss: 0.0385\n",
      "Epoch [8280/10000], Loss: 0.0385\n",
      "Epoch [8290/10000], Loss: 0.0385\n",
      "Epoch [8300/10000], Loss: 0.0385\n",
      "Epoch [8310/10000], Loss: 0.0385\n",
      "Epoch [8320/10000], Loss: 0.0385\n",
      "Epoch [8330/10000], Loss: 0.0385\n",
      "Epoch [8340/10000], Loss: 0.0385\n",
      "Epoch [8350/10000], Loss: 0.0385\n",
      "Epoch [8360/10000], Loss: 0.0384\n",
      "Epoch [8370/10000], Loss: 0.0385\n",
      "Epoch [8380/10000], Loss: 0.0385\n",
      "Epoch [8390/10000], Loss: 0.0385\n",
      "Epoch [8400/10000], Loss: 0.0385\n",
      "Epoch [8410/10000], Loss: 0.0385\n",
      "Epoch [8420/10000], Loss: 0.0385\n",
      "Epoch [8430/10000], Loss: 0.0385\n",
      "Epoch [8440/10000], Loss: 0.0385\n",
      "Epoch [8450/10000], Loss: 0.0385\n",
      "Epoch [8460/10000], Loss: 0.0385\n",
      "Epoch [8470/10000], Loss: 0.0385\n",
      "Epoch [8480/10000], Loss: 0.0384\n",
      "Epoch [8490/10000], Loss: 0.0385\n",
      "Epoch [8500/10000], Loss: 0.0385\n",
      "Epoch [8510/10000], Loss: 0.0384\n",
      "Epoch [8520/10000], Loss: 0.0385\n",
      "Epoch [8530/10000], Loss: 0.0385\n",
      "Epoch [8540/10000], Loss: 0.0385\n",
      "Epoch [8550/10000], Loss: 0.0385\n",
      "Epoch [8560/10000], Loss: 0.0384\n",
      "Epoch [8570/10000], Loss: 0.0385\n",
      "Epoch [8580/10000], Loss: 0.0385\n",
      "Epoch [8590/10000], Loss: 0.0385\n",
      "Epoch [8600/10000], Loss: 0.0385\n",
      "Epoch [8610/10000], Loss: 0.0385\n",
      "Epoch [8620/10000], Loss: 0.0385\n",
      "Epoch [8630/10000], Loss: 0.0385\n",
      "Epoch [8640/10000], Loss: 0.0385\n",
      "Epoch [8650/10000], Loss: 0.0385\n",
      "Epoch [8660/10000], Loss: 0.0385\n",
      "Epoch [8670/10000], Loss: 0.0385\n",
      "Epoch [8680/10000], Loss: 0.0385\n",
      "Epoch [8690/10000], Loss: 0.0385\n",
      "Epoch [8700/10000], Loss: 0.0384\n",
      "Epoch [8710/10000], Loss: 0.0385\n",
      "Epoch [8720/10000], Loss: 0.0385\n",
      "Epoch [8730/10000], Loss: 0.0385\n",
      "Epoch [8740/10000], Loss: 0.0385\n",
      "Epoch [8750/10000], Loss: 0.0385\n",
      "Epoch [8760/10000], Loss: 0.0385\n",
      "Epoch [8770/10000], Loss: 0.0385\n",
      "Epoch [8780/10000], Loss: 0.0385\n",
      "Epoch [8790/10000], Loss: 0.0385\n",
      "Epoch [8800/10000], Loss: 0.0385\n",
      "Epoch [8810/10000], Loss: 0.0385\n",
      "Epoch [8820/10000], Loss: 0.0385\n",
      "Epoch [8830/10000], Loss: 0.0385\n",
      "Epoch [8840/10000], Loss: 0.0385\n",
      "Epoch [8850/10000], Loss: 0.0385\n",
      "Epoch [8860/10000], Loss: 0.0385\n",
      "Epoch [8870/10000], Loss: 0.0384\n",
      "Epoch [8880/10000], Loss: 0.0384\n",
      "Epoch [8890/10000], Loss: 0.0385\n",
      "Epoch [8900/10000], Loss: 0.0384\n",
      "Epoch [8910/10000], Loss: 0.0384\n",
      "Epoch [8920/10000], Loss: 0.0385\n",
      "Epoch [8930/10000], Loss: 0.0385\n",
      "Epoch [8940/10000], Loss: 0.0385\n",
      "Epoch [8950/10000], Loss: 0.0385\n",
      "Epoch [8960/10000], Loss: 0.0385\n",
      "Epoch [8970/10000], Loss: 0.0385\n",
      "Epoch [8980/10000], Loss: 0.0384\n",
      "Epoch [8990/10000], Loss: 0.0385\n",
      "Epoch [9000/10000], Loss: 0.0385\n",
      "Epoch [9010/10000], Loss: 0.0385\n",
      "Epoch [9020/10000], Loss: 0.0385\n",
      "Epoch [9030/10000], Loss: 0.0385\n",
      "Epoch [9040/10000], Loss: 0.0384\n",
      "Epoch [9050/10000], Loss: 0.0385\n",
      "Epoch [9060/10000], Loss: 0.0385\n",
      "Epoch [9070/10000], Loss: 0.0385\n",
      "Epoch [9080/10000], Loss: 0.0384\n",
      "Epoch [9090/10000], Loss: 0.0384\n",
      "Epoch [9100/10000], Loss: 0.0385\n",
      "Epoch [9110/10000], Loss: 0.0384\n",
      "Epoch [9120/10000], Loss: 0.0385\n",
      "Epoch [9130/10000], Loss: 0.0385\n",
      "Epoch [9140/10000], Loss: 0.0384\n",
      "Epoch [9150/10000], Loss: 0.0385\n",
      "Epoch [9160/10000], Loss: 0.0385\n",
      "Epoch [9170/10000], Loss: 0.0384\n",
      "Epoch [9180/10000], Loss: 0.0384\n",
      "Epoch [9190/10000], Loss: 0.0385\n",
      "Epoch [9200/10000], Loss: 0.0385\n",
      "Epoch [9210/10000], Loss: 0.0384\n",
      "Epoch [9220/10000], Loss: 0.0384\n",
      "Epoch [9230/10000], Loss: 0.0385\n",
      "Epoch [9240/10000], Loss: 0.0384\n",
      "Epoch [9250/10000], Loss: 0.0385\n",
      "Epoch [9260/10000], Loss: 0.0385\n",
      "Epoch [9270/10000], Loss: 0.0385\n",
      "Epoch [9280/10000], Loss: 0.0384\n",
      "Epoch [9290/10000], Loss: 0.0384\n",
      "Epoch [9300/10000], Loss: 0.0385\n",
      "Epoch [9310/10000], Loss: 0.0384\n",
      "Epoch [9320/10000], Loss: 0.0385\n",
      "Epoch [9330/10000], Loss: 0.0384\n",
      "Epoch [9340/10000], Loss: 0.0385\n",
      "Epoch [9350/10000], Loss: 0.0385\n",
      "Epoch [9360/10000], Loss: 0.0385\n",
      "Epoch [9370/10000], Loss: 0.0385\n",
      "Epoch [9380/10000], Loss: 0.0385\n",
      "Epoch [9390/10000], Loss: 0.0384\n",
      "Epoch [9400/10000], Loss: 0.0384\n",
      "Epoch [9410/10000], Loss: 0.0385\n",
      "Epoch [9420/10000], Loss: 0.0385\n",
      "Epoch [9430/10000], Loss: 0.0384\n",
      "Epoch [9440/10000], Loss: 0.0384\n",
      "Epoch [9450/10000], Loss: 0.0385\n",
      "Epoch [9460/10000], Loss: 0.0384\n",
      "Epoch [9470/10000], Loss: 0.0385\n",
      "Epoch [9480/10000], Loss: 0.0384\n",
      "Epoch [9490/10000], Loss: 0.0384\n",
      "Epoch [9500/10000], Loss: 0.0384\n",
      "Epoch [9510/10000], Loss: 0.0384\n",
      "Epoch [9520/10000], Loss: 0.0385\n",
      "Epoch [9530/10000], Loss: 0.0385\n",
      "Epoch [9540/10000], Loss: 0.0384\n",
      "Epoch [9550/10000], Loss: 0.0384\n",
      "Epoch [9560/10000], Loss: 0.0385\n",
      "Epoch [9570/10000], Loss: 0.0385\n",
      "Epoch [9580/10000], Loss: 0.0384\n",
      "Epoch [9590/10000], Loss: 0.0384\n",
      "Epoch [9600/10000], Loss: 0.0385\n",
      "Epoch [9610/10000], Loss: 0.0385\n",
      "Epoch [9620/10000], Loss: 0.0385\n",
      "Epoch [9630/10000], Loss: 0.0385\n",
      "Epoch [9640/10000], Loss: 0.0385\n",
      "Epoch [9650/10000], Loss: 0.0385\n",
      "Epoch [9660/10000], Loss: 0.0385\n",
      "Epoch [9670/10000], Loss: 0.0385\n",
      "Epoch [9680/10000], Loss: 0.0384\n",
      "Epoch [9690/10000], Loss: 0.0384\n",
      "Epoch [9700/10000], Loss: 0.0385\n",
      "Epoch [9710/10000], Loss: 0.0384\n",
      "Epoch [9720/10000], Loss: 0.0384\n",
      "Epoch [9730/10000], Loss: 0.0385\n",
      "Epoch [9740/10000], Loss: 0.0384\n",
      "Epoch [9750/10000], Loss: 0.0384\n",
      "Epoch [9760/10000], Loss: 0.0384\n",
      "Epoch [9770/10000], Loss: 0.0384\n",
      "Epoch [9780/10000], Loss: 0.0384\n",
      "Epoch [9790/10000], Loss: 0.0385\n",
      "Epoch [9800/10000], Loss: 0.0384\n",
      "Epoch [9810/10000], Loss: 0.0384\n",
      "Epoch [9820/10000], Loss: 0.0384\n",
      "Epoch [9830/10000], Loss: 0.0385\n",
      "Epoch [9840/10000], Loss: 0.0384\n",
      "Epoch [9850/10000], Loss: 0.0384\n",
      "Epoch [9860/10000], Loss: 0.0384\n",
      "Epoch [9870/10000], Loss: 0.0384\n",
      "Epoch [9880/10000], Loss: 0.0384\n",
      "Epoch [9890/10000], Loss: 0.0384\n",
      "Epoch [9900/10000], Loss: 0.0384\n",
      "Epoch [9910/10000], Loss: 0.0384\n",
      "Epoch [9920/10000], Loss: 0.0384\n",
      "Epoch [9930/10000], Loss: 0.0385\n",
      "Epoch [9940/10000], Loss: 0.0384\n",
      "Epoch [9950/10000], Loss: 0.0384\n",
      "Epoch [9960/10000], Loss: 0.0384\n",
      "Epoch [9970/10000], Loss: 0.0384\n",
      "Epoch [9980/10000], Loss: 0.0384\n",
      "Epoch [9990/10000], Loss: 0.0384\n",
      "Epoch [10000/10000], Loss: 0.0385\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"softmax_classifier_stable_active_adult.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n",
      "torch.return_types.max(\n",
      "values=tensor([3.0225e-05]),\n",
      "indices=tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, y_pred_tensor = torch.max(test_outputs, 1)\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "    # Calculate accuracyI have\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    print(\n",
    "        torch.max(\n",
    "            model(\n",
    "                torch.tensor(\n",
    "                    scaler.fit_transform(X[0].reshape(1, -1)), dtype=torch.float32\n",
    "                )\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class ElasticNetLoss(nn.Module):\n",
    "    def __init__(self, model, alpha=1.0, l1_ratio=0.5):\n",
    "        super(ElasticNetLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        ce_loss = self.cross_entropy_loss(outputs, targets)\n",
    "        l1_norm = sum(param.abs().sum() for param in self.model.parameters())\n",
    "        l2_norm = sum(param.pow(2).sum() for param in self.model.parameters())\n",
    "        elastic_net_penalty = self.alpha * (\n",
    "            self.l1_ratio * l1_norm + (1 - self.l1_ratio) * l2_norm\n",
    "        )\n",
    "        return ce_loss + elastic_net_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df1 = pd.read_excel(\n",
    "    \"/home/gddaslab/mxp140/sclerosis_project/miRNA_signal_hsa_number2.xlsx\",\n",
    "    engine=\"openpyxl\",\n",
    "    sheet_name=\"Sheet1\",\n",
    ")\n",
    "\n",
    "# Drop non-feature columns\n",
    "df = df1.drop(columns=[\"ID\", \"Transcript_ID\"])\n",
    "df = df.iloc[:, 10:]\n",
    "\n",
    "# Label the columns based on their types\n",
    "labels = {\"aHC\": 0, \"sMS\": 1, \"aMS\": 2, \"aPOMS\": 3, \"sPOMS\": 4, \"pBar\": 5}\n",
    "\n",
    "# Create target labels for each column\n",
    "y = []\n",
    "for col in df.columns:\n",
    "    for key in labels.keys():\n",
    "        if col.startswith(key):\n",
    "            y.append(labels[key])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for the cross-validation\n",
    "n_folds = 4\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to store the best model and its accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to tensor\n",
    "X = df.T.values\n",
    "y = y\n",
    "\n",
    "# Convert the entire dataset to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "Epoch [10/10000], Loss: 55.6817\n",
      "Epoch [20/10000], Loss: 63.2771\n",
      "Epoch [30/10000], Loss: 21.8486\n",
      "Epoch [40/10000], Loss: 15.1776\n",
      "Epoch [50/10000], Loss: 69.6757\n",
      "Epoch [60/10000], Loss: 25.2206\n",
      "Epoch [70/10000], Loss: 1.0683\n",
      "Epoch [80/10000], Loss: 1.0437\n",
      "Epoch [90/10000], Loss: 1.0196\n",
      "Epoch [100/10000], Loss: 0.9959\n",
      "Epoch [110/10000], Loss: 0.9726\n",
      "Epoch [120/10000], Loss: 0.9497\n",
      "Epoch [130/10000], Loss: 0.9273\n",
      "Epoch [140/10000], Loss: 0.9052\n",
      "Epoch [150/10000], Loss: 0.8836\n",
      "Epoch [160/10000], Loss: 0.8623\n",
      "Epoch [170/10000], Loss: 0.8415\n",
      "Epoch [180/10000], Loss: 0.8210\n",
      "Epoch [190/10000], Loss: 0.8010\n",
      "Epoch [200/10000], Loss: 0.7814\n",
      "Epoch [210/10000], Loss: 0.7622\n",
      "Epoch [220/10000], Loss: 0.7433\n",
      "Epoch [230/10000], Loss: 0.7248\n",
      "Epoch [240/10000], Loss: 0.7067\n",
      "Epoch [250/10000], Loss: 0.6889\n",
      "Epoch [260/10000], Loss: 0.6715\n",
      "Epoch [270/10000], Loss: 0.6545\n",
      "Epoch [280/10000], Loss: 0.6379\n",
      "Epoch [290/10000], Loss: 0.6216\n",
      "Epoch [300/10000], Loss: 0.6058\n",
      "Epoch [310/10000], Loss: 0.5903\n",
      "Epoch [320/10000], Loss: 0.5751\n",
      "Epoch [330/10000], Loss: 0.5603\n",
      "Epoch [340/10000], Loss: 0.5458\n",
      "Epoch [350/10000], Loss: 0.5317\n",
      "Epoch [360/10000], Loss: 0.5178\n",
      "Epoch [370/10000], Loss: 0.5043\n",
      "Epoch [380/10000], Loss: 0.4911\n",
      "Epoch [390/10000], Loss: 0.4782\n",
      "Epoch [400/10000], Loss: 0.4656\n",
      "Epoch [410/10000], Loss: 0.4533\n",
      "Epoch [420/10000], Loss: 0.4412\n",
      "Epoch [430/10000], Loss: 0.4295\n",
      "Epoch [440/10000], Loss: 0.4180\n",
      "Epoch [450/10000], Loss: 0.4068\n",
      "Epoch [460/10000], Loss: 0.3959\n",
      "Epoch [470/10000], Loss: 0.3853\n",
      "Epoch [480/10000], Loss: 0.3749\n",
      "Epoch [490/10000], Loss: 0.3647\n",
      "Epoch [500/10000], Loss: 0.3548\n",
      "Epoch [510/10000], Loss: 0.3451\n",
      "Epoch [520/10000], Loss: 0.3356\n",
      "Epoch [530/10000], Loss: 0.3264\n",
      "Epoch [540/10000], Loss: 0.3174\n",
      "Epoch [550/10000], Loss: 0.3086\n",
      "Epoch [560/10000], Loss: 0.3001\n",
      "Epoch [570/10000], Loss: 0.2918\n",
      "Epoch [580/10000], Loss: 0.2836\n",
      "Epoch [590/10000], Loss: 0.2757\n",
      "Epoch [600/10000], Loss: 0.2679\n",
      "Epoch [610/10000], Loss: 0.2604\n",
      "Epoch [620/10000], Loss: 0.2531\n",
      "Epoch [630/10000], Loss: 0.2460\n",
      "Epoch [640/10000], Loss: 0.2390\n",
      "Epoch [650/10000], Loss: 0.2323\n",
      "Epoch [660/10000], Loss: 0.2258\n",
      "Epoch [670/10000], Loss: 0.2195\n",
      "Epoch [680/10000], Loss: 0.2133\n",
      "Epoch [690/10000], Loss: 0.2072\n",
      "Epoch [700/10000], Loss: 0.2014\n",
      "Epoch [710/10000], Loss: 0.1957\n",
      "Epoch [720/10000], Loss: 0.1902\n",
      "Epoch [730/10000], Loss: 0.1848\n",
      "Epoch [740/10000], Loss: 0.1796\n",
      "Epoch [750/10000], Loss: 0.1747\n",
      "Epoch [760/10000], Loss: 0.1698\n",
      "Epoch [770/10000], Loss: 0.1651\n",
      "Epoch [780/10000], Loss: 0.1606\n",
      "Epoch [790/10000], Loss: 0.1563\n",
      "Epoch [800/10000], Loss: 0.1521\n",
      "Epoch [810/10000], Loss: 0.1481\n",
      "Epoch [820/10000], Loss: 0.1442\n",
      "Epoch [830/10000], Loss: 0.1405\n",
      "Epoch [840/10000], Loss: 0.1370\n",
      "Epoch [850/10000], Loss: 0.1335\n",
      "Epoch [860/10000], Loss: 0.1303\n",
      "Epoch [870/10000], Loss: 0.1271\n",
      "Epoch [880/10000], Loss: 0.1244\n",
      "Epoch [890/10000], Loss: 63.9442\n",
      "Epoch [900/10000], Loss: 21.8591\n",
      "Epoch [910/10000], Loss: 18.2960\n",
      "Epoch [920/10000], Loss: 73.1790\n",
      "Epoch [930/10000], Loss: 25.3743\n",
      "Epoch [940/10000], Loss: 23.1436\n",
      "Epoch [950/10000], Loss: 62.3683\n",
      "Epoch [960/10000], Loss: 1.2805\n",
      "Epoch [970/10000], Loss: 1.2554\n",
      "Epoch [980/10000], Loss: 1.2308\n",
      "Epoch [990/10000], Loss: 1.2066\n",
      "Epoch [1000/10000], Loss: 1.1829\n",
      "Epoch [1010/10000], Loss: 1.1596\n",
      "Epoch [1020/10000], Loss: 1.1367\n",
      "Epoch [1030/10000], Loss: 1.1141\n",
      "Epoch [1040/10000], Loss: 1.0919\n",
      "Epoch [1050/10000], Loss: 1.0701\n",
      "Epoch [1060/10000], Loss: 1.0487\n",
      "Epoch [1070/10000], Loss: 1.0276\n",
      "Epoch [1080/10000], Loss: 1.0069\n",
      "Epoch [1090/10000], Loss: 0.9866\n",
      "Epoch [1100/10000], Loss: 0.9666\n",
      "Epoch [1110/10000], Loss: 0.9470\n",
      "Epoch [1120/10000], Loss: 0.9277\n",
      "Epoch [1130/10000], Loss: 0.9087\n",
      "Epoch [1140/10000], Loss: 0.8900\n",
      "Epoch [1150/10000], Loss: 0.8717\n",
      "Epoch [1160/10000], Loss: 0.8537\n",
      "Epoch [1170/10000], Loss: 0.8361\n",
      "Epoch [1180/10000], Loss: 0.8188\n",
      "Epoch [1190/10000], Loss: 0.8018\n",
      "Epoch [1200/10000], Loss: 0.7852\n",
      "Epoch [1210/10000], Loss: 0.7690\n",
      "Epoch [1220/10000], Loss: 0.7531\n",
      "Epoch [1230/10000], Loss: 0.7375\n",
      "Epoch [1240/10000], Loss: 0.7223\n",
      "Epoch [1250/10000], Loss: 0.7074\n",
      "Epoch [1260/10000], Loss: 0.6929\n",
      "Epoch [1270/10000], Loss: 0.6786\n",
      "Epoch [1280/10000], Loss: 0.6647\n",
      "Epoch [1290/10000], Loss: 0.6510\n",
      "Epoch [1300/10000], Loss: 0.6375\n",
      "Epoch [1310/10000], Loss: 0.6243\n",
      "Epoch [1320/10000], Loss: 0.6115\n",
      "Epoch [1330/10000], Loss: 0.5990\n",
      "Epoch [1340/10000], Loss: 0.5867\n",
      "Epoch [1350/10000], Loss: 0.5748\n",
      "Epoch [1360/10000], Loss: 0.5631\n",
      "Epoch [1370/10000], Loss: 0.5518\n",
      "Epoch [1380/10000], Loss: 0.5407\n",
      "Epoch [1390/10000], Loss: 0.5300\n",
      "Epoch [1400/10000], Loss: 0.5195\n",
      "Epoch [1410/10000], Loss: 0.5092\n",
      "Epoch [1420/10000], Loss: 0.4991\n",
      "Epoch [1430/10000], Loss: 0.4893\n",
      "Epoch [1440/10000], Loss: 0.4797\n",
      "Epoch [1450/10000], Loss: 0.4703\n",
      "Epoch [1460/10000], Loss: 0.4610\n",
      "Epoch [1470/10000], Loss: 0.4521\n",
      "Epoch [1480/10000], Loss: 0.4433\n",
      "Epoch [1490/10000], Loss: 0.4348\n",
      "Epoch [1500/10000], Loss: 0.4264\n",
      "Epoch [1510/10000], Loss: 0.4182\n",
      "Epoch [1520/10000], Loss: 0.4102\n",
      "Epoch [1530/10000], Loss: 0.4024\n",
      "Epoch [1540/10000], Loss: 0.3949\n",
      "Epoch [1550/10000], Loss: 0.3875\n",
      "Epoch [1560/10000], Loss: 0.3803\n",
      "Epoch [1570/10000], Loss: 0.3733\n",
      "Epoch [1580/10000], Loss: 0.3664\n",
      "Epoch [1590/10000], Loss: 0.3598\n",
      "Epoch [1600/10000], Loss: 0.3533\n",
      "Epoch [1610/10000], Loss: 0.3469\n",
      "Epoch [1620/10000], Loss: 0.3407\n",
      "Epoch [1630/10000], Loss: 0.3347\n",
      "Epoch [1640/10000], Loss: 0.3288\n",
      "Epoch [1650/10000], Loss: 0.3230\n",
      "Epoch [1660/10000], Loss: 0.3174\n",
      "Epoch [1670/10000], Loss: 0.3118\n",
      "Epoch [1680/10000], Loss: 0.3064\n",
      "Epoch [1690/10000], Loss: 0.3011\n",
      "Epoch [1700/10000], Loss: 0.2958\n",
      "Epoch [1710/10000], Loss: 0.2907\n",
      "Epoch [1720/10000], Loss: 0.2857\n",
      "Epoch [1730/10000], Loss: 0.2808\n",
      "Epoch [1740/10000], Loss: 0.2760\n",
      "Epoch [1750/10000], Loss: 0.2713\n",
      "Epoch [1760/10000], Loss: 0.2667\n",
      "Epoch [1770/10000], Loss: 0.2622\n",
      "Epoch [1780/10000], Loss: 0.2578\n",
      "Epoch [1790/10000], Loss: 0.2534\n",
      "Epoch [1800/10000], Loss: 0.2492\n",
      "Epoch [1810/10000], Loss: 0.2450\n",
      "Epoch [1820/10000], Loss: 0.2410\n",
      "Epoch [1830/10000], Loss: 0.2370\n",
      "Epoch [1840/10000], Loss: 0.2331\n",
      "Epoch [1850/10000], Loss: 0.2293\n",
      "Epoch [1860/10000], Loss: 0.2256\n",
      "Epoch [1870/10000], Loss: 0.2220\n",
      "Epoch [1880/10000], Loss: 0.2184\n",
      "Epoch [1890/10000], Loss: 0.2149\n",
      "Epoch [1900/10000], Loss: 0.2114\n",
      "Epoch [1910/10000], Loss: 0.2081\n",
      "Epoch [1920/10000], Loss: 0.2048\n",
      "Epoch [1930/10000], Loss: 0.2015\n",
      "Epoch [1940/10000], Loss: 0.1984\n",
      "Epoch [1950/10000], Loss: 0.1952\n",
      "Epoch [1960/10000], Loss: 0.1922\n",
      "Epoch [1970/10000], Loss: 0.1892\n",
      "Epoch [1980/10000], Loss: 0.1862\n",
      "Epoch [1990/10000], Loss: 0.1833\n",
      "Epoch [2000/10000], Loss: 0.1804\n",
      "Epoch [2010/10000], Loss: 0.1776\n",
      "Epoch [2020/10000], Loss: 0.1748\n",
      "Epoch [2030/10000], Loss: 0.1721\n",
      "Epoch [2040/10000], Loss: 0.1694\n",
      "Epoch [2050/10000], Loss: 0.1667\n",
      "Epoch [2060/10000], Loss: 0.1641\n",
      "Epoch [2070/10000], Loss: 0.1616\n",
      "Epoch [2080/10000], Loss: 0.1590\n",
      "Epoch [2090/10000], Loss: 0.1566\n",
      "Epoch [2100/10000], Loss: 0.1542\n",
      "Epoch [2110/10000], Loss: 0.1518\n",
      "Epoch [2120/10000], Loss: 0.1494\n",
      "Epoch [2130/10000], Loss: 0.1471\n",
      "Epoch [2140/10000], Loss: 0.1449\n",
      "Epoch [2150/10000], Loss: 0.1426\n",
      "Epoch [2160/10000], Loss: 0.1404\n",
      "Epoch [2170/10000], Loss: 0.1383\n",
      "Epoch [2180/10000], Loss: 0.1362\n",
      "Epoch [2190/10000], Loss: 0.1341\n",
      "Epoch [2200/10000], Loss: 0.1320\n",
      "Epoch [2210/10000], Loss: 0.1300\n",
      "Epoch [2220/10000], Loss: 0.1280\n",
      "Epoch [2230/10000], Loss: 0.1261\n",
      "Epoch [2240/10000], Loss: 0.1242\n",
      "Epoch [2250/10000], Loss: 0.1223\n",
      "Epoch [2260/10000], Loss: 0.1205\n",
      "Epoch [2270/10000], Loss: 0.1187\n",
      "Epoch [2280/10000], Loss: 0.1169\n",
      "Epoch [2290/10000], Loss: 0.1152\n",
      "Epoch [2300/10000], Loss: 0.1136\n",
      "Epoch [2310/10000], Loss: 0.1119\n",
      "Epoch [2320/10000], Loss: 0.1103\n",
      "Epoch [2330/10000], Loss: 0.1087\n",
      "Epoch [2340/10000], Loss: 0.1072\n",
      "Epoch [2350/10000], Loss: 0.1057\n",
      "Epoch [2360/10000], Loss: 0.1043\n",
      "Epoch [2370/10000], Loss: 0.1029\n",
      "Epoch [2380/10000], Loss: 0.1015\n",
      "Epoch [2390/10000], Loss: 0.1002\n",
      "Epoch [2400/10000], Loss: 0.1026\n",
      "Epoch [2410/10000], Loss: 6.9690\n",
      "Epoch [2420/10000], Loss: 51.3177\n",
      "Epoch [2430/10000], Loss: 59.1643\n",
      "Epoch [2440/10000], Loss: 17.9271\n",
      "Epoch [2450/10000], Loss: 10.3606\n",
      "Epoch [2460/10000], Loss: 55.2747\n",
      "Epoch [2470/10000], Loss: 14.4235\n",
      "Epoch [2480/10000], Loss: 12.7892\n",
      "Epoch [2490/10000], Loss: 56.6737\n",
      "Epoch [2500/10000], Loss: 1.6198\n",
      "Epoch [2510/10000], Loss: 1.5940\n",
      "Epoch [2520/10000], Loss: 1.5686\n",
      "Epoch [2530/10000], Loss: 1.5434\n",
      "Epoch [2540/10000], Loss: 1.5186\n",
      "Epoch [2550/10000], Loss: 1.4942\n",
      "Epoch [2560/10000], Loss: 1.4701\n",
      "Epoch [2570/10000], Loss: 1.4464\n",
      "Epoch [2580/10000], Loss: 1.4230\n",
      "Epoch [2590/10000], Loss: 1.4000\n",
      "Epoch [2600/10000], Loss: 1.3774\n",
      "Epoch [2610/10000], Loss: 1.3550\n",
      "Epoch [2620/10000], Loss: 1.3330\n",
      "Epoch [2630/10000], Loss: 1.3112\n",
      "Epoch [2640/10000], Loss: 1.2898\n",
      "Epoch [2650/10000], Loss: 1.2687\n",
      "Epoch [2660/10000], Loss: 1.2479\n",
      "Epoch [2670/10000], Loss: 1.2274\n",
      "Epoch [2680/10000], Loss: 1.2072\n",
      "Epoch [2690/10000], Loss: 1.1872\n",
      "Epoch [2700/10000], Loss: 1.1676\n",
      "Epoch [2710/10000], Loss: 1.1482\n",
      "Epoch [2720/10000], Loss: 1.1292\n",
      "Epoch [2730/10000], Loss: 1.1105\n",
      "Epoch [2740/10000], Loss: 1.0921\n",
      "Epoch [2750/10000], Loss: 1.0740\n",
      "Epoch [2760/10000], Loss: 1.0561\n",
      "Epoch [2770/10000], Loss: 1.0385\n",
      "Epoch [2780/10000], Loss: 1.0212\n",
      "Epoch [2790/10000], Loss: 1.0041\n",
      "Epoch [2800/10000], Loss: 0.9872\n",
      "Epoch [2810/10000], Loss: 0.9706\n",
      "Epoch [2820/10000], Loss: 0.9543\n",
      "Epoch [2830/10000], Loss: 0.9382\n",
      "Epoch [2840/10000], Loss: 0.9224\n",
      "Epoch [2850/10000], Loss: 0.9068\n",
      "Epoch [2860/10000], Loss: 0.8915\n",
      "Epoch [2870/10000], Loss: 0.8766\n",
      "Epoch [2880/10000], Loss: 0.8619\n",
      "Epoch [2890/10000], Loss: 0.8474\n",
      "Epoch [2900/10000], Loss: 0.8332\n",
      "Epoch [2910/10000], Loss: 0.8192\n",
      "Epoch [2920/10000], Loss: 0.8054\n",
      "Epoch [2930/10000], Loss: 0.7919\n",
      "Epoch [2940/10000], Loss: 0.7785\n",
      "Epoch [2950/10000], Loss: 0.7653\n",
      "Epoch [2960/10000], Loss: 0.7524\n",
      "Epoch [2970/10000], Loss: 0.7398\n",
      "Epoch [2980/10000], Loss: 0.7273\n",
      "Epoch [2990/10000], Loss: 0.7151\n",
      "Epoch [3000/10000], Loss: 0.7031\n",
      "Epoch [3010/10000], Loss: 0.6913\n",
      "Epoch [3020/10000], Loss: 0.6797\n",
      "Epoch [3030/10000], Loss: 0.6683\n",
      "Epoch [3040/10000], Loss: 0.6571\n",
      "Epoch [3050/10000], Loss: 0.6461\n",
      "Epoch [3060/10000], Loss: 0.6353\n",
      "Epoch [3070/10000], Loss: 0.6247\n",
      "Epoch [3080/10000], Loss: 0.6143\n",
      "Epoch [3090/10000], Loss: 0.6040\n",
      "Epoch [3100/10000], Loss: 0.5939\n",
      "Epoch [3110/10000], Loss: 0.5840\n",
      "Epoch [3120/10000], Loss: 0.5742\n",
      "Epoch [3130/10000], Loss: 0.5646\n",
      "Epoch [3140/10000], Loss: 0.5551\n",
      "Epoch [3150/10000], Loss: 0.5459\n",
      "Epoch [3160/10000], Loss: 0.5368\n",
      "Epoch [3170/10000], Loss: 0.5279\n",
      "Epoch [3180/10000], Loss: 0.5191\n",
      "Epoch [3190/10000], Loss: 0.5105\n",
      "Epoch [3200/10000], Loss: 0.5020\n",
      "Epoch [3210/10000], Loss: 0.4937\n",
      "Epoch [3220/10000], Loss: 0.4855\n",
      "Epoch [3230/10000], Loss: 0.4775\n",
      "Epoch [3240/10000], Loss: 0.4696\n",
      "Epoch [3250/10000], Loss: 0.4619\n",
      "Epoch [3260/10000], Loss: 0.4544\n",
      "Epoch [3270/10000], Loss: 0.4471\n",
      "Epoch [3280/10000], Loss: 0.4398\n",
      "Epoch [3290/10000], Loss: 0.4327\n",
      "Epoch [3300/10000], Loss: 0.4258\n",
      "Epoch [3310/10000], Loss: 0.4190\n",
      "Epoch [3320/10000], Loss: 0.4123\n",
      "Epoch [3330/10000], Loss: 0.4057\n",
      "Epoch [3340/10000], Loss: 0.3992\n",
      "Epoch [3350/10000], Loss: 0.3930\n",
      "Epoch [3360/10000], Loss: 0.3868\n",
      "Epoch [3370/10000], Loss: 0.3807\n",
      "Epoch [3380/10000], Loss: 0.3747\n",
      "Epoch [3390/10000], Loss: 0.3689\n",
      "Epoch [3400/10000], Loss: 0.3631\n",
      "Epoch [3410/10000], Loss: 0.3575\n",
      "Epoch [3420/10000], Loss: 0.3520\n",
      "Epoch [3430/10000], Loss: 0.3465\n",
      "Epoch [3440/10000], Loss: 0.3411\n",
      "Epoch [3450/10000], Loss: 0.3358\n",
      "Epoch [3460/10000], Loss: 0.3306\n",
      "Epoch [3470/10000], Loss: 0.3255\n",
      "Epoch [3480/10000], Loss: 0.3204\n",
      "Epoch [3490/10000], Loss: 0.3155\n",
      "Epoch [3500/10000], Loss: 0.3107\n",
      "Epoch [3510/10000], Loss: 0.3060\n",
      "Epoch [3520/10000], Loss: 0.3013\n",
      "Epoch [3530/10000], Loss: 0.2967\n",
      "Epoch [3540/10000], Loss: 0.2922\n",
      "Epoch [3550/10000], Loss: 0.2878\n",
      "Epoch [3560/10000], Loss: 0.2835\n",
      "Epoch [3570/10000], Loss: 0.2792\n",
      "Epoch [3580/10000], Loss: 0.2750\n",
      "Epoch [3590/10000], Loss: 0.2709\n",
      "Epoch [3600/10000], Loss: 0.2669\n",
      "Epoch [3610/10000], Loss: 0.2630\n",
      "Epoch [3620/10000], Loss: 0.2592\n",
      "Epoch [3630/10000], Loss: 0.2554\n",
      "Epoch [3640/10000], Loss: 0.2517\n",
      "Epoch [3650/10000], Loss: 0.2481\n",
      "Epoch [3660/10000], Loss: 0.2446\n",
      "Epoch [3670/10000], Loss: 0.2412\n",
      "Epoch [3680/10000], Loss: 0.2378\n",
      "Epoch [3690/10000], Loss: 0.2345\n",
      "Epoch [3700/10000], Loss: 0.2313\n",
      "Epoch [3710/10000], Loss: 0.2281\n",
      "Epoch [3720/10000], Loss: 0.2250\n",
      "Epoch [3730/10000], Loss: 0.2220\n",
      "Epoch [3740/10000], Loss: 0.2190\n",
      "Epoch [3750/10000], Loss: 0.2161\n",
      "Epoch [3760/10000], Loss: 0.2133\n",
      "Epoch [3770/10000], Loss: 0.2104\n",
      "Epoch [3780/10000], Loss: 0.2077\n",
      "Epoch [3790/10000], Loss: 0.2049\n",
      "Epoch [3800/10000], Loss: 0.2022\n",
      "Epoch [3810/10000], Loss: 0.1996\n",
      "Epoch [3820/10000], Loss: 0.1970\n",
      "Epoch [3830/10000], Loss: 0.1944\n",
      "Epoch [3840/10000], Loss: 0.1919\n",
      "Epoch [3850/10000], Loss: 0.1895\n",
      "Epoch [3860/10000], Loss: 0.1871\n",
      "Epoch [3870/10000], Loss: 0.1848\n",
      "Epoch [3880/10000], Loss: 0.1824\n",
      "Epoch [3890/10000], Loss: 0.1802\n",
      "Epoch [3900/10000], Loss: 0.1779\n",
      "Epoch [3910/10000], Loss: 0.1757\n",
      "Epoch [3920/10000], Loss: 0.1735\n",
      "Epoch [3930/10000], Loss: 0.1714\n",
      "Epoch [3940/10000], Loss: 0.1694\n",
      "Epoch [3950/10000], Loss: 0.1673\n",
      "Epoch [3960/10000], Loss: 0.1653\n",
      "Epoch [3970/10000], Loss: 0.1634\n",
      "Epoch [3980/10000], Loss: 0.1615\n",
      "Epoch [3990/10000], Loss: 0.1596\n",
      "Epoch [4000/10000], Loss: 0.1577\n",
      "Epoch [4010/10000], Loss: 0.1559\n",
      "Epoch [4020/10000], Loss: 0.1541\n",
      "Epoch [4030/10000], Loss: 0.1523\n",
      "Epoch [4040/10000], Loss: 0.1505\n",
      "Epoch [4050/10000], Loss: 0.1489\n",
      "Epoch [4060/10000], Loss: 0.1472\n",
      "Epoch [4070/10000], Loss: 0.1455\n",
      "Epoch [4080/10000], Loss: 0.1439\n",
      "Epoch [4090/10000], Loss: 0.1423\n",
      "Epoch [4100/10000], Loss: 0.1408\n",
      "Epoch [4110/10000], Loss: 0.1392\n",
      "Epoch [4120/10000], Loss: 0.1377\n",
      "Epoch [4130/10000], Loss: 0.1362\n",
      "Epoch [4140/10000], Loss: 0.1347\n",
      "Epoch [4150/10000], Loss: 0.1332\n",
      "Epoch [4160/10000], Loss: 0.1317\n",
      "Epoch [4170/10000], Loss: 0.1303\n",
      "Epoch [4180/10000], Loss: 0.1289\n",
      "Epoch [4190/10000], Loss: 0.1275\n",
      "Epoch [4200/10000], Loss: 0.1261\n",
      "Epoch [4210/10000], Loss: 0.1248\n",
      "Epoch [4220/10000], Loss: 0.1234\n",
      "Epoch [4230/10000], Loss: 0.1221\n",
      "Epoch [4240/10000], Loss: 0.1208\n",
      "Epoch [4250/10000], Loss: 0.1195\n",
      "Epoch [4260/10000], Loss: 0.1182\n",
      "Epoch [4270/10000], Loss: 0.1169\n",
      "Epoch [4280/10000], Loss: 0.1157\n",
      "Epoch [4290/10000], Loss: 0.1145\n",
      "Epoch [4300/10000], Loss: 0.1132\n",
      "Epoch [4310/10000], Loss: 0.1120\n",
      "Epoch [4320/10000], Loss: 0.1109\n",
      "Epoch [4330/10000], Loss: 0.1097\n",
      "Epoch [4340/10000], Loss: 0.1086\n",
      "Epoch [4350/10000], Loss: 0.1075\n",
      "Epoch [4360/10000], Loss: 0.1064\n",
      "Epoch [4370/10000], Loss: 0.1053\n",
      "Epoch [4380/10000], Loss: 0.1042\n",
      "Epoch [4390/10000], Loss: 0.1032\n",
      "Epoch [4400/10000], Loss: 0.1022\n",
      "Epoch [4410/10000], Loss: 0.1012\n",
      "Epoch [4420/10000], Loss: 0.1002\n",
      "Epoch [4430/10000], Loss: 0.0993\n",
      "Epoch [4440/10000], Loss: 0.0983\n",
      "Epoch [4450/10000], Loss: 0.0975\n",
      "Epoch [4460/10000], Loss: 0.0966\n",
      "Epoch [4470/10000], Loss: 0.0957\n",
      "Epoch [4480/10000], Loss: 0.0948\n",
      "Epoch [4490/10000], Loss: 0.0940\n",
      "Epoch [4500/10000], Loss: 0.0932\n",
      "Epoch [4510/10000], Loss: 0.0924\n",
      "Epoch [4520/10000], Loss: 0.0917\n",
      "Epoch [4530/10000], Loss: 0.0911\n",
      "Epoch [4540/10000], Loss: 0.1041\n",
      "Epoch [4550/10000], Loss: 29.9204\n",
      "Epoch [4560/10000], Loss: 5.4709\n",
      "Epoch [4570/10000], Loss: 69.5889\n",
      "Epoch [4580/10000], Loss: 27.8492\n",
      "Epoch [4590/10000], Loss: 1.6925\n",
      "Epoch [4600/10000], Loss: 0.8926\n",
      "Epoch [4610/10000], Loss: 0.8686\n",
      "Epoch [4620/10000], Loss: 0.8452\n",
      "Epoch [4630/10000], Loss: 0.8223\n",
      "Epoch [4640/10000], Loss: 0.8001\n",
      "Epoch [4650/10000], Loss: 0.7784\n",
      "Epoch [4660/10000], Loss: 0.7572\n",
      "Epoch [4670/10000], Loss: 0.7366\n",
      "Epoch [4680/10000], Loss: 0.7166\n",
      "Epoch [4690/10000], Loss: 0.6971\n",
      "Epoch [4700/10000], Loss: 0.6781\n",
      "Epoch [4710/10000], Loss: 0.6596\n",
      "Epoch [4720/10000], Loss: 0.6415\n",
      "Epoch [4730/10000], Loss: 0.6239\n",
      "Epoch [4740/10000], Loss: 0.6069\n",
      "Epoch [4750/10000], Loss: 0.5902\n",
      "Epoch [4760/10000], Loss: 0.5740\n",
      "Epoch [4770/10000], Loss: 0.5582\n",
      "Epoch [4780/10000], Loss: 0.5428\n",
      "Epoch [4790/10000], Loss: 0.5278\n",
      "Epoch [4800/10000], Loss: 0.5133\n",
      "Epoch [4810/10000], Loss: 0.4992\n",
      "Epoch [4820/10000], Loss: 0.4855\n",
      "Epoch [4830/10000], Loss: 0.4722\n",
      "Epoch [4840/10000], Loss: 0.4592\n",
      "Epoch [4850/10000], Loss: 0.4466\n",
      "Epoch [4860/10000], Loss: 0.4344\n",
      "Epoch [4870/10000], Loss: 0.4226\n",
      "Epoch [4880/10000], Loss: 0.4112\n",
      "Epoch [4890/10000], Loss: 0.4001\n",
      "Epoch [4900/10000], Loss: 0.3894\n",
      "Epoch [4910/10000], Loss: 0.3791\n",
      "Epoch [4920/10000], Loss: 0.3690\n",
      "Epoch [4930/10000], Loss: 0.3593\n",
      "Epoch [4940/10000], Loss: 0.3499\n",
      "Epoch [4950/10000], Loss: 0.3407\n",
      "Epoch [4960/10000], Loss: 0.3318\n",
      "Epoch [4970/10000], Loss: 0.3233\n",
      "Epoch [4980/10000], Loss: 0.3150\n",
      "Epoch [4990/10000], Loss: 0.3070\n",
      "Epoch [5000/10000], Loss: 0.2992\n",
      "Epoch [5010/10000], Loss: 0.2916\n",
      "Epoch [5020/10000], Loss: 0.2844\n",
      "Epoch [5030/10000], Loss: 0.2774\n",
      "Epoch [5040/10000], Loss: 0.2707\n",
      "Epoch [5050/10000], Loss: 0.2641\n",
      "Epoch [5060/10000], Loss: 0.2578\n",
      "Epoch [5070/10000], Loss: 0.2518\n",
      "Epoch [5080/10000], Loss: 0.2459\n",
      "Epoch [5090/10000], Loss: 0.2402\n",
      "Epoch [5100/10000], Loss: 0.2347\n",
      "Epoch [5110/10000], Loss: 0.2294\n",
      "Epoch [5120/10000], Loss: 0.2242\n",
      "Epoch [5130/10000], Loss: 0.2191\n",
      "Epoch [5140/10000], Loss: 0.2143\n",
      "Epoch [5150/10000], Loss: 0.2096\n",
      "Epoch [5160/10000], Loss: 0.2050\n",
      "Epoch [5170/10000], Loss: 0.2005\n",
      "Epoch [5180/10000], Loss: 0.1963\n",
      "Epoch [5190/10000], Loss: 0.1921\n",
      "Epoch [5200/10000], Loss: 0.1881\n",
      "Epoch [5210/10000], Loss: 0.1843\n",
      "Epoch [5220/10000], Loss: 0.1805\n",
      "Epoch [5230/10000], Loss: 0.1769\n",
      "Epoch [5240/10000], Loss: 0.1735\n",
      "Epoch [5250/10000], Loss: 0.1702\n",
      "Epoch [5260/10000], Loss: 0.1669\n",
      "Epoch [5270/10000], Loss: 0.1638\n",
      "Epoch [5280/10000], Loss: 0.1608\n",
      "Epoch [5290/10000], Loss: 0.1579\n",
      "Epoch [5300/10000], Loss: 0.1551\n",
      "Epoch [5310/10000], Loss: 0.1524\n",
      "Epoch [5320/10000], Loss: 0.1498\n",
      "Epoch [5330/10000], Loss: 0.1472\n",
      "Epoch [5340/10000], Loss: 0.1447\n",
      "Epoch [5350/10000], Loss: 0.1423\n",
      "Epoch [5360/10000], Loss: 0.1400\n",
      "Epoch [5370/10000], Loss: 0.1378\n",
      "Epoch [5380/10000], Loss: 0.1357\n",
      "Epoch [5390/10000], Loss: 0.1335\n",
      "Epoch [5400/10000], Loss: 0.1315\n",
      "Epoch [5410/10000], Loss: 0.1296\n",
      "Epoch [5420/10000], Loss: 0.1277\n",
      "Epoch [5430/10000], Loss: 0.1259\n",
      "Epoch [5440/10000], Loss: 0.1242\n",
      "Epoch [5450/10000], Loss: 0.1225\n",
      "Epoch [5460/10000], Loss: 0.1209\n",
      "Epoch [5470/10000], Loss: 0.1194\n",
      "Epoch [5480/10000], Loss: 0.1179\n",
      "Epoch [5490/10000], Loss: 0.1165\n",
      "Epoch [5500/10000], Loss: 0.1152\n",
      "Epoch [5510/10000], Loss: 0.1139\n",
      "Epoch [5520/10000], Loss: 0.1126\n",
      "Epoch [5530/10000], Loss: 0.1113\n",
      "Epoch [5540/10000], Loss: 0.1101\n",
      "Epoch [5550/10000], Loss: 0.1089\n",
      "Epoch [5560/10000], Loss: 0.1078\n",
      "Epoch [5570/10000], Loss: 0.1067\n",
      "Epoch [5580/10000], Loss: 0.1057\n",
      "Epoch [5590/10000], Loss: 0.1047\n",
      "Epoch [5600/10000], Loss: 0.1037\n",
      "Epoch [5610/10000], Loss: 0.1028\n",
      "Epoch [5620/10000], Loss: 0.1019\n",
      "Epoch [5630/10000], Loss: 0.1010\n",
      "Epoch [5640/10000], Loss: 0.1001\n",
      "Epoch [5650/10000], Loss: 0.0993\n",
      "Epoch [5660/10000], Loss: 0.0985\n",
      "Epoch [5670/10000], Loss: 0.0976\n",
      "Epoch [5680/10000], Loss: 0.0969\n",
      "Epoch [5690/10000], Loss: 0.0961\n",
      "Epoch [5700/10000], Loss: 0.0953\n",
      "Epoch [5710/10000], Loss: 0.0946\n",
      "Epoch [5720/10000], Loss: 0.0938\n",
      "Epoch [5730/10000], Loss: 0.0931\n",
      "Epoch [5740/10000], Loss: 0.0924\n",
      "Epoch [5750/10000], Loss: 0.0917\n",
      "Epoch [5760/10000], Loss: 0.0911\n",
      "Epoch [5770/10000], Loss: 0.0905\n",
      "Epoch [5780/10000], Loss: 0.0898\n",
      "Epoch [5790/10000], Loss: 0.0893\n",
      "Epoch [5800/10000], Loss: 0.0893\n",
      "Epoch [5810/10000], Loss: 55.7620\n",
      "Epoch [5820/10000], Loss: 13.8199\n",
      "Epoch [5830/10000], Loss: 34.3058\n",
      "Epoch [5840/10000], Loss: 65.6821\n",
      "Epoch [5850/10000], Loss: 24.3853\n",
      "Epoch [5860/10000], Loss: 24.3853\n",
      "Epoch [5870/10000], Loss: 61.8649\n",
      "Epoch [5880/10000], Loss: 16.1160\n",
      "Epoch [5890/10000], Loss: 1.3915\n",
      "Epoch [5900/10000], Loss: 1.3661\n",
      "Epoch [5910/10000], Loss: 1.3412\n",
      "Epoch [5920/10000], Loss: 1.3166\n",
      "Epoch [5930/10000], Loss: 1.2923\n",
      "Epoch [5940/10000], Loss: 1.2684\n",
      "Epoch [5950/10000], Loss: 1.2449\n",
      "Epoch [5960/10000], Loss: 1.2217\n",
      "Epoch [5970/10000], Loss: 1.1990\n",
      "Epoch [5980/10000], Loss: 1.1767\n",
      "Epoch [5990/10000], Loss: 1.1549\n",
      "Epoch [6000/10000], Loss: 1.1334\n",
      "Epoch [6010/10000], Loss: 1.1123\n",
      "Epoch [6020/10000], Loss: 1.0916\n",
      "Epoch [6030/10000], Loss: 1.0713\n",
      "Epoch [6040/10000], Loss: 1.0513\n",
      "Epoch [6050/10000], Loss: 1.0316\n",
      "Epoch [6060/10000], Loss: 1.0123\n",
      "Epoch [6070/10000], Loss: 0.9933\n",
      "Epoch [6080/10000], Loss: 0.9746\n",
      "Epoch [6090/10000], Loss: 0.9563\n",
      "Epoch [6100/10000], Loss: 0.9383\n",
      "Epoch [6110/10000], Loss: 0.9207\n",
      "Epoch [6120/10000], Loss: 0.9032\n",
      "Epoch [6130/10000], Loss: 0.8862\n",
      "Epoch [6140/10000], Loss: 0.8694\n",
      "Epoch [6150/10000], Loss: 0.8528\n",
      "Epoch [6160/10000], Loss: 0.8366\n",
      "Epoch [6170/10000], Loss: 0.8205\n",
      "Epoch [6180/10000], Loss: 0.8048\n",
      "Epoch [6190/10000], Loss: 0.7894\n",
      "Epoch [6200/10000], Loss: 0.7743\n",
      "Epoch [6210/10000], Loss: 0.7595\n",
      "Epoch [6220/10000], Loss: 0.7450\n",
      "Epoch [6230/10000], Loss: 0.7307\n",
      "Epoch [6240/10000], Loss: 0.7167\n",
      "Epoch [6250/10000], Loss: 0.7030\n",
      "Epoch [6260/10000], Loss: 0.6895\n",
      "Epoch [6270/10000], Loss: 0.6763\n",
      "Epoch [6280/10000], Loss: 0.6632\n",
      "Epoch [6290/10000], Loss: 0.6505\n",
      "Epoch [6300/10000], Loss: 0.6380\n",
      "Epoch [6310/10000], Loss: 0.6258\n",
      "Epoch [6320/10000], Loss: 0.6138\n",
      "Epoch [6330/10000], Loss: 0.6021\n",
      "Epoch [6340/10000], Loss: 0.5906\n",
      "Epoch [6350/10000], Loss: 0.5793\n",
      "Epoch [6360/10000], Loss: 0.5683\n",
      "Epoch [6370/10000], Loss: 0.5575\n",
      "Epoch [6380/10000], Loss: 0.5469\n",
      "Epoch [6390/10000], Loss: 0.5365\n",
      "Epoch [6400/10000], Loss: 0.5263\n",
      "Epoch [6410/10000], Loss: 0.5164\n",
      "Epoch [6420/10000], Loss: 0.5066\n",
      "Epoch [6430/10000], Loss: 0.4970\n",
      "Epoch [6440/10000], Loss: 0.4876\n",
      "Epoch [6450/10000], Loss: 0.4783\n",
      "Epoch [6460/10000], Loss: 0.4693\n",
      "Epoch [6470/10000], Loss: 0.4604\n",
      "Epoch [6480/10000], Loss: 0.4518\n",
      "Epoch [6490/10000], Loss: 0.4433\n",
      "Epoch [6500/10000], Loss: 0.4350\n",
      "Epoch [6510/10000], Loss: 0.4268\n",
      "Epoch [6520/10000], Loss: 0.4188\n",
      "Epoch [6530/10000], Loss: 0.4110\n",
      "Epoch [6540/10000], Loss: 0.4034\n",
      "Epoch [6550/10000], Loss: 0.3960\n",
      "Epoch [6560/10000], Loss: 0.3888\n",
      "Epoch [6570/10000], Loss: 0.3817\n",
      "Epoch [6580/10000], Loss: 0.3747\n",
      "Epoch [6590/10000], Loss: 0.3680\n",
      "Epoch [6600/10000], Loss: 0.3613\n",
      "Epoch [6610/10000], Loss: 0.3548\n",
      "Epoch [6620/10000], Loss: 0.3485\n",
      "Epoch [6630/10000], Loss: 0.3423\n",
      "Epoch [6640/10000], Loss: 0.3363\n",
      "Epoch [6650/10000], Loss: 0.3303\n",
      "Epoch [6660/10000], Loss: 0.3245\n",
      "Epoch [6670/10000], Loss: 0.3188\n",
      "Epoch [6680/10000], Loss: 0.3133\n",
      "Epoch [6690/10000], Loss: 0.3078\n",
      "Epoch [6700/10000], Loss: 0.3024\n",
      "Epoch [6710/10000], Loss: 0.2971\n",
      "Epoch [6720/10000], Loss: 0.2920\n",
      "Epoch [6730/10000], Loss: 0.2869\n",
      "Epoch [6740/10000], Loss: 0.2820\n",
      "Epoch [6750/10000], Loss: 0.2771\n",
      "Epoch [6760/10000], Loss: 0.2723\n",
      "Epoch [6770/10000], Loss: 0.2677\n",
      "Epoch [6780/10000], Loss: 0.2631\n",
      "Epoch [6790/10000], Loss: 0.2587\n",
      "Epoch [6800/10000], Loss: 0.2543\n",
      "Epoch [6810/10000], Loss: 0.2501\n",
      "Epoch [6820/10000], Loss: 0.2459\n",
      "Epoch [6830/10000], Loss: 0.2418\n",
      "Epoch [6840/10000], Loss: 0.2378\n",
      "Epoch [6850/10000], Loss: 0.2338\n",
      "Epoch [6860/10000], Loss: 0.2300\n",
      "Epoch [6870/10000], Loss: 0.2263\n",
      "Epoch [6880/10000], Loss: 0.2227\n",
      "Epoch [6890/10000], Loss: 0.2191\n",
      "Epoch [6900/10000], Loss: 0.2157\n",
      "Epoch [6910/10000], Loss: 0.2124\n",
      "Epoch [6920/10000], Loss: 0.2091\n",
      "Epoch [6930/10000], Loss: 0.2059\n",
      "Epoch [6940/10000], Loss: 0.2028\n",
      "Epoch [6950/10000], Loss: 0.1997\n",
      "Epoch [6960/10000], Loss: 0.1967\n",
      "Epoch [6970/10000], Loss: 0.1938\n",
      "Epoch [6980/10000], Loss: 0.1910\n",
      "Epoch [6990/10000], Loss: 0.1882\n",
      "Epoch [7000/10000], Loss: 0.1854\n",
      "Epoch [7010/10000], Loss: 0.1827\n",
      "Epoch [7020/10000], Loss: 0.1801\n",
      "Epoch [7030/10000], Loss: 0.1775\n",
      "Epoch [7040/10000], Loss: 0.1750\n",
      "Epoch [7050/10000], Loss: 0.1725\n",
      "Epoch [7060/10000], Loss: 0.1701\n",
      "Epoch [7070/10000], Loss: 0.1677\n",
      "Epoch [7080/10000], Loss: 0.1654\n",
      "Epoch [7090/10000], Loss: 0.1631\n",
      "Epoch [7100/10000], Loss: 0.1609\n",
      "Epoch [7110/10000], Loss: 0.1587\n",
      "Epoch [7120/10000], Loss: 0.1566\n",
      "Epoch [7130/10000], Loss: 0.1545\n",
      "Epoch [7140/10000], Loss: 0.1524\n",
      "Epoch [7150/10000], Loss: 0.1505\n",
      "Epoch [7160/10000], Loss: 0.1485\n",
      "Epoch [7170/10000], Loss: 0.1466\n",
      "Epoch [7180/10000], Loss: 0.1448\n",
      "Epoch [7190/10000], Loss: 0.1430\n",
      "Epoch [7200/10000], Loss: 0.1412\n",
      "Epoch [7210/10000], Loss: 0.1395\n",
      "Epoch [7220/10000], Loss: 0.1378\n",
      "Epoch [7230/10000], Loss: 0.1362\n",
      "Epoch [7240/10000], Loss: 0.1346\n",
      "Epoch [7250/10000], Loss: 0.1331\n",
      "Epoch [7260/10000], Loss: 0.1316\n",
      "Epoch [7270/10000], Loss: 0.1302\n",
      "Epoch [7280/10000], Loss: 0.1287\n",
      "Epoch [7290/10000], Loss: 0.1273\n",
      "Epoch [7300/10000], Loss: 0.1259\n",
      "Epoch [7310/10000], Loss: 0.1246\n",
      "Epoch [7320/10000], Loss: 0.1233\n",
      "Epoch [7330/10000], Loss: 0.1219\n",
      "Epoch [7340/10000], Loss: 0.1206\n",
      "Epoch [7350/10000], Loss: 0.1194\n",
      "Epoch [7360/10000], Loss: 0.1182\n",
      "Epoch [7370/10000], Loss: 0.1170\n",
      "Epoch [7380/10000], Loss: 0.1158\n",
      "Epoch [7390/10000], Loss: 0.1146\n",
      "Epoch [7400/10000], Loss: 0.1135\n",
      "Epoch [7410/10000], Loss: 0.1125\n",
      "Epoch [7420/10000], Loss: 0.1114\n",
      "Epoch [7430/10000], Loss: 0.1104\n",
      "Epoch [7440/10000], Loss: 0.1094\n",
      "Epoch [7450/10000], Loss: 0.1085\n",
      "Epoch [7460/10000], Loss: 0.1076\n",
      "Epoch [7470/10000], Loss: 0.1067\n",
      "Epoch [7480/10000], Loss: 0.1059\n",
      "Epoch [7490/10000], Loss: 0.1051\n",
      "Epoch [7500/10000], Loss: 0.1043\n",
      "Epoch [7510/10000], Loss: 0.1035\n",
      "Epoch [7520/10000], Loss: 0.1027\n",
      "Epoch [7530/10000], Loss: 0.1020\n",
      "Epoch [7540/10000], Loss: 0.1012\n",
      "Epoch [7550/10000], Loss: 0.1005\n",
      "Epoch [7560/10000], Loss: 0.0998\n",
      "Epoch [7570/10000], Loss: 0.0991\n",
      "Epoch [7580/10000], Loss: 0.0984\n",
      "Epoch [7590/10000], Loss: 0.0977\n",
      "Epoch [7600/10000], Loss: 0.0970\n",
      "Epoch [7610/10000], Loss: 0.0964\n",
      "Epoch [7620/10000], Loss: 0.0957\n",
      "Epoch [7630/10000], Loss: 0.0951\n",
      "Epoch [7640/10000], Loss: 0.0945\n",
      "Epoch [7650/10000], Loss: 0.0938\n",
      "Epoch [7660/10000], Loss: 0.0932\n",
      "Epoch [7670/10000], Loss: 0.0926\n",
      "Epoch [7680/10000], Loss: 0.0920\n",
      "Epoch [7690/10000], Loss: 0.0914\n",
      "Epoch [7700/10000], Loss: 0.0909\n",
      "Epoch [7710/10000], Loss: 0.0903\n",
      "Epoch [7720/10000], Loss: 0.0898\n",
      "Epoch [7730/10000], Loss: 0.0893\n",
      "Epoch [7740/10000], Loss: 0.0891\n",
      "Epoch [7750/10000], Loss: 0.1746\n",
      "Epoch [7760/10000], Loss: 2.2527\n",
      "Epoch [7770/10000], Loss: 76.0425\n",
      "Epoch [7780/10000], Loss: 18.9896\n",
      "Epoch [7790/10000], Loss: 12.7410\n",
      "Epoch [7800/10000], Loss: 44.2818\n",
      "Epoch [7810/10000], Loss: 20.7865\n",
      "Epoch [7820/10000], Loss: 1.2137\n",
      "Epoch [7830/10000], Loss: 1.1886\n",
      "Epoch [7840/10000], Loss: 1.1639\n",
      "Epoch [7850/10000], Loss: 1.1397\n",
      "Epoch [7860/10000], Loss: 1.1159\n",
      "Epoch [7870/10000], Loss: 1.0926\n",
      "Epoch [7880/10000], Loss: 1.0697\n",
      "Epoch [7890/10000], Loss: 1.0473\n",
      "Epoch [7900/10000], Loss: 1.0252\n",
      "Epoch [7910/10000], Loss: 1.0036\n",
      "Epoch [7920/10000], Loss: 0.9823\n",
      "Epoch [7930/10000], Loss: 0.9616\n",
      "Epoch [7940/10000], Loss: 0.9412\n",
      "Epoch [7950/10000], Loss: 0.9214\n",
      "Epoch [7960/10000], Loss: 0.9019\n",
      "Epoch [7970/10000], Loss: 0.8829\n",
      "Epoch [7980/10000], Loss: 0.8642\n",
      "Epoch [7990/10000], Loss: 0.8460\n",
      "Epoch [8000/10000], Loss: 0.8280\n",
      "Epoch [8010/10000], Loss: 0.8105\n",
      "Epoch [8020/10000], Loss: 0.7932\n",
      "Epoch [8030/10000], Loss: 0.7764\n",
      "Epoch [8040/10000], Loss: 0.7597\n",
      "Epoch [8050/10000], Loss: 0.7434\n",
      "Epoch [8060/10000], Loss: 0.7274\n",
      "Epoch [8070/10000], Loss: 0.7116\n",
      "Epoch [8080/10000], Loss: 0.6963\n",
      "Epoch [8090/10000], Loss: 0.6812\n",
      "Epoch [8100/10000], Loss: 0.6665\n",
      "Epoch [8110/10000], Loss: 0.6522\n",
      "Epoch [8120/10000], Loss: 0.6381\n",
      "Epoch [8130/10000], Loss: 0.6243\n",
      "Epoch [8140/10000], Loss: 0.6109\n",
      "Epoch [8150/10000], Loss: 0.5977\n",
      "Epoch [8160/10000], Loss: 0.5848\n",
      "Epoch [8170/10000], Loss: 0.5721\n",
      "Epoch [8180/10000], Loss: 0.5598\n",
      "Epoch [8190/10000], Loss: 0.5478\n",
      "Epoch [8200/10000], Loss: 0.5360\n",
      "Epoch [8210/10000], Loss: 0.5246\n",
      "Epoch [8220/10000], Loss: 0.5134\n",
      "Epoch [8230/10000], Loss: 0.5025\n",
      "Epoch [8240/10000], Loss: 0.4918\n",
      "Epoch [8250/10000], Loss: 0.4814\n",
      "Epoch [8260/10000], Loss: 0.4713\n",
      "Epoch [8270/10000], Loss: 0.4613\n",
      "Epoch [8280/10000], Loss: 0.4516\n",
      "Epoch [8290/10000], Loss: 0.4421\n",
      "Epoch [8300/10000], Loss: 0.4328\n",
      "Epoch [8310/10000], Loss: 0.4237\n",
      "Epoch [8320/10000], Loss: 0.4148\n",
      "Epoch [8330/10000], Loss: 0.4061\n",
      "Epoch [8340/10000], Loss: 0.3977\n",
      "Epoch [8350/10000], Loss: 0.3895\n",
      "Epoch [8360/10000], Loss: 0.3814\n",
      "Epoch [8370/10000], Loss: 0.3735\n",
      "Epoch [8380/10000], Loss: 0.3658\n",
      "Epoch [8390/10000], Loss: 0.3583\n",
      "Epoch [8400/10000], Loss: 0.3511\n",
      "Epoch [8410/10000], Loss: 0.3440\n",
      "Epoch [8420/10000], Loss: 0.3372\n",
      "Epoch [8430/10000], Loss: 0.3304\n",
      "Epoch [8440/10000], Loss: 0.3238\n",
      "Epoch [8450/10000], Loss: 0.3175\n",
      "Epoch [8460/10000], Loss: 0.3113\n",
      "Epoch [8470/10000], Loss: 0.3053\n",
      "Epoch [8480/10000], Loss: 0.2994\n",
      "Epoch [8490/10000], Loss: 0.2936\n",
      "Epoch [8500/10000], Loss: 0.2880\n",
      "Epoch [8510/10000], Loss: 0.2824\n",
      "Epoch [8520/10000], Loss: 0.2770\n",
      "Epoch [8530/10000], Loss: 0.2718\n",
      "Epoch [8540/10000], Loss: 0.2666\n",
      "Epoch [8550/10000], Loss: 0.2615\n",
      "Epoch [8560/10000], Loss: 0.2566\n",
      "Epoch [8570/10000], Loss: 0.2518\n",
      "Epoch [8580/10000], Loss: 0.2471\n",
      "Epoch [8590/10000], Loss: 0.2426\n",
      "Epoch [8600/10000], Loss: 0.2381\n",
      "Epoch [8610/10000], Loss: 0.2337\n",
      "Epoch [8620/10000], Loss: 0.2295\n",
      "Epoch [8630/10000], Loss: 0.2253\n",
      "Epoch [8640/10000], Loss: 0.2213\n",
      "Epoch [8650/10000], Loss: 0.2173\n",
      "Epoch [8660/10000], Loss: 0.2135\n",
      "Epoch [8670/10000], Loss: 0.2098\n",
      "Epoch [8680/10000], Loss: 0.2061\n",
      "Epoch [8690/10000], Loss: 0.2026\n",
      "Epoch [8700/10000], Loss: 0.1992\n",
      "Epoch [8710/10000], Loss: 0.1958\n",
      "Epoch [8720/10000], Loss: 0.1926\n",
      "Epoch [8730/10000], Loss: 0.1894\n",
      "Epoch [8740/10000], Loss: 0.1863\n",
      "Epoch [8750/10000], Loss: 0.1833\n",
      "Epoch [8760/10000], Loss: 0.1804\n",
      "Epoch [8770/10000], Loss: 0.1776\n",
      "Epoch [8780/10000], Loss: 0.1748\n",
      "Epoch [8790/10000], Loss: 0.1721\n",
      "Epoch [8800/10000], Loss: 0.1694\n",
      "Epoch [8810/10000], Loss: 0.1668\n",
      "Epoch [8820/10000], Loss: 0.1643\n",
      "Epoch [8830/10000], Loss: 0.1618\n",
      "Epoch [8840/10000], Loss: 0.1594\n",
      "Epoch [8850/10000], Loss: 0.1571\n",
      "Epoch [8860/10000], Loss: 0.1548\n",
      "Epoch [8870/10000], Loss: 0.1526\n",
      "Epoch [8880/10000], Loss: 0.1504\n",
      "Epoch [8890/10000], Loss: 0.1482\n",
      "Epoch [8900/10000], Loss: 0.1461\n",
      "Epoch [8910/10000], Loss: 0.1441\n",
      "Epoch [8920/10000], Loss: 0.1422\n",
      "Epoch [8930/10000], Loss: 0.1403\n",
      "Epoch [8940/10000], Loss: 0.1384\n",
      "Epoch [8950/10000], Loss: 0.1366\n",
      "Epoch [8960/10000], Loss: 0.1349\n",
      "Epoch [8970/10000], Loss: 0.1332\n",
      "Epoch [8980/10000], Loss: 0.1315\n",
      "Epoch [8990/10000], Loss: 0.1299\n",
      "Epoch [9000/10000], Loss: 0.1283\n",
      "Epoch [9010/10000], Loss: 0.1268\n",
      "Epoch [9020/10000], Loss: 0.1254\n",
      "Epoch [9030/10000], Loss: 0.1240\n",
      "Epoch [9040/10000], Loss: 0.1226\n",
      "Epoch [9050/10000], Loss: 0.1213\n",
      "Epoch [9060/10000], Loss: 0.1199\n",
      "Epoch [9070/10000], Loss: 0.1186\n",
      "Epoch [9080/10000], Loss: 0.1173\n",
      "Epoch [9090/10000], Loss: 0.1161\n",
      "Epoch [9100/10000], Loss: 0.1148\n",
      "Epoch [9110/10000], Loss: 0.1137\n",
      "Epoch [9120/10000], Loss: 0.1125\n",
      "Epoch [9130/10000], Loss: 0.1114\n",
      "Epoch [9140/10000], Loss: 0.1103\n",
      "Epoch [9150/10000], Loss: 0.1092\n",
      "Epoch [9160/10000], Loss: 0.1083\n",
      "Epoch [9170/10000], Loss: 0.1073\n",
      "Epoch [9180/10000], Loss: 0.1063\n",
      "Epoch [9190/10000], Loss: 0.1055\n",
      "Epoch [9200/10000], Loss: 0.1046\n",
      "Epoch [9210/10000], Loss: 0.1038\n",
      "Epoch [9220/10000], Loss: 0.1030\n",
      "Epoch [9230/10000], Loss: 0.1022\n",
      "Epoch [9240/10000], Loss: 0.1015\n",
      "Epoch [9250/10000], Loss: 0.1008\n",
      "Epoch [9260/10000], Loss: 0.1001\n",
      "Epoch [9270/10000], Loss: 0.0994\n",
      "Epoch [9280/10000], Loss: 0.0987\n",
      "Epoch [9290/10000], Loss: 0.0981\n",
      "Epoch [9300/10000], Loss: 0.0975\n",
      "Epoch [9310/10000], Loss: 0.0968\n",
      "Epoch [9320/10000], Loss: 0.0962\n",
      "Epoch [9330/10000], Loss: 0.0956\n",
      "Epoch [9340/10000], Loss: 0.0950\n",
      "Epoch [9350/10000], Loss: 0.0944\n",
      "Epoch [9360/10000], Loss: 0.0939\n",
      "Epoch [9370/10000], Loss: 0.0933\n",
      "Epoch [9380/10000], Loss: 0.0928\n",
      "Epoch [9390/10000], Loss: 0.0922\n",
      "Epoch [9400/10000], Loss: 0.0917\n",
      "Epoch [9410/10000], Loss: 0.0912\n",
      "Epoch [9420/10000], Loss: 0.0907\n",
      "Epoch [9430/10000], Loss: 0.0902\n",
      "Epoch [9440/10000], Loss: 0.0897\n",
      "Epoch [9450/10000], Loss: 0.0892\n",
      "Epoch [9460/10000], Loss: 0.0892\n",
      "Epoch [9470/10000], Loss: 19.2244\n",
      "Epoch [9480/10000], Loss: 31.5850\n",
      "Epoch [9490/10000], Loss: 70.1214\n",
      "Epoch [9500/10000], Loss: 28.3726\n",
      "Epoch [9510/10000], Loss: 38.8394\n",
      "Epoch [9520/10000], Loss: 58.1446\n",
      "Epoch [9530/10000], Loss: 17.2088\n",
      "Epoch [9540/10000], Loss: 1.2548\n",
      "Epoch [9550/10000], Loss: 1.2297\n",
      "Epoch [9560/10000], Loss: 1.2049\n",
      "Epoch [9570/10000], Loss: 1.1806\n",
      "Epoch [9580/10000], Loss: 1.1566\n",
      "Epoch [9590/10000], Loss: 1.1331\n",
      "Epoch [9600/10000], Loss: 1.1099\n",
      "Epoch [9610/10000], Loss: 1.0871\n",
      "Epoch [9620/10000], Loss: 1.0647\n",
      "Epoch [9630/10000], Loss: 1.0429\n",
      "Epoch [9640/10000], Loss: 1.0215\n",
      "Epoch [9650/10000], Loss: 1.0005\n",
      "Epoch [9660/10000], Loss: 0.9800\n",
      "Epoch [9670/10000], Loss: 0.9599\n",
      "Epoch [9680/10000], Loss: 0.9402\n",
      "Epoch [9690/10000], Loss: 0.9208\n",
      "Epoch [9700/10000], Loss: 0.9018\n",
      "Epoch [9710/10000], Loss: 0.8831\n",
      "Epoch [9720/10000], Loss: 0.8648\n",
      "Epoch [9730/10000], Loss: 0.8468\n",
      "Epoch [9740/10000], Loss: 0.8292\n",
      "Epoch [9750/10000], Loss: 0.8120\n",
      "Epoch [9760/10000], Loss: 0.7950\n",
      "Epoch [9770/10000], Loss: 0.7784\n",
      "Epoch [9780/10000], Loss: 0.7621\n",
      "Epoch [9790/10000], Loss: 0.7460\n",
      "Epoch [9800/10000], Loss: 0.7303\n",
      "Epoch [9810/10000], Loss: 0.7150\n",
      "Epoch [9820/10000], Loss: 0.7000\n",
      "Epoch [9830/10000], Loss: 0.6853\n",
      "Epoch [9840/10000], Loss: 0.6709\n",
      "Epoch [9850/10000], Loss: 0.6569\n",
      "Epoch [9860/10000], Loss: 0.6431\n",
      "Epoch [9870/10000], Loss: 0.6296\n",
      "Epoch [9880/10000], Loss: 0.6164\n",
      "Epoch [9890/10000], Loss: 0.6034\n",
      "Epoch [9900/10000], Loss: 0.5908\n",
      "Epoch [9910/10000], Loss: 0.5784\n",
      "Epoch [9920/10000], Loss: 0.5663\n",
      "Epoch [9930/10000], Loss: 0.5545\n",
      "Epoch [9940/10000], Loss: 0.5429\n",
      "Epoch [9950/10000], Loss: 0.5316\n",
      "Epoch [9960/10000], Loss: 0.5206\n",
      "Epoch [9970/10000], Loss: 0.5097\n",
      "Epoch [9980/10000], Loss: 0.4992\n",
      "Epoch [9990/10000], Loss: 0.4889\n",
      "Epoch [10000/10000], Loss: 0.4788\n",
      "Validation Accuracy: 0.33\n",
      "Fold 2/4\n",
      "Epoch [10/10000], Loss: 85.0614\n",
      "Epoch [20/10000], Loss: 33.4248\n",
      "Epoch [30/10000], Loss: 21.7794\n",
      "Epoch [40/10000], Loss: 0.5583\n",
      "Epoch [50/10000], Loss: 0.5351\n",
      "Epoch [60/10000], Loss: 0.5127\n",
      "Epoch [70/10000], Loss: 0.4909\n",
      "Epoch [80/10000], Loss: 0.4698\n",
      "Epoch [90/10000], Loss: 0.4493\n",
      "Epoch [100/10000], Loss: 0.4295\n",
      "Epoch [110/10000], Loss: 0.4104\n",
      "Epoch [120/10000], Loss: 0.3919\n",
      "Epoch [130/10000], Loss: 0.3740\n",
      "Epoch [140/10000], Loss: 0.3568\n",
      "Epoch [150/10000], Loss: 0.3402\n",
      "Epoch [160/10000], Loss: 0.3244\n",
      "Epoch [170/10000], Loss: 0.3091\n",
      "Epoch [180/10000], Loss: 0.2944\n",
      "Epoch [190/10000], Loss: 0.2804\n",
      "Epoch [200/10000], Loss: 0.2669\n",
      "Epoch [210/10000], Loss: 0.2539\n",
      "Epoch [220/10000], Loss: 0.2416\n",
      "Epoch [230/10000], Loss: 0.2298\n",
      "Epoch [240/10000], Loss: 0.2187\n",
      "Epoch [250/10000], Loss: 0.2082\n",
      "Epoch [260/10000], Loss: 0.1983\n",
      "Epoch [270/10000], Loss: 0.1890\n",
      "Epoch [280/10000], Loss: 0.1803\n",
      "Epoch [290/10000], Loss: 0.1721\n",
      "Epoch [300/10000], Loss: 0.1646\n",
      "Epoch [310/10000], Loss: 0.1596\n",
      "Epoch [320/10000], Loss: 0.1826\n",
      "Epoch [330/10000], Loss: 0.1683\n",
      "Epoch [340/10000], Loss: 0.1591\n",
      "Epoch [350/10000], Loss: 0.1521\n",
      "Epoch [360/10000], Loss: 84.4746\n",
      "Epoch [370/10000], Loss: 51.4061\n",
      "Epoch [380/10000], Loss: 0.3517\n",
      "Epoch [390/10000], Loss: 0.3302\n",
      "Epoch [400/10000], Loss: 0.3103\n",
      "Epoch [410/10000], Loss: 0.2921\n",
      "Epoch [420/10000], Loss: 0.2754\n",
      "Epoch [430/10000], Loss: 0.2600\n",
      "Epoch [440/10000], Loss: 0.2460\n",
      "Epoch [450/10000], Loss: 0.2332\n",
      "Epoch [460/10000], Loss: 0.2216\n",
      "Epoch [470/10000], Loss: 0.2110\n",
      "Epoch [480/10000], Loss: 0.2013\n",
      "Epoch [490/10000], Loss: 0.1924\n",
      "Epoch [500/10000], Loss: 0.1842\n",
      "Epoch [510/10000], Loss: 0.1767\n",
      "Epoch [520/10000], Loss: 0.1698\n",
      "Epoch [530/10000], Loss: 0.1634\n",
      "Epoch [540/10000], Loss: 0.1574\n",
      "Epoch [550/10000], Loss: 0.1518\n",
      "Epoch [560/10000], Loss: 0.1467\n",
      "Epoch [570/10000], Loss: 0.1418\n",
      "Epoch [580/10000], Loss: 0.1373\n",
      "Epoch [590/10000], Loss: 0.1332\n",
      "Epoch [600/10000], Loss: 0.1303\n",
      "Epoch [610/10000], Loss: 22.2777\n",
      "Epoch [620/10000], Loss: 0.3087\n",
      "Epoch [630/10000], Loss: 0.2870\n",
      "Epoch [640/10000], Loss: 0.2673\n",
      "Epoch [650/10000], Loss: 0.2496\n",
      "Epoch [660/10000], Loss: 0.2335\n",
      "Epoch [670/10000], Loss: 0.2190\n",
      "Epoch [680/10000], Loss: 0.2063\n",
      "Epoch [690/10000], Loss: 0.1951\n",
      "Epoch [700/10000], Loss: 0.1853\n",
      "Epoch [710/10000], Loss: 0.1766\n",
      "Epoch [720/10000], Loss: 0.1690\n",
      "Epoch [730/10000], Loss: 0.1622\n",
      "Epoch [740/10000], Loss: 0.1563\n",
      "Epoch [750/10000], Loss: 0.1509\n",
      "Epoch [760/10000], Loss: 0.1461\n",
      "Epoch [770/10000], Loss: 0.1416\n",
      "Epoch [780/10000], Loss: 0.1375\n",
      "Epoch [790/10000], Loss: 0.1337\n",
      "Epoch [800/10000], Loss: 0.1301\n",
      "Epoch [810/10000], Loss: 0.1268\n",
      "Epoch [820/10000], Loss: 0.1236\n",
      "Epoch [830/10000], Loss: 0.1208\n",
      "Epoch [840/10000], Loss: 69.3946\n",
      "Epoch [850/10000], Loss: 62.1422\n",
      "Epoch [860/10000], Loss: 1.9611\n",
      "Epoch [870/10000], Loss: 0.5557\n",
      "Epoch [880/10000], Loss: 0.5322\n",
      "Epoch [890/10000], Loss: 0.5098\n",
      "Epoch [900/10000], Loss: 0.4884\n",
      "Epoch [910/10000], Loss: 0.4678\n",
      "Epoch [920/10000], Loss: 0.4481\n",
      "Epoch [930/10000], Loss: 0.4293\n",
      "Epoch [940/10000], Loss: 0.4114\n",
      "Epoch [950/10000], Loss: 0.3942\n",
      "Epoch [960/10000], Loss: 0.3779\n",
      "Epoch [970/10000], Loss: 0.3622\n",
      "Epoch [980/10000], Loss: 0.3474\n",
      "Epoch [990/10000], Loss: 0.3333\n",
      "Epoch [1000/10000], Loss: 0.3199\n",
      "Epoch [1010/10000], Loss: 0.3073\n",
      "Epoch [1020/10000], Loss: 0.2954\n",
      "Epoch [1030/10000], Loss: 0.2842\n",
      "Epoch [1040/10000], Loss: 0.2736\n",
      "Epoch [1050/10000], Loss: 0.2637\n",
      "Epoch [1060/10000], Loss: 0.2543\n",
      "Epoch [1070/10000], Loss: 0.2454\n",
      "Epoch [1080/10000], Loss: 0.2371\n",
      "Epoch [1090/10000], Loss: 0.2292\n",
      "Epoch [1100/10000], Loss: 0.2218\n",
      "Epoch [1110/10000], Loss: 0.2149\n",
      "Epoch [1120/10000], Loss: 0.2084\n",
      "Epoch [1130/10000], Loss: 0.2023\n",
      "Epoch [1140/10000], Loss: 0.1966\n",
      "Epoch [1150/10000], Loss: 0.1911\n",
      "Epoch [1160/10000], Loss: 0.1861\n",
      "Epoch [1170/10000], Loss: 0.1812\n",
      "Epoch [1180/10000], Loss: 0.1766\n",
      "Epoch [1190/10000], Loss: 0.1723\n",
      "Epoch [1200/10000], Loss: 0.1681\n",
      "Epoch [1210/10000], Loss: 0.1641\n",
      "Epoch [1220/10000], Loss: 0.1603\n",
      "Epoch [1230/10000], Loss: 0.1566\n",
      "Epoch [1240/10000], Loss: 0.1530\n",
      "Epoch [1250/10000], Loss: 0.1497\n",
      "Epoch [1260/10000], Loss: 0.1464\n",
      "Epoch [1270/10000], Loss: 0.1434\n",
      "Epoch [1280/10000], Loss: 0.1404\n",
      "Epoch [1290/10000], Loss: 0.1375\n",
      "Epoch [1300/10000], Loss: 0.1347\n",
      "Epoch [1310/10000], Loss: 0.1320\n",
      "Epoch [1320/10000], Loss: 0.1294\n",
      "Epoch [1330/10000], Loss: 0.1269\n",
      "Epoch [1340/10000], Loss: 0.1245\n",
      "Epoch [1350/10000], Loss: 0.1222\n",
      "Epoch [1360/10000], Loss: 0.1200\n",
      "Epoch [1370/10000], Loss: 0.1178\n",
      "Epoch [1380/10000], Loss: 0.1157\n",
      "Epoch [1390/10000], Loss: 0.1137\n",
      "Epoch [1400/10000], Loss: 0.1118\n",
      "Epoch [1410/10000], Loss: 0.1100\n",
      "Epoch [1420/10000], Loss: 0.1129\n",
      "Epoch [1430/10000], Loss: 17.0627\n",
      "Epoch [1440/10000], Loss: 0.3649\n",
      "Epoch [1450/10000], Loss: 0.3416\n",
      "Epoch [1460/10000], Loss: 0.3204\n",
      "Epoch [1470/10000], Loss: 0.3007\n",
      "Epoch [1480/10000], Loss: 0.2824\n",
      "Epoch [1490/10000], Loss: 0.2654\n",
      "Epoch [1500/10000], Loss: 0.2497\n",
      "Epoch [1510/10000], Loss: 0.2353\n",
      "Epoch [1520/10000], Loss: 0.2221\n",
      "Epoch [1530/10000], Loss: 0.2102\n",
      "Epoch [1540/10000], Loss: 0.1994\n",
      "Epoch [1550/10000], Loss: 0.1896\n",
      "Epoch [1560/10000], Loss: 0.1808\n",
      "Epoch [1570/10000], Loss: 0.1728\n",
      "Epoch [1580/10000], Loss: 0.1656\n",
      "Epoch [1590/10000], Loss: 0.1591\n",
      "Epoch [1600/10000], Loss: 0.1534\n",
      "Epoch [1610/10000], Loss: 0.1482\n",
      "Epoch [1620/10000], Loss: 0.1437\n",
      "Epoch [1630/10000], Loss: 0.1396\n",
      "Epoch [1640/10000], Loss: 0.1359\n",
      "Epoch [1650/10000], Loss: 0.1326\n",
      "Epoch [1660/10000], Loss: 0.1296\n",
      "Epoch [1670/10000], Loss: 0.1268\n",
      "Epoch [1680/10000], Loss: 0.1244\n",
      "Epoch [1690/10000], Loss: 0.1221\n",
      "Epoch [1700/10000], Loss: 0.1200\n",
      "Epoch [1710/10000], Loss: 0.1180\n",
      "Epoch [1720/10000], Loss: 0.1161\n",
      "Epoch [1730/10000], Loss: 0.1143\n",
      "Epoch [1740/10000], Loss: 0.1125\n",
      "Epoch [1750/10000], Loss: 0.1109\n",
      "Epoch [1760/10000], Loss: 0.1092\n",
      "Epoch [1770/10000], Loss: 0.1077\n",
      "Epoch [1780/10000], Loss: 0.1062\n",
      "Epoch [1790/10000], Loss: 0.1048\n",
      "Epoch [1800/10000], Loss: 0.3330\n",
      "Epoch [1810/10000], Loss: 0.1802\n",
      "Epoch [1820/10000], Loss: 0.1612\n",
      "Epoch [1830/10000], Loss: 0.1461\n",
      "Epoch [1840/10000], Loss: 0.1346\n",
      "Epoch [1850/10000], Loss: 0.1259\n",
      "Epoch [1860/10000], Loss: 0.1195\n",
      "Epoch [1870/10000], Loss: 0.1149\n",
      "Epoch [1880/10000], Loss: 0.1115\n",
      "Epoch [1890/10000], Loss: 0.1091\n",
      "Epoch [1900/10000], Loss: 0.1072\n",
      "Epoch [1910/10000], Loss: 0.1057\n",
      "Epoch [1920/10000], Loss: 0.1043\n",
      "Epoch [1930/10000], Loss: 0.1099\n",
      "Epoch [1940/10000], Loss: 25.7990\n",
      "Epoch [1950/10000], Loss: 0.2350\n",
      "Epoch [1960/10000], Loss: 0.2149\n",
      "Epoch [1970/10000], Loss: 0.1973\n",
      "Epoch [1980/10000], Loss: 0.1818\n",
      "Epoch [1990/10000], Loss: 0.1685\n",
      "Epoch [2000/10000], Loss: 0.1573\n",
      "Epoch [2010/10000], Loss: 0.1479\n",
      "Epoch [2020/10000], Loss: 0.1399\n",
      "Epoch [2030/10000], Loss: 0.1333\n",
      "Epoch [2040/10000], Loss: 0.1278\n",
      "Epoch [2050/10000], Loss: 0.1233\n",
      "Epoch [2060/10000], Loss: 0.1196\n",
      "Epoch [2070/10000], Loss: 0.1164\n",
      "Epoch [2080/10000], Loss: 0.1138\n",
      "Epoch [2090/10000], Loss: 0.1117\n",
      "Epoch [2100/10000], Loss: 0.1098\n",
      "Epoch [2110/10000], Loss: 0.1082\n",
      "Epoch [2120/10000], Loss: 0.1067\n",
      "Epoch [2130/10000], Loss: 0.1053\n",
      "Epoch [2140/10000], Loss: 0.1040\n",
      "Epoch [2150/10000], Loss: 0.1033\n",
      "Epoch [2160/10000], Loss: 28.5787\n",
      "Epoch [2170/10000], Loss: 0.2061\n",
      "Epoch [2180/10000], Loss: 0.1862\n",
      "Epoch [2190/10000], Loss: 0.1694\n",
      "Epoch [2200/10000], Loss: 0.1554\n",
      "Epoch [2210/10000], Loss: 0.1440\n",
      "Epoch [2220/10000], Loss: 0.1348\n",
      "Epoch [2230/10000], Loss: 0.1274\n",
      "Epoch [2240/10000], Loss: 0.1217\n",
      "Epoch [2250/10000], Loss: 0.1173\n",
      "Epoch [2260/10000], Loss: 0.1137\n",
      "Epoch [2270/10000], Loss: 0.1110\n",
      "Epoch [2280/10000], Loss: 0.1088\n",
      "Epoch [2290/10000], Loss: 0.1071\n",
      "Epoch [2300/10000], Loss: 0.1056\n",
      "Epoch [2310/10000], Loss: 0.1043\n",
      "Epoch [2320/10000], Loss: 0.1030\n",
      "Epoch [2330/10000], Loss: 0.1019\n",
      "Epoch [2340/10000], Loss: 0.1171\n",
      "Epoch [2350/10000], Loss: 76.0886\n",
      "Epoch [2360/10000], Loss: 54.4781\n",
      "Epoch [2370/10000], Loss: 0.4722\n",
      "Epoch [2380/10000], Loss: 0.4492\n",
      "Epoch [2390/10000], Loss: 0.4275\n",
      "Epoch [2400/10000], Loss: 0.4068\n",
      "Epoch [2410/10000], Loss: 0.3870\n",
      "Epoch [2420/10000], Loss: 0.3683\n",
      "Epoch [2430/10000], Loss: 0.3505\n",
      "Epoch [2440/10000], Loss: 0.3337\n",
      "Epoch [2450/10000], Loss: 0.3178\n",
      "Epoch [2460/10000], Loss: 0.3028\n",
      "Epoch [2470/10000], Loss: 0.2886\n",
      "Epoch [2480/10000], Loss: 0.2753\n",
      "Epoch [2490/10000], Loss: 0.2629\n",
      "Epoch [2500/10000], Loss: 0.2513\n",
      "Epoch [2510/10000], Loss: 0.2405\n",
      "Epoch [2520/10000], Loss: 0.2304\n",
      "Epoch [2530/10000], Loss: 0.2209\n",
      "Epoch [2540/10000], Loss: 0.2121\n",
      "Epoch [2550/10000], Loss: 0.2038\n",
      "Epoch [2560/10000], Loss: 0.1961\n",
      "Epoch [2570/10000], Loss: 0.1889\n",
      "Epoch [2580/10000], Loss: 0.1823\n",
      "Epoch [2590/10000], Loss: 0.1761\n",
      "Epoch [2600/10000], Loss: 0.1703\n",
      "Epoch [2610/10000], Loss: 0.1651\n",
      "Epoch [2620/10000], Loss: 0.1602\n",
      "Epoch [2630/10000], Loss: 0.1556\n",
      "Epoch [2640/10000], Loss: 0.1514\n",
      "Epoch [2650/10000], Loss: 0.1474\n",
      "Epoch [2660/10000], Loss: 0.1437\n",
      "Epoch [2670/10000], Loss: 0.1403\n",
      "Epoch [2680/10000], Loss: 0.1371\n",
      "Epoch [2690/10000], Loss: 0.1341\n",
      "Epoch [2700/10000], Loss: 0.1314\n",
      "Epoch [2710/10000], Loss: 0.1288\n",
      "Epoch [2720/10000], Loss: 0.1265\n",
      "Epoch [2730/10000], Loss: 0.1244\n",
      "Epoch [2740/10000], Loss: 0.1224\n",
      "Epoch [2750/10000], Loss: 0.1205\n",
      "Epoch [2760/10000], Loss: 0.1188\n",
      "Epoch [2770/10000], Loss: 0.1171\n",
      "Epoch [2780/10000], Loss: 0.1156\n",
      "Epoch [2790/10000], Loss: 0.1141\n",
      "Epoch [2800/10000], Loss: 0.1127\n",
      "Epoch [2810/10000], Loss: 0.1113\n",
      "Epoch [2820/10000], Loss: 0.1100\n",
      "Epoch [2830/10000], Loss: 0.1088\n",
      "Epoch [2840/10000], Loss: 0.1075\n",
      "Epoch [2850/10000], Loss: 0.1063\n",
      "Epoch [2860/10000], Loss: 0.1052\n",
      "Epoch [2870/10000], Loss: 0.1040\n",
      "Epoch [2880/10000], Loss: 0.1029\n",
      "Epoch [2890/10000], Loss: 0.1018\n",
      "Epoch [2900/10000], Loss: 0.1008\n",
      "Epoch [2910/10000], Loss: 0.0998\n",
      "Epoch [2920/10000], Loss: 0.0992\n",
      "Epoch [2930/10000], Loss: 30.1393\n",
      "Epoch [2940/10000], Loss: 0.2439\n",
      "Epoch [2950/10000], Loss: 0.2226\n",
      "Epoch [2960/10000], Loss: 0.2038\n",
      "Epoch [2970/10000], Loss: 0.1872\n",
      "Epoch [2980/10000], Loss: 0.1728\n",
      "Epoch [2990/10000], Loss: 0.1603\n",
      "Epoch [3000/10000], Loss: 0.1498\n",
      "Epoch [3010/10000], Loss: 0.1409\n",
      "Epoch [3020/10000], Loss: 0.1334\n",
      "Epoch [3030/10000], Loss: 0.1272\n",
      "Epoch [3040/10000], Loss: 0.1221\n",
      "Epoch [3050/10000], Loss: 0.1179\n",
      "Epoch [3060/10000], Loss: 0.1144\n",
      "Epoch [3070/10000], Loss: 0.1114\n",
      "Epoch [3080/10000], Loss: 0.1090\n",
      "Epoch [3090/10000], Loss: 0.1070\n",
      "Epoch [3100/10000], Loss: 0.1053\n",
      "Epoch [3110/10000], Loss: 0.1039\n",
      "Epoch [3120/10000], Loss: 0.1026\n",
      "Epoch [3130/10000], Loss: 0.1016\n",
      "Epoch [3140/10000], Loss: 0.1005\n",
      "Epoch [3150/10000], Loss: 0.0996\n",
      "Epoch [3160/10000], Loss: 0.0986\n",
      "Epoch [3170/10000], Loss: 0.0993\n",
      "Epoch [3180/10000], Loss: 61.4676\n",
      "Epoch [3190/10000], Loss: 0.2181\n",
      "Epoch [3200/10000], Loss: 0.1980\n",
      "Epoch [3210/10000], Loss: 0.1807\n",
      "Epoch [3220/10000], Loss: 0.1659\n",
      "Epoch [3230/10000], Loss: 0.1533\n",
      "Epoch [3240/10000], Loss: 0.1428\n",
      "Epoch [3250/10000], Loss: 0.1342\n",
      "Epoch [3260/10000], Loss: 0.1270\n",
      "Epoch [3270/10000], Loss: 0.1213\n",
      "Epoch [3280/10000], Loss: 0.1167\n",
      "Epoch [3290/10000], Loss: 0.1129\n",
      "Epoch [3300/10000], Loss: 0.1098\n",
      "Epoch [3310/10000], Loss: 0.1073\n",
      "Epoch [3320/10000], Loss: 0.1053\n",
      "Epoch [3330/10000], Loss: 0.1036\n",
      "Epoch [3340/10000], Loss: 0.1022\n",
      "Epoch [3350/10000], Loss: 0.1011\n",
      "Epoch [3360/10000], Loss: 0.1001\n",
      "Epoch [3370/10000], Loss: 0.0991\n",
      "Epoch [3380/10000], Loss: 0.0983\n",
      "Epoch [3390/10000], Loss: 0.0984\n",
      "Epoch [3400/10000], Loss: 20.4444\n",
      "Epoch [3410/10000], Loss: 0.2961\n",
      "Epoch [3420/10000], Loss: 0.2737\n",
      "Epoch [3430/10000], Loss: 0.2533\n",
      "Epoch [3440/10000], Loss: 0.2347\n",
      "Epoch [3450/10000], Loss: 0.2179\n",
      "Epoch [3460/10000], Loss: 0.2027\n",
      "Epoch [3470/10000], Loss: 0.1892\n",
      "Epoch [3480/10000], Loss: 0.1772\n",
      "Epoch [3490/10000], Loss: 0.1667\n",
      "Epoch [3500/10000], Loss: 0.1574\n",
      "Epoch [3510/10000], Loss: 0.1491\n",
      "Epoch [3520/10000], Loss: 0.1420\n",
      "Epoch [3530/10000], Loss: 0.1357\n",
      "Epoch [3540/10000], Loss: 0.1303\n",
      "Epoch [3550/10000], Loss: 0.1257\n",
      "Epoch [3560/10000], Loss: 0.1217\n",
      "Epoch [3570/10000], Loss: 0.1182\n",
      "Epoch [3580/10000], Loss: 0.1152\n",
      "Epoch [3590/10000], Loss: 0.1126\n",
      "Epoch [3600/10000], Loss: 0.1103\n",
      "Epoch [3610/10000], Loss: 0.1084\n",
      "Epoch [3620/10000], Loss: 0.1067\n",
      "Epoch [3630/10000], Loss: 0.1052\n",
      "Epoch [3640/10000], Loss: 0.1039\n",
      "Epoch [3650/10000], Loss: 0.1027\n",
      "Epoch [3660/10000], Loss: 0.1017\n",
      "Epoch [3670/10000], Loss: 0.1008\n",
      "Epoch [3680/10000], Loss: 0.0999\n",
      "Epoch [3690/10000], Loss: 0.0990\n",
      "Epoch [3700/10000], Loss: 0.0982\n",
      "Epoch [3710/10000], Loss: 0.0974\n",
      "Epoch [3720/10000], Loss: 0.0990\n",
      "Epoch [3730/10000], Loss: 20.5604\n",
      "Epoch [3740/10000], Loss: 29.2537\n",
      "Epoch [3750/10000], Loss: 0.3438\n",
      "Epoch [3760/10000], Loss: 0.3222\n",
      "Epoch [3770/10000], Loss: 0.3021\n",
      "Epoch [3780/10000], Loss: 0.2835\n",
      "Epoch [3790/10000], Loss: 0.2662\n",
      "Epoch [3800/10000], Loss: 0.2502\n",
      "Epoch [3810/10000], Loss: 0.2354\n",
      "Epoch [3820/10000], Loss: 0.2218\n",
      "Epoch [3830/10000], Loss: 0.2094\n",
      "Epoch [3840/10000], Loss: 0.1981\n",
      "Epoch [3850/10000], Loss: 0.1878\n",
      "Epoch [3860/10000], Loss: 0.1784\n",
      "Epoch [3870/10000], Loss: 0.1699\n",
      "Epoch [3880/10000], Loss: 0.1621\n",
      "Epoch [3890/10000], Loss: 0.1552\n",
      "Epoch [3900/10000], Loss: 0.1489\n",
      "Epoch [3910/10000], Loss: 0.1434\n",
      "Epoch [3920/10000], Loss: 0.1384\n",
      "Epoch [3930/10000], Loss: 0.1339\n",
      "Epoch [3940/10000], Loss: 0.1299\n",
      "Epoch [3950/10000], Loss: 0.1263\n",
      "Epoch [3960/10000], Loss: 0.1230\n",
      "Epoch [3970/10000], Loss: 0.1200\n",
      "Epoch [3980/10000], Loss: 0.1174\n",
      "Epoch [3990/10000], Loss: 0.1151\n",
      "Epoch [4000/10000], Loss: 0.1130\n",
      "Epoch [4010/10000], Loss: 0.1111\n",
      "Epoch [4020/10000], Loss: 0.1094\n",
      "Epoch [4030/10000], Loss: 0.1079\n",
      "Epoch [4040/10000], Loss: 0.1065\n",
      "Epoch [4050/10000], Loss: 0.1052\n",
      "Epoch [4060/10000], Loss: 0.1040\n",
      "Epoch [4070/10000], Loss: 0.1030\n",
      "Epoch [4080/10000], Loss: 0.1020\n",
      "Epoch [4090/10000], Loss: 0.1011\n",
      "Epoch [4100/10000], Loss: 0.1003\n",
      "Epoch [4110/10000], Loss: 0.0995\n",
      "Epoch [4120/10000], Loss: 0.0987\n",
      "Epoch [4130/10000], Loss: 0.0978\n",
      "Epoch [4140/10000], Loss: 0.0972\n",
      "Epoch [4150/10000], Loss: 0.0984\n",
      "Epoch [4160/10000], Loss: 80.1060\n",
      "Epoch [4170/10000], Loss: 0.2933\n",
      "Epoch [4180/10000], Loss: 0.2708\n",
      "Epoch [4190/10000], Loss: 0.2506\n",
      "Epoch [4200/10000], Loss: 0.2323\n",
      "Epoch [4210/10000], Loss: 0.2156\n",
      "Epoch [4220/10000], Loss: 0.2006\n",
      "Epoch [4230/10000], Loss: 0.1872\n",
      "Epoch [4240/10000], Loss: 0.1754\n",
      "Epoch [4250/10000], Loss: 0.1649\n",
      "Epoch [4260/10000], Loss: 0.1558\n",
      "Epoch [4270/10000], Loss: 0.1476\n",
      "Epoch [4280/10000], Loss: 0.1405\n",
      "Epoch [4290/10000], Loss: 0.1344\n",
      "Epoch [4300/10000], Loss: 0.1291\n",
      "Epoch [4310/10000], Loss: 0.1245\n",
      "Epoch [4320/10000], Loss: 0.1206\n",
      "Epoch [4330/10000], Loss: 0.1171\n",
      "Epoch [4340/10000], Loss: 0.1141\n",
      "Epoch [4350/10000], Loss: 0.1115\n",
      "Epoch [4360/10000], Loss: 0.1093\n",
      "Epoch [4370/10000], Loss: 0.1074\n",
      "Epoch [4380/10000], Loss: 0.1057\n",
      "Epoch [4390/10000], Loss: 0.1043\n",
      "Epoch [4400/10000], Loss: 0.1030\n",
      "Epoch [4410/10000], Loss: 0.1018\n",
      "Epoch [4420/10000], Loss: 0.1009\n",
      "Epoch [4430/10000], Loss: 0.1000\n",
      "Epoch [4440/10000], Loss: 0.0992\n",
      "Epoch [4450/10000], Loss: 0.0984\n",
      "Epoch [4460/10000], Loss: 0.0976\n",
      "Epoch [4470/10000], Loss: 0.0969\n",
      "Epoch [4480/10000], Loss: 0.0962\n",
      "Epoch [4490/10000], Loss: 0.0980\n",
      "Epoch [4500/10000], Loss: 47.8262\n",
      "Epoch [4510/10000], Loss: 76.8394\n",
      "Epoch [4520/10000], Loss: 0.3381\n",
      "Epoch [4530/10000], Loss: 0.3167\n",
      "Epoch [4540/10000], Loss: 0.2966\n",
      "Epoch [4550/10000], Loss: 0.2780\n",
      "Epoch [4560/10000], Loss: 0.2607\n",
      "Epoch [4570/10000], Loss: 0.2447\n",
      "Epoch [4580/10000], Loss: 0.2299\n",
      "Epoch [4590/10000], Loss: 0.2164\n",
      "Epoch [4600/10000], Loss: 0.2042\n",
      "Epoch [4610/10000], Loss: 0.1931\n",
      "Epoch [4620/10000], Loss: 0.1830\n",
      "Epoch [4630/10000], Loss: 0.1739\n",
      "Epoch [4640/10000], Loss: 0.1656\n",
      "Epoch [4650/10000], Loss: 0.1580\n",
      "Epoch [4660/10000], Loss: 0.1513\n",
      "Epoch [4670/10000], Loss: 0.1453\n",
      "Epoch [4680/10000], Loss: 0.1399\n",
      "Epoch [4690/10000], Loss: 0.1351\n",
      "Epoch [4700/10000], Loss: 0.1308\n",
      "Epoch [4710/10000], Loss: 0.1269\n",
      "Epoch [4720/10000], Loss: 0.1235\n",
      "Epoch [4730/10000], Loss: 0.1203\n",
      "Epoch [4740/10000], Loss: 0.1174\n",
      "Epoch [4750/10000], Loss: 0.1150\n",
      "Epoch [4760/10000], Loss: 0.1127\n",
      "Epoch [4770/10000], Loss: 0.1107\n",
      "Epoch [4780/10000], Loss: 0.1090\n",
      "Epoch [4790/10000], Loss: 0.1074\n",
      "Epoch [4800/10000], Loss: 0.1059\n",
      "Epoch [4810/10000], Loss: 0.1046\n",
      "Epoch [4820/10000], Loss: 0.1034\n",
      "Epoch [4830/10000], Loss: 0.1023\n",
      "Epoch [4840/10000], Loss: 0.1014\n",
      "Epoch [4850/10000], Loss: 0.1005\n",
      "Epoch [4860/10000], Loss: 0.0997\n",
      "Epoch [4870/10000], Loss: 0.0989\n",
      "Epoch [4880/10000], Loss: 0.0981\n",
      "Epoch [4890/10000], Loss: 0.0974\n",
      "Epoch [4900/10000], Loss: 0.0967\n",
      "Epoch [4910/10000], Loss: 0.0964\n",
      "Epoch [4920/10000], Loss: 0.5734\n",
      "Epoch [4930/10000], Loss: 0.1845\n",
      "Epoch [4940/10000], Loss: 0.1642\n",
      "Epoch [4950/10000], Loss: 0.1482\n",
      "Epoch [4960/10000], Loss: 0.1354\n",
      "Epoch [4970/10000], Loss: 0.1255\n",
      "Epoch [4980/10000], Loss: 0.1179\n",
      "Epoch [4990/10000], Loss: 0.1122\n",
      "Epoch [5000/10000], Loss: 0.1079\n",
      "Epoch [5010/10000], Loss: 0.1047\n",
      "Epoch [5020/10000], Loss: 0.1023\n",
      "Epoch [5030/10000], Loss: 0.1004\n",
      "Epoch [5040/10000], Loss: 0.0991\n",
      "Epoch [5050/10000], Loss: 0.0980\n",
      "Epoch [5060/10000], Loss: 0.0971\n",
      "Epoch [5070/10000], Loss: 0.0964\n",
      "Epoch [5080/10000], Loss: 0.0958\n",
      "Epoch [5090/10000], Loss: 0.0988\n",
      "Epoch [5100/10000], Loss: 51.2413\n",
      "Epoch [5110/10000], Loss: 0.2243\n",
      "Epoch [5120/10000], Loss: 0.2042\n",
      "Epoch [5130/10000], Loss: 0.1865\n",
      "Epoch [5140/10000], Loss: 0.1711\n",
      "Epoch [5150/10000], Loss: 0.1579\n",
      "Epoch [5160/10000], Loss: 0.1469\n",
      "Epoch [5170/10000], Loss: 0.1377\n",
      "Epoch [5180/10000], Loss: 0.1300\n",
      "Epoch [5190/10000], Loss: 0.1236\n",
      "Epoch [5200/10000], Loss: 0.1185\n",
      "Epoch [5210/10000], Loss: 0.1142\n",
      "Epoch [5220/10000], Loss: 0.1107\n",
      "Epoch [5230/10000], Loss: 0.1077\n",
      "Epoch [5240/10000], Loss: 0.1053\n",
      "Epoch [5250/10000], Loss: 0.1033\n",
      "Epoch [5260/10000], Loss: 0.1017\n",
      "Epoch [5270/10000], Loss: 0.1004\n",
      "Epoch [5280/10000], Loss: 0.0992\n",
      "Epoch [5290/10000], Loss: 0.0982\n",
      "Epoch [5300/10000], Loss: 0.0974\n",
      "Epoch [5310/10000], Loss: 0.0967\n",
      "Epoch [5320/10000], Loss: 0.0961\n",
      "Epoch [5330/10000], Loss: 0.0965\n",
      "Epoch [5340/10000], Loss: 0.1705\n",
      "Epoch [5350/10000], Loss: 0.2429\n",
      "Epoch [5360/10000], Loss: 0.2209\n",
      "Epoch [5370/10000], Loss: 0.2018\n",
      "Epoch [5380/10000], Loss: 0.1851\n",
      "Epoch [5390/10000], Loss: 0.1706\n",
      "Epoch [5400/10000], Loss: 0.1582\n",
      "Epoch [5410/10000], Loss: 0.1477\n",
      "Epoch [5420/10000], Loss: 0.1388\n",
      "Epoch [5430/10000], Loss: 0.1314\n",
      "Epoch [5440/10000], Loss: 0.1251\n",
      "Epoch [5450/10000], Loss: 0.1200\n",
      "Epoch [5460/10000], Loss: 0.1157\n",
      "Epoch [5470/10000], Loss: 0.1121\n",
      "Epoch [5480/10000], Loss: 0.1091\n",
      "Epoch [5490/10000], Loss: 0.1065\n",
      "Epoch [5500/10000], Loss: 0.1045\n",
      "Epoch [5510/10000], Loss: 0.1028\n",
      "Epoch [5520/10000], Loss: 0.1013\n",
      "Epoch [5530/10000], Loss: 0.1000\n",
      "Epoch [5540/10000], Loss: 0.0990\n",
      "Epoch [5550/10000], Loss: 0.0981\n",
      "Epoch [5560/10000], Loss: 0.0973\n",
      "Epoch [5570/10000], Loss: 0.0966\n",
      "Epoch [5580/10000], Loss: 0.0960\n",
      "Epoch [5590/10000], Loss: 0.0957\n",
      "Epoch [5600/10000], Loss: 0.1058\n",
      "Epoch [5610/10000], Loss: 32.9726\n",
      "Epoch [5620/10000], Loss: 51.4869\n",
      "Epoch [5630/10000], Loss: 0.4017\n",
      "Epoch [5640/10000], Loss: 0.3794\n",
      "Epoch [5650/10000], Loss: 0.3586\n",
      "Epoch [5660/10000], Loss: 0.3389\n",
      "Epoch [5670/10000], Loss: 0.3204\n",
      "Epoch [5680/10000], Loss: 0.3029\n",
      "Epoch [5690/10000], Loss: 0.2865\n",
      "Epoch [5700/10000], Loss: 0.2711\n",
      "Epoch [5710/10000], Loss: 0.2568\n",
      "Epoch [5720/10000], Loss: 0.2434\n",
      "Epoch [5730/10000], Loss: 0.2310\n",
      "Epoch [5740/10000], Loss: 0.2197\n",
      "Epoch [5750/10000], Loss: 0.2091\n",
      "Epoch [5760/10000], Loss: 0.1994\n",
      "Epoch [5770/10000], Loss: 0.1904\n",
      "Epoch [5780/10000], Loss: 0.1822\n",
      "Epoch [5790/10000], Loss: 0.1746\n",
      "Epoch [5800/10000], Loss: 0.1676\n",
      "Epoch [5810/10000], Loss: 0.1612\n",
      "Epoch [5820/10000], Loss: 0.1554\n",
      "Epoch [5830/10000], Loss: 0.1501\n",
      "Epoch [5840/10000], Loss: 0.1453\n",
      "Epoch [5850/10000], Loss: 0.1408\n",
      "Epoch [5860/10000], Loss: 0.1367\n",
      "Epoch [5870/10000], Loss: 0.1329\n",
      "Epoch [5880/10000], Loss: 0.1295\n",
      "Epoch [5890/10000], Loss: 0.1263\n",
      "Epoch [5900/10000], Loss: 0.1234\n",
      "Epoch [5910/10000], Loss: 0.1208\n",
      "Epoch [5920/10000], Loss: 0.1184\n",
      "Epoch [5930/10000], Loss: 0.1162\n",
      "Epoch [5940/10000], Loss: 0.1142\n",
      "Epoch [5950/10000], Loss: 0.1123\n",
      "Epoch [5960/10000], Loss: 0.1107\n",
      "Epoch [5970/10000], Loss: 0.1091\n",
      "Epoch [5980/10000], Loss: 0.1077\n",
      "Epoch [5990/10000], Loss: 0.1064\n",
      "Epoch [6000/10000], Loss: 0.1052\n",
      "Epoch [6010/10000], Loss: 0.1041\n",
      "Epoch [6020/10000], Loss: 0.1030\n",
      "Epoch [6030/10000], Loss: 0.1021\n",
      "Epoch [6040/10000], Loss: 0.1013\n",
      "Epoch [6050/10000], Loss: 0.1005\n",
      "Epoch [6060/10000], Loss: 0.0997\n",
      "Epoch [6070/10000], Loss: 0.0990\n",
      "Epoch [6080/10000], Loss: 0.0983\n",
      "Epoch [6090/10000], Loss: 0.0976\n",
      "Epoch [6100/10000], Loss: 0.0970\n",
      "Epoch [6110/10000], Loss: 0.0964\n",
      "Epoch [6120/10000], Loss: 0.0959\n",
      "Epoch [6130/10000], Loss: 0.0969\n",
      "Epoch [6140/10000], Loss: 77.2173\n",
      "Epoch [6150/10000], Loss: 55.2397\n",
      "Epoch [6160/10000], Loss: 31.5628\n",
      "Epoch [6170/10000], Loss: 1.0695\n",
      "Epoch [6180/10000], Loss: 0.7031\n",
      "Epoch [6190/10000], Loss: 0.6792\n",
      "Epoch [6200/10000], Loss: 0.6561\n",
      "Epoch [6210/10000], Loss: 0.6338\n",
      "Epoch [6220/10000], Loss: 0.6123\n",
      "Epoch [6230/10000], Loss: 0.5914\n",
      "Epoch [6240/10000], Loss: 0.5712\n",
      "Epoch [6250/10000], Loss: 0.5517\n",
      "Epoch [6260/10000], Loss: 0.5327\n",
      "Epoch [6270/10000], Loss: 0.5143\n",
      "Epoch [6280/10000], Loss: 0.4965\n",
      "Epoch [6290/10000], Loss: 0.4793\n",
      "Epoch [6300/10000], Loss: 0.4627\n",
      "Epoch [6310/10000], Loss: 0.4468\n",
      "Epoch [6320/10000], Loss: 0.4313\n",
      "Epoch [6330/10000], Loss: 0.4165\n",
      "Epoch [6340/10000], Loss: 0.4023\n",
      "Epoch [6350/10000], Loss: 0.3886\n",
      "Epoch [6360/10000], Loss: 0.3755\n",
      "Epoch [6370/10000], Loss: 0.3629\n",
      "Epoch [6380/10000], Loss: 0.3509\n",
      "Epoch [6390/10000], Loss: 0.3394\n",
      "Epoch [6400/10000], Loss: 0.3283\n",
      "Epoch [6410/10000], Loss: 0.3177\n",
      "Epoch [6420/10000], Loss: 0.3076\n",
      "Epoch [6430/10000], Loss: 0.2979\n",
      "Epoch [6440/10000], Loss: 0.2885\n",
      "Epoch [6450/10000], Loss: 0.2796\n",
      "Epoch [6460/10000], Loss: 0.2710\n",
      "Epoch [6470/10000], Loss: 0.2628\n",
      "Epoch [6480/10000], Loss: 0.2549\n",
      "Epoch [6490/10000], Loss: 0.2474\n",
      "Epoch [6500/10000], Loss: 0.2403\n",
      "Epoch [6510/10000], Loss: 0.2335\n",
      "Epoch [6520/10000], Loss: 0.2269\n",
      "Epoch [6530/10000], Loss: 0.2207\n",
      "Epoch [6540/10000], Loss: 0.2148\n",
      "Epoch [6550/10000], Loss: 0.2091\n",
      "Epoch [6560/10000], Loss: 0.2038\n",
      "Epoch [6570/10000], Loss: 0.1986\n",
      "Epoch [6580/10000], Loss: 0.1938\n",
      "Epoch [6590/10000], Loss: 0.1891\n",
      "Epoch [6600/10000], Loss: 0.1846\n",
      "Epoch [6610/10000], Loss: 0.1803\n",
      "Epoch [6620/10000], Loss: 0.1761\n",
      "Epoch [6630/10000], Loss: 0.1722\n",
      "Epoch [6640/10000], Loss: 0.1684\n",
      "Epoch [6650/10000], Loss: 0.1648\n",
      "Epoch [6660/10000], Loss: 0.1614\n",
      "Epoch [6670/10000], Loss: 0.1580\n",
      "Epoch [6680/10000], Loss: 0.1548\n",
      "Epoch [6690/10000], Loss: 0.1518\n",
      "Epoch [6700/10000], Loss: 0.1488\n",
      "Epoch [6710/10000], Loss: 0.1461\n",
      "Epoch [6720/10000], Loss: 0.1435\n",
      "Epoch [6730/10000], Loss: 0.1410\n",
      "Epoch [6740/10000], Loss: 0.1387\n",
      "Epoch [6750/10000], Loss: 0.1364\n",
      "Epoch [6760/10000], Loss: 0.1342\n",
      "Epoch [6770/10000], Loss: 0.1321\n",
      "Epoch [6780/10000], Loss: 0.1301\n",
      "Epoch [6790/10000], Loss: 0.1283\n",
      "Epoch [6800/10000], Loss: 0.1265\n",
      "Epoch [6810/10000], Loss: 0.1248\n",
      "Epoch [6820/10000], Loss: 0.1231\n",
      "Epoch [6830/10000], Loss: 0.1216\n",
      "Epoch [6840/10000], Loss: 0.1201\n",
      "Epoch [6850/10000], Loss: 0.1186\n",
      "Epoch [6860/10000], Loss: 0.1172\n",
      "Epoch [6870/10000], Loss: 0.1159\n",
      "Epoch [6880/10000], Loss: 0.1146\n",
      "Epoch [6890/10000], Loss: 0.1134\n",
      "Epoch [6900/10000], Loss: 0.1122\n",
      "Epoch [6910/10000], Loss: 0.1112\n",
      "Epoch [6920/10000], Loss: 0.1101\n",
      "Epoch [6930/10000], Loss: 0.1092\n",
      "Epoch [6940/10000], Loss: 0.1082\n",
      "Epoch [6950/10000], Loss: 0.1073\n",
      "Epoch [6960/10000], Loss: 0.1064\n",
      "Epoch [6970/10000], Loss: 0.1056\n",
      "Epoch [6980/10000], Loss: 0.1048\n",
      "Epoch [6990/10000], Loss: 0.1041\n",
      "Epoch [7000/10000], Loss: 0.1033\n",
      "Epoch [7010/10000], Loss: 0.1026\n",
      "Epoch [7020/10000], Loss: 0.1019\n",
      "Epoch [7030/10000], Loss: 0.1012\n",
      "Epoch [7040/10000], Loss: 0.1005\n",
      "Epoch [7050/10000], Loss: 0.0999\n",
      "Epoch [7060/10000], Loss: 0.0992\n",
      "Epoch [7070/10000], Loss: 0.0986\n",
      "Epoch [7080/10000], Loss: 0.0980\n",
      "Epoch [7090/10000], Loss: 0.0973\n",
      "Epoch [7100/10000], Loss: 0.0967\n",
      "Epoch [7110/10000], Loss: 0.0962\n",
      "Epoch [7120/10000], Loss: 0.0957\n",
      "Epoch [7130/10000], Loss: 0.0959\n",
      "Epoch [7140/10000], Loss: 87.0099\n",
      "Epoch [7150/10000], Loss: 83.2817\n",
      "Epoch [7160/10000], Loss: 0.3915\n",
      "Epoch [7170/10000], Loss: 0.3687\n",
      "Epoch [7180/10000], Loss: 0.3473\n",
      "Epoch [7190/10000], Loss: 0.3273\n",
      "Epoch [7200/10000], Loss: 0.3085\n",
      "Epoch [7210/10000], Loss: 0.2910\n",
      "Epoch [7220/10000], Loss: 0.2746\n",
      "Epoch [7230/10000], Loss: 0.2593\n",
      "Epoch [7240/10000], Loss: 0.2452\n",
      "Epoch [7250/10000], Loss: 0.2320\n",
      "Epoch [7260/10000], Loss: 0.2199\n",
      "Epoch [7270/10000], Loss: 0.2088\n",
      "Epoch [7280/10000], Loss: 0.1985\n",
      "Epoch [7290/10000], Loss: 0.1891\n",
      "Epoch [7300/10000], Loss: 0.1805\n",
      "Epoch [7310/10000], Loss: 0.1725\n",
      "Epoch [7320/10000], Loss: 0.1653\n",
      "Epoch [7330/10000], Loss: 0.1587\n",
      "Epoch [7340/10000], Loss: 0.1527\n",
      "Epoch [7350/10000], Loss: 0.1473\n",
      "Epoch [7360/10000], Loss: 0.1424\n",
      "Epoch [7370/10000], Loss: 0.1379\n",
      "Epoch [7380/10000], Loss: 0.1338\n",
      "Epoch [7390/10000], Loss: 0.1301\n",
      "Epoch [7400/10000], Loss: 0.1267\n",
      "Epoch [7410/10000], Loss: 0.1235\n",
      "Epoch [7420/10000], Loss: 0.1207\n",
      "Epoch [7430/10000], Loss: 0.1181\n",
      "Epoch [7440/10000], Loss: 0.1158\n",
      "Epoch [7450/10000], Loss: 0.1137\n",
      "Epoch [7460/10000], Loss: 0.1118\n",
      "Epoch [7470/10000], Loss: 0.1101\n",
      "Epoch [7480/10000], Loss: 0.1086\n",
      "Epoch [7490/10000], Loss: 0.1071\n",
      "Epoch [7500/10000], Loss: 0.1058\n",
      "Epoch [7510/10000], Loss: 0.1046\n",
      "Epoch [7520/10000], Loss: 0.1034\n",
      "Epoch [7530/10000], Loss: 0.1024\n",
      "Epoch [7540/10000], Loss: 0.1015\n",
      "Epoch [7550/10000], Loss: 0.1006\n",
      "Epoch [7560/10000], Loss: 0.0998\n",
      "Epoch [7570/10000], Loss: 0.0991\n",
      "Epoch [7580/10000], Loss: 0.0985\n",
      "Epoch [7590/10000], Loss: 0.0978\n",
      "Epoch [7600/10000], Loss: 0.0972\n",
      "Epoch [7610/10000], Loss: 0.0966\n",
      "Epoch [7620/10000], Loss: 0.0960\n",
      "Epoch [7630/10000], Loss: 0.0955\n",
      "Epoch [7640/10000], Loss: 0.0949\n",
      "Epoch [7650/10000], Loss: 0.0945\n",
      "Epoch [7660/10000], Loss: 0.1005\n",
      "Epoch [7670/10000], Loss: 0.2094\n",
      "Epoch [7680/10000], Loss: 0.1879\n",
      "Epoch [7690/10000], Loss: 0.1696\n",
      "Epoch [7700/10000], Loss: 0.1542\n",
      "Epoch [7710/10000], Loss: 0.1416\n",
      "Epoch [7720/10000], Loss: 0.1314\n",
      "Epoch [7730/10000], Loss: 0.1232\n",
      "Epoch [7740/10000], Loss: 0.1167\n",
      "Epoch [7750/10000], Loss: 0.1117\n",
      "Epoch [7760/10000], Loss: 0.1078\n",
      "Epoch [7770/10000], Loss: 0.1047\n",
      "Epoch [7780/10000], Loss: 0.1022\n",
      "Epoch [7790/10000], Loss: 0.1004\n",
      "Epoch [7800/10000], Loss: 0.0989\n",
      "Epoch [7810/10000], Loss: 0.0976\n",
      "Epoch [7820/10000], Loss: 0.0966\n",
      "Epoch [7830/10000], Loss: 0.0958\n",
      "Epoch [7840/10000], Loss: 0.0951\n",
      "Epoch [7850/10000], Loss: 0.0946\n",
      "Epoch [7860/10000], Loss: 0.0954\n",
      "Epoch [7870/10000], Loss: 44.5306\n",
      "Epoch [7880/10000], Loss: 79.8253\n",
      "Epoch [7890/10000], Loss: 74.7884\n",
      "Epoch [7900/10000], Loss: 0.4514\n",
      "Epoch [7910/10000], Loss: 0.4291\n",
      "Epoch [7920/10000], Loss: 0.4080\n",
      "Epoch [7930/10000], Loss: 0.3879\n",
      "Epoch [7940/10000], Loss: 0.3687\n",
      "Epoch [7950/10000], Loss: 0.3504\n",
      "Epoch [7960/10000], Loss: 0.3332\n",
      "Epoch [7970/10000], Loss: 0.3169\n",
      "Epoch [7980/10000], Loss: 0.3014\n",
      "Epoch [7990/10000], Loss: 0.2869\n",
      "Epoch [8000/10000], Loss: 0.2732\n",
      "Epoch [8010/10000], Loss: 0.2604\n",
      "Epoch [8020/10000], Loss: 0.2484\n",
      "Epoch [8030/10000], Loss: 0.2373\n",
      "Epoch [8040/10000], Loss: 0.2268\n",
      "Epoch [8050/10000], Loss: 0.2171\n",
      "Epoch [8060/10000], Loss: 0.2080\n",
      "Epoch [8070/10000], Loss: 0.1995\n",
      "Epoch [8080/10000], Loss: 0.1916\n",
      "Epoch [8090/10000], Loss: 0.1843\n",
      "Epoch [8100/10000], Loss: 0.1775\n",
      "Epoch [8110/10000], Loss: 0.1712\n",
      "Epoch [8120/10000], Loss: 0.1654\n",
      "Epoch [8130/10000], Loss: 0.1600\n",
      "Epoch [8140/10000], Loss: 0.1550\n",
      "Epoch [8150/10000], Loss: 0.1504\n",
      "Epoch [8160/10000], Loss: 0.1462\n",
      "Epoch [8170/10000], Loss: 0.1421\n",
      "Epoch [8180/10000], Loss: 0.1384\n",
      "Epoch [8190/10000], Loss: 0.1350\n",
      "Epoch [8200/10000], Loss: 0.1317\n",
      "Epoch [8210/10000], Loss: 0.1287\n",
      "Epoch [8220/10000], Loss: 0.1259\n",
      "Epoch [8230/10000], Loss: 0.1234\n",
      "Epoch [8240/10000], Loss: 0.1211\n",
      "Epoch [8250/10000], Loss: 0.1189\n",
      "Epoch [8260/10000], Loss: 0.1168\n",
      "Epoch [8270/10000], Loss: 0.1150\n",
      "Epoch [8280/10000], Loss: 0.1132\n",
      "Epoch [8290/10000], Loss: 0.1117\n",
      "Epoch [8300/10000], Loss: 0.1102\n",
      "Epoch [8310/10000], Loss: 0.1088\n",
      "Epoch [8320/10000], Loss: 0.1075\n",
      "Epoch [8330/10000], Loss: 0.1062\n",
      "Epoch [8340/10000], Loss: 0.1051\n",
      "Epoch [8350/10000], Loss: 0.1041\n",
      "Epoch [8360/10000], Loss: 0.1031\n",
      "Epoch [8370/10000], Loss: 0.1021\n",
      "Epoch [8380/10000], Loss: 0.1013\n",
      "Epoch [8390/10000], Loss: 0.1006\n",
      "Epoch [8400/10000], Loss: 0.0998\n",
      "Epoch [8410/10000], Loss: 0.0991\n",
      "Epoch [8420/10000], Loss: 0.0984\n",
      "Epoch [8430/10000], Loss: 0.0978\n",
      "Epoch [8440/10000], Loss: 0.0973\n",
      "Epoch [8450/10000], Loss: 0.0967\n",
      "Epoch [8460/10000], Loss: 0.0962\n",
      "Epoch [8470/10000], Loss: 0.0956\n",
      "Epoch [8480/10000], Loss: 0.0952\n",
      "Epoch [8490/10000], Loss: 0.0970\n",
      "Epoch [8500/10000], Loss: 9.1313\n",
      "Epoch [8510/10000], Loss: 53.1866\n",
      "Epoch [8520/10000], Loss: 0.3692\n",
      "Epoch [8530/10000], Loss: 0.3470\n",
      "Epoch [8540/10000], Loss: 0.3262\n",
      "Epoch [8550/10000], Loss: 0.3068\n",
      "Epoch [8560/10000], Loss: 0.2886\n",
      "Epoch [8570/10000], Loss: 0.2716\n",
      "Epoch [8580/10000], Loss: 0.2557\n",
      "Epoch [8590/10000], Loss: 0.2410\n",
      "Epoch [8600/10000], Loss: 0.2275\n",
      "Epoch [8610/10000], Loss: 0.2151\n",
      "Epoch [8620/10000], Loss: 0.2038\n",
      "Epoch [8630/10000], Loss: 0.1934\n",
      "Epoch [8640/10000], Loss: 0.1840\n",
      "Epoch [8650/10000], Loss: 0.1753\n",
      "Epoch [8660/10000], Loss: 0.1675\n",
      "Epoch [8670/10000], Loss: 0.1603\n",
      "Epoch [8680/10000], Loss: 0.1538\n",
      "Epoch [8690/10000], Loss: 0.1480\n",
      "Epoch [8700/10000], Loss: 0.1427\n",
      "Epoch [8710/10000], Loss: 0.1380\n",
      "Epoch [8720/10000], Loss: 0.1337\n",
      "Epoch [8730/10000], Loss: 0.1298\n",
      "Epoch [8740/10000], Loss: 0.1262\n",
      "Epoch [8750/10000], Loss: 0.1230\n",
      "Epoch [8760/10000], Loss: 0.1200\n",
      "Epoch [8770/10000], Loss: 0.1174\n",
      "Epoch [8780/10000], Loss: 0.1150\n",
      "Epoch [8790/10000], Loss: 0.1129\n",
      "Epoch [8800/10000], Loss: 0.1110\n",
      "Epoch [8810/10000], Loss: 0.1093\n",
      "Epoch [8820/10000], Loss: 0.1077\n",
      "Epoch [8830/10000], Loss: 0.1063\n",
      "Epoch [8840/10000], Loss: 0.1050\n",
      "Epoch [8850/10000], Loss: 0.1038\n",
      "Epoch [8860/10000], Loss: 0.1027\n",
      "Epoch [8870/10000], Loss: 0.1017\n",
      "Epoch [8880/10000], Loss: 0.1008\n",
      "Epoch [8890/10000], Loss: 0.0999\n",
      "Epoch [8900/10000], Loss: 0.0992\n",
      "Epoch [8910/10000], Loss: 0.0985\n",
      "Epoch [8920/10000], Loss: 0.0978\n",
      "Epoch [8930/10000], Loss: 0.0972\n",
      "Epoch [8940/10000], Loss: 0.0967\n",
      "Epoch [8950/10000], Loss: 0.0961\n",
      "Epoch [8960/10000], Loss: 0.0956\n",
      "Epoch [8970/10000], Loss: 0.0951\n",
      "Epoch [8980/10000], Loss: 0.0947\n",
      "Epoch [8990/10000], Loss: 0.0956\n",
      "Epoch [9000/10000], Loss: 82.7196\n",
      "Epoch [9010/10000], Loss: 51.4890\n",
      "Epoch [9020/10000], Loss: 0.3421\n",
      "Epoch [9030/10000], Loss: 0.3202\n",
      "Epoch [9040/10000], Loss: 0.2999\n",
      "Epoch [9050/10000], Loss: 0.2810\n",
      "Epoch [9060/10000], Loss: 0.2634\n",
      "Epoch [9070/10000], Loss: 0.2471\n",
      "Epoch [9080/10000], Loss: 0.2321\n",
      "Epoch [9090/10000], Loss: 0.2183\n",
      "Epoch [9100/10000], Loss: 0.2057\n",
      "Epoch [9110/10000], Loss: 0.1944\n",
      "Epoch [9120/10000], Loss: 0.1841\n",
      "Epoch [9130/10000], Loss: 0.1747\n",
      "Epoch [9140/10000], Loss: 0.1663\n",
      "Epoch [9150/10000], Loss: 0.1586\n",
      "Epoch [9160/10000], Loss: 0.1517\n",
      "Epoch [9170/10000], Loss: 0.1456\n",
      "Epoch [9180/10000], Loss: 0.1401\n",
      "Epoch [9190/10000], Loss: 0.1352\n",
      "Epoch [9200/10000], Loss: 0.1308\n",
      "Epoch [9210/10000], Loss: 0.1268\n",
      "Epoch [9220/10000], Loss: 0.1233\n",
      "Epoch [9230/10000], Loss: 0.1201\n",
      "Epoch [9240/10000], Loss: 0.1171\n",
      "Epoch [9250/10000], Loss: 0.1146\n",
      "Epoch [9260/10000], Loss: 0.1123\n",
      "Epoch [9270/10000], Loss: 0.1102\n",
      "Epoch [9280/10000], Loss: 0.1084\n",
      "Epoch [9290/10000], Loss: 0.1068\n",
      "Epoch [9300/10000], Loss: 0.1053\n",
      "Epoch [9310/10000], Loss: 0.1040\n",
      "Epoch [9320/10000], Loss: 0.1027\n",
      "Epoch [9330/10000], Loss: 0.1016\n",
      "Epoch [9340/10000], Loss: 0.1006\n",
      "Epoch [9350/10000], Loss: 0.0997\n",
      "Epoch [9360/10000], Loss: 0.0989\n",
      "Epoch [9370/10000], Loss: 0.0982\n",
      "Epoch [9380/10000], Loss: 0.0975\n",
      "Epoch [9390/10000], Loss: 0.0969\n",
      "Epoch [9400/10000], Loss: 0.0963\n",
      "Epoch [9410/10000], Loss: 0.0958\n",
      "Epoch [9420/10000], Loss: 0.0954\n",
      "Epoch [9430/10000], Loss: 0.0954\n",
      "Epoch [9440/10000], Loss: 0.2918\n",
      "Epoch [9450/10000], Loss: 0.1192\n",
      "Epoch [9460/10000], Loss: 0.1072\n",
      "Epoch [9470/10000], Loss: 0.1009\n",
      "Epoch [9480/10000], Loss: 0.0976\n",
      "Epoch [9490/10000], Loss: 0.0959\n",
      "Epoch [9500/10000], Loss: 0.0950\n",
      "Epoch [9510/10000], Loss: 0.0944\n",
      "Epoch [9520/10000], Loss: 0.0954\n",
      "Epoch [9530/10000], Loss: 32.0121\n",
      "Epoch [9540/10000], Loss: 73.7982\n",
      "Epoch [9550/10000], Loss: 54.6735\n",
      "Epoch [9560/10000], Loss: 29.1905\n",
      "Epoch [9570/10000], Loss: 0.6629\n",
      "Epoch [9580/10000], Loss: 0.6395\n",
      "Epoch [9590/10000], Loss: 0.6167\n",
      "Epoch [9600/10000], Loss: 0.5947\n",
      "Epoch [9610/10000], Loss: 0.5735\n",
      "Epoch [9620/10000], Loss: 0.5531\n",
      "Epoch [9630/10000], Loss: 0.5333\n",
      "Epoch [9640/10000], Loss: 0.5142\n",
      "Epoch [9650/10000], Loss: 0.4957\n",
      "Epoch [9660/10000], Loss: 0.4780\n",
      "Epoch [9670/10000], Loss: 0.4607\n",
      "Epoch [9680/10000], Loss: 0.4441\n",
      "Epoch [9690/10000], Loss: 0.4281\n",
      "Epoch [9700/10000], Loss: 0.4126\n",
      "Epoch [9710/10000], Loss: 0.3978\n",
      "Epoch [9720/10000], Loss: 0.3836\n",
      "Epoch [9730/10000], Loss: 0.3699\n",
      "Epoch [9740/10000], Loss: 0.3569\n",
      "Epoch [9750/10000], Loss: 0.3444\n",
      "Epoch [9760/10000], Loss: 0.3326\n",
      "Epoch [9770/10000], Loss: 0.3212\n",
      "Epoch [9780/10000], Loss: 0.3103\n",
      "Epoch [9790/10000], Loss: 0.2999\n",
      "Epoch [9800/10000], Loss: 0.2900\n",
      "Epoch [9810/10000], Loss: 0.2805\n",
      "Epoch [9820/10000], Loss: 0.2714\n",
      "Epoch [9830/10000], Loss: 0.2627\n",
      "Epoch [9840/10000], Loss: 0.2544\n",
      "Epoch [9850/10000], Loss: 0.2464\n",
      "Epoch [9860/10000], Loss: 0.2389\n",
      "Epoch [9870/10000], Loss: 0.2318\n",
      "Epoch [9880/10000], Loss: 0.2250\n",
      "Epoch [9890/10000], Loss: 0.2184\n",
      "Epoch [9900/10000], Loss: 0.2122\n",
      "Epoch [9910/10000], Loss: 0.2064\n",
      "Epoch [9920/10000], Loss: 0.2008\n",
      "Epoch [9930/10000], Loss: 0.1955\n",
      "Epoch [9940/10000], Loss: 0.1905\n",
      "Epoch [9950/10000], Loss: 0.1857\n",
      "Epoch [9960/10000], Loss: 0.1811\n",
      "Epoch [9970/10000], Loss: 0.1767\n",
      "Epoch [9980/10000], Loss: 0.1725\n",
      "Epoch [9990/10000], Loss: 0.1685\n",
      "Epoch [10000/10000], Loss: 0.1646\n",
      "Validation Accuracy: 0.00\n",
      "Fold 3/4\n",
      "Epoch [10/10000], Loss: 58.1417\n",
      "Epoch [20/10000], Loss: 1.7016\n",
      "Epoch [30/10000], Loss: 52.0049\n",
      "Epoch [40/10000], Loss: 0.5923\n",
      "Epoch [50/10000], Loss: 0.5690\n",
      "Epoch [60/10000], Loss: 0.5464\n",
      "Epoch [70/10000], Loss: 0.5245\n",
      "Epoch [80/10000], Loss: 0.5032\n",
      "Epoch [90/10000], Loss: 0.4826\n",
      "Epoch [100/10000], Loss: 0.4626\n",
      "Epoch [110/10000], Loss: 0.4433\n",
      "Epoch [120/10000], Loss: 0.4247\n",
      "Epoch [130/10000], Loss: 0.4065\n",
      "Epoch [140/10000], Loss: 0.3890\n",
      "Epoch [150/10000], Loss: 0.3720\n",
      "Epoch [160/10000], Loss: 0.3557\n",
      "Epoch [170/10000], Loss: 0.3399\n",
      "Epoch [180/10000], Loss: 0.3247\n",
      "Epoch [190/10000], Loss: 0.3102\n",
      "Epoch [200/10000], Loss: 0.2961\n",
      "Epoch [210/10000], Loss: 0.2826\n",
      "Epoch [220/10000], Loss: 0.2697\n",
      "Epoch [230/10000], Loss: 0.2573\n",
      "Epoch [240/10000], Loss: 0.2454\n",
      "Epoch [250/10000], Loss: 0.2341\n",
      "Epoch [260/10000], Loss: 0.2233\n",
      "Epoch [270/10000], Loss: 0.2131\n",
      "Epoch [280/10000], Loss: 0.2034\n",
      "Epoch [290/10000], Loss: 0.1943\n",
      "Epoch [300/10000], Loss: 0.1858\n",
      "Epoch [310/10000], Loss: 0.1779\n",
      "Epoch [320/10000], Loss: 0.1705\n",
      "Epoch [330/10000], Loss: 0.1643\n",
      "Epoch [340/10000], Loss: 48.8343\n",
      "Epoch [350/10000], Loss: 77.6178\n",
      "Epoch [360/10000], Loss: 0.4820\n",
      "Epoch [370/10000], Loss: 0.4592\n",
      "Epoch [380/10000], Loss: 0.4377\n",
      "Epoch [390/10000], Loss: 0.4172\n",
      "Epoch [400/10000], Loss: 0.3979\n",
      "Epoch [410/10000], Loss: 0.3796\n",
      "Epoch [420/10000], Loss: 0.3624\n",
      "Epoch [430/10000], Loss: 0.3462\n",
      "Epoch [440/10000], Loss: 0.3311\n",
      "Epoch [450/10000], Loss: 0.3169\n",
      "Epoch [460/10000], Loss: 0.3035\n",
      "Epoch [470/10000], Loss: 0.2909\n",
      "Epoch [480/10000], Loss: 0.2790\n",
      "Epoch [490/10000], Loss: 0.2680\n",
      "Epoch [500/10000], Loss: 0.2576\n",
      "Epoch [510/10000], Loss: 0.2478\n",
      "Epoch [520/10000], Loss: 0.2385\n",
      "Epoch [530/10000], Loss: 0.2298\n",
      "Epoch [540/10000], Loss: 0.2216\n",
      "Epoch [550/10000], Loss: 0.2138\n",
      "Epoch [560/10000], Loss: 0.2064\n",
      "Epoch [570/10000], Loss: 0.1994\n",
      "Epoch [580/10000], Loss: 0.1927\n",
      "Epoch [590/10000], Loss: 0.1864\n",
      "Epoch [600/10000], Loss: 0.1803\n",
      "Epoch [610/10000], Loss: 0.1745\n",
      "Epoch [620/10000], Loss: 0.1691\n",
      "Epoch [630/10000], Loss: 0.1639\n",
      "Epoch [640/10000], Loss: 0.1590\n",
      "Epoch [650/10000], Loss: 0.1544\n",
      "Epoch [660/10000], Loss: 0.1500\n",
      "Epoch [670/10000], Loss: 0.1459\n",
      "Epoch [680/10000], Loss: 0.1420\n",
      "Epoch [690/10000], Loss: 0.1383\n",
      "Epoch [700/10000], Loss: 0.1358\n",
      "Epoch [710/10000], Loss: 43.7246\n",
      "Epoch [720/10000], Loss: 81.2431\n",
      "Epoch [730/10000], Loss: 62.4050\n",
      "Epoch [740/10000], Loss: 56.3862\n",
      "Epoch [750/10000], Loss: 0.7757\n",
      "Epoch [760/10000], Loss: 0.7514\n",
      "Epoch [770/10000], Loss: 0.7281\n",
      "Epoch [780/10000], Loss: 0.7055\n",
      "Epoch [790/10000], Loss: 0.6836\n",
      "Epoch [800/10000], Loss: 0.6624\n",
      "Epoch [810/10000], Loss: 0.6419\n",
      "Epoch [820/10000], Loss: 0.6218\n",
      "Epoch [830/10000], Loss: 0.6024\n",
      "Epoch [840/10000], Loss: 0.5835\n",
      "Epoch [850/10000], Loss: 0.5651\n",
      "Epoch [860/10000], Loss: 0.5474\n",
      "Epoch [870/10000], Loss: 0.5302\n",
      "Epoch [880/10000], Loss: 0.5137\n",
      "Epoch [890/10000], Loss: 0.4978\n",
      "Epoch [900/10000], Loss: 0.4824\n",
      "Epoch [910/10000], Loss: 0.4676\n",
      "Epoch [920/10000], Loss: 0.4534\n",
      "Epoch [930/10000], Loss: 0.4397\n",
      "Epoch [940/10000], Loss: 0.4265\n",
      "Epoch [950/10000], Loss: 0.4138\n",
      "Epoch [960/10000], Loss: 0.4016\n",
      "Epoch [970/10000], Loss: 0.3899\n",
      "Epoch [980/10000], Loss: 0.3787\n",
      "Epoch [990/10000], Loss: 0.3679\n",
      "Epoch [1000/10000], Loss: 0.3577\n",
      "Epoch [1010/10000], Loss: 0.3479\n",
      "Epoch [1020/10000], Loss: 0.3385\n",
      "Epoch [1030/10000], Loss: 0.3295\n",
      "Epoch [1040/10000], Loss: 0.3209\n",
      "Epoch [1050/10000], Loss: 0.3125\n",
      "Epoch [1060/10000], Loss: 0.3045\n",
      "Epoch [1070/10000], Loss: 0.2968\n",
      "Epoch [1080/10000], Loss: 0.2893\n",
      "Epoch [1090/10000], Loss: 0.2822\n",
      "Epoch [1100/10000], Loss: 0.2754\n",
      "Epoch [1110/10000], Loss: 0.2688\n",
      "Epoch [1120/10000], Loss: 0.2625\n",
      "Epoch [1130/10000], Loss: 0.2565\n",
      "Epoch [1140/10000], Loss: 0.2507\n",
      "Epoch [1150/10000], Loss: 0.2451\n",
      "Epoch [1160/10000], Loss: 0.2397\n",
      "Epoch [1170/10000], Loss: 0.2344\n",
      "Epoch [1180/10000], Loss: 0.2293\n",
      "Epoch [1190/10000], Loss: 0.2244\n",
      "Epoch [1200/10000], Loss: 0.2196\n",
      "Epoch [1210/10000], Loss: 0.2150\n",
      "Epoch [1220/10000], Loss: 0.2105\n",
      "Epoch [1230/10000], Loss: 0.2061\n",
      "Epoch [1240/10000], Loss: 0.2018\n",
      "Epoch [1250/10000], Loss: 0.1977\n",
      "Epoch [1260/10000], Loss: 0.1937\n",
      "Epoch [1270/10000], Loss: 0.1898\n",
      "Epoch [1280/10000], Loss: 0.1860\n",
      "Epoch [1290/10000], Loss: 0.1822\n",
      "Epoch [1300/10000], Loss: 0.1786\n",
      "Epoch [1310/10000], Loss: 0.1750\n",
      "Epoch [1320/10000], Loss: 0.1716\n",
      "Epoch [1330/10000], Loss: 0.1682\n",
      "Epoch [1340/10000], Loss: 0.1649\n",
      "Epoch [1350/10000], Loss: 0.1617\n",
      "Epoch [1360/10000], Loss: 0.1586\n",
      "Epoch [1370/10000], Loss: 0.1555\n",
      "Epoch [1380/10000], Loss: 0.1525\n",
      "Epoch [1390/10000], Loss: 0.1496\n",
      "Epoch [1400/10000], Loss: 0.1468\n",
      "Epoch [1410/10000], Loss: 0.1440\n",
      "Epoch [1420/10000], Loss: 0.1413\n",
      "Epoch [1430/10000], Loss: 0.1386\n",
      "Epoch [1440/10000], Loss: 0.1361\n",
      "Epoch [1450/10000], Loss: 0.1336\n",
      "Epoch [1460/10000], Loss: 0.1312\n",
      "Epoch [1470/10000], Loss: 0.1289\n",
      "Epoch [1480/10000], Loss: 0.1266\n",
      "Epoch [1490/10000], Loss: 0.1245\n",
      "Epoch [1500/10000], Loss: 0.1224\n",
      "Epoch [1510/10000], Loss: 0.1205\n",
      "Epoch [1520/10000], Loss: 0.1842\n",
      "Epoch [1530/10000], Loss: 27.5917\n",
      "Epoch [1540/10000], Loss: 0.3362\n",
      "Epoch [1550/10000], Loss: 0.3143\n",
      "Epoch [1560/10000], Loss: 0.2942\n",
      "Epoch [1570/10000], Loss: 0.2758\n",
      "Epoch [1580/10000], Loss: 0.2588\n",
      "Epoch [1590/10000], Loss: 0.2434\n",
      "Epoch [1600/10000], Loss: 0.2295\n",
      "Epoch [1610/10000], Loss: 0.2168\n",
      "Epoch [1620/10000], Loss: 0.2054\n",
      "Epoch [1630/10000], Loss: 0.1953\n",
      "Epoch [1640/10000], Loss: 0.1863\n",
      "Epoch [1650/10000], Loss: 0.1781\n",
      "Epoch [1660/10000], Loss: 0.1709\n",
      "Epoch [1670/10000], Loss: 0.1646\n",
      "Epoch [1680/10000], Loss: 0.1589\n",
      "Epoch [1690/10000], Loss: 0.1539\n",
      "Epoch [1700/10000], Loss: 0.1495\n",
      "Epoch [1710/10000], Loss: 0.1454\n",
      "Epoch [1720/10000], Loss: 0.1419\n",
      "Epoch [1730/10000], Loss: 0.1387\n",
      "Epoch [1740/10000], Loss: 0.1359\n",
      "Epoch [1750/10000], Loss: 0.1333\n",
      "Epoch [1760/10000], Loss: 0.1309\n",
      "Epoch [1770/10000], Loss: 0.1287\n",
      "Epoch [1780/10000], Loss: 0.1266\n",
      "Epoch [1790/10000], Loss: 0.1246\n",
      "Epoch [1800/10000], Loss: 0.1227\n",
      "Epoch [1810/10000], Loss: 0.1208\n",
      "Epoch [1820/10000], Loss: 0.1191\n",
      "Epoch [1830/10000], Loss: 0.1262\n",
      "Epoch [1840/10000], Loss: 83.5131\n",
      "Epoch [1850/10000], Loss: 28.0636\n",
      "Epoch [1860/10000], Loss: 57.2410\n",
      "Epoch [1870/10000], Loss: 0.9717\n",
      "Epoch [1880/10000], Loss: 0.7208\n",
      "Epoch [1890/10000], Loss: 0.6972\n",
      "Epoch [1900/10000], Loss: 0.6744\n",
      "Epoch [1910/10000], Loss: 0.6524\n",
      "Epoch [1920/10000], Loss: 0.6311\n",
      "Epoch [1930/10000], Loss: 0.6104\n",
      "Epoch [1940/10000], Loss: 0.5904\n",
      "Epoch [1950/10000], Loss: 0.5710\n",
      "Epoch [1960/10000], Loss: 0.5521\n",
      "Epoch [1970/10000], Loss: 0.5338\n",
      "Epoch [1980/10000], Loss: 0.5161\n",
      "Epoch [1990/10000], Loss: 0.4990\n",
      "Epoch [2000/10000], Loss: 0.4826\n",
      "Epoch [2010/10000], Loss: 0.4668\n",
      "Epoch [2020/10000], Loss: 0.4517\n",
      "Epoch [2030/10000], Loss: 0.4372\n",
      "Epoch [2040/10000], Loss: 0.4233\n",
      "Epoch [2050/10000], Loss: 0.4100\n",
      "Epoch [2060/10000], Loss: 0.3972\n",
      "Epoch [2070/10000], Loss: 0.3849\n",
      "Epoch [2080/10000], Loss: 0.3732\n",
      "Epoch [2090/10000], Loss: 0.3619\n",
      "Epoch [2100/10000], Loss: 0.3510\n",
      "Epoch [2110/10000], Loss: 0.3406\n",
      "Epoch [2120/10000], Loss: 0.3307\n",
      "Epoch [2130/10000], Loss: 0.3213\n",
      "Epoch [2140/10000], Loss: 0.3121\n",
      "Epoch [2150/10000], Loss: 0.3034\n",
      "Epoch [2160/10000], Loss: 0.2949\n",
      "Epoch [2170/10000], Loss: 0.2868\n",
      "Epoch [2180/10000], Loss: 0.2791\n",
      "Epoch [2190/10000], Loss: 0.2718\n",
      "Epoch [2200/10000], Loss: 0.2647\n",
      "Epoch [2210/10000], Loss: 0.2580\n",
      "Epoch [2220/10000], Loss: 0.2515\n",
      "Epoch [2230/10000], Loss: 0.2453\n",
      "Epoch [2240/10000], Loss: 0.2394\n",
      "Epoch [2250/10000], Loss: 0.2337\n",
      "Epoch [2260/10000], Loss: 0.2283\n",
      "Epoch [2270/10000], Loss: 0.2231\n",
      "Epoch [2280/10000], Loss: 0.2181\n",
      "Epoch [2290/10000], Loss: 0.2133\n",
      "Epoch [2300/10000], Loss: 0.2087\n",
      "Epoch [2310/10000], Loss: 0.2042\n",
      "Epoch [2320/10000], Loss: 0.1999\n",
      "Epoch [2330/10000], Loss: 0.1957\n",
      "Epoch [2340/10000], Loss: 0.1918\n",
      "Epoch [2350/10000], Loss: 0.1881\n",
      "Epoch [2360/10000], Loss: 0.1845\n",
      "Epoch [2370/10000], Loss: 0.1810\n",
      "Epoch [2380/10000], Loss: 0.1777\n",
      "Epoch [2390/10000], Loss: 0.1745\n",
      "Epoch [2400/10000], Loss: 0.1713\n",
      "Epoch [2410/10000], Loss: 0.1684\n",
      "Epoch [2420/10000], Loss: 0.1656\n",
      "Epoch [2430/10000], Loss: 0.1629\n",
      "Epoch [2440/10000], Loss: 0.1603\n",
      "Epoch [2450/10000], Loss: 0.1578\n",
      "Epoch [2460/10000], Loss: 0.1553\n",
      "Epoch [2470/10000], Loss: 0.1530\n",
      "Epoch [2480/10000], Loss: 0.1507\n",
      "Epoch [2490/10000], Loss: 0.1484\n",
      "Epoch [2500/10000], Loss: 0.1463\n",
      "Epoch [2510/10000], Loss: 0.1442\n",
      "Epoch [2520/10000], Loss: 0.1422\n",
      "Epoch [2530/10000], Loss: 0.1402\n",
      "Epoch [2540/10000], Loss: 0.1383\n",
      "Epoch [2550/10000], Loss: 0.1364\n",
      "Epoch [2560/10000], Loss: 0.1346\n",
      "Epoch [2570/10000], Loss: 0.1328\n",
      "Epoch [2580/10000], Loss: 0.1311\n",
      "Epoch [2590/10000], Loss: 0.1294\n",
      "Epoch [2600/10000], Loss: 0.1277\n",
      "Epoch [2610/10000], Loss: 0.1261\n",
      "Epoch [2620/10000], Loss: 0.1245\n",
      "Epoch [2630/10000], Loss: 0.1230\n",
      "Epoch [2640/10000], Loss: 0.1215\n",
      "Epoch [2650/10000], Loss: 0.1200\n",
      "Epoch [2660/10000], Loss: 0.1186\n",
      "Epoch [2670/10000], Loss: 0.1172\n",
      "Epoch [2680/10000], Loss: 0.1158\n",
      "Epoch [2690/10000], Loss: 0.1146\n",
      "Epoch [2700/10000], Loss: 0.1212\n",
      "Epoch [2710/10000], Loss: 60.5261\n",
      "Epoch [2720/10000], Loss: 3.5295\n",
      "Epoch [2730/10000], Loss: 5.4120\n",
      "Epoch [2740/10000], Loss: 19.0059\n",
      "Epoch [2750/10000], Loss: 0.7106\n",
      "Epoch [2760/10000], Loss: 0.6871\n",
      "Epoch [2770/10000], Loss: 0.6644\n",
      "Epoch [2780/10000], Loss: 0.6424\n",
      "Epoch [2790/10000], Loss: 0.6211\n",
      "Epoch [2800/10000], Loss: 0.6005\n",
      "Epoch [2810/10000], Loss: 0.5804\n",
      "Epoch [2820/10000], Loss: 0.5610\n",
      "Epoch [2830/10000], Loss: 0.5422\n",
      "Epoch [2840/10000], Loss: 0.5240\n",
      "Epoch [2850/10000], Loss: 0.5063\n",
      "Epoch [2860/10000], Loss: 0.4893\n",
      "Epoch [2870/10000], Loss: 0.4730\n",
      "Epoch [2880/10000], Loss: 0.4573\n",
      "Epoch [2890/10000], Loss: 0.4423\n",
      "Epoch [2900/10000], Loss: 0.4279\n",
      "Epoch [2910/10000], Loss: 0.4141\n",
      "Epoch [2920/10000], Loss: 0.4009\n",
      "Epoch [2930/10000], Loss: 0.3882\n",
      "Epoch [2940/10000], Loss: 0.3760\n",
      "Epoch [2950/10000], Loss: 0.3644\n",
      "Epoch [2960/10000], Loss: 0.3532\n",
      "Epoch [2970/10000], Loss: 0.3425\n",
      "Epoch [2980/10000], Loss: 0.3322\n",
      "Epoch [2990/10000], Loss: 0.3225\n",
      "Epoch [3000/10000], Loss: 0.3131\n",
      "Epoch [3010/10000], Loss: 0.3041\n",
      "Epoch [3020/10000], Loss: 0.2954\n",
      "Epoch [3030/10000], Loss: 0.2871\n",
      "Epoch [3040/10000], Loss: 0.2791\n",
      "Epoch [3050/10000], Loss: 0.2716\n",
      "Epoch [3060/10000], Loss: 0.2643\n",
      "Epoch [3070/10000], Loss: 0.2574\n",
      "Epoch [3080/10000], Loss: 0.2507\n",
      "Epoch [3090/10000], Loss: 0.2444\n",
      "Epoch [3100/10000], Loss: 0.2383\n",
      "Epoch [3110/10000], Loss: 0.2324\n",
      "Epoch [3120/10000], Loss: 0.2269\n",
      "Epoch [3130/10000], Loss: 0.2216\n",
      "Epoch [3140/10000], Loss: 0.2165\n",
      "Epoch [3150/10000], Loss: 0.2116\n",
      "Epoch [3160/10000], Loss: 0.2069\n",
      "Epoch [3170/10000], Loss: 0.2023\n",
      "Epoch [3180/10000], Loss: 0.1979\n",
      "Epoch [3190/10000], Loss: 0.1937\n",
      "Epoch [3200/10000], Loss: 0.1896\n",
      "Epoch [3210/10000], Loss: 0.1858\n",
      "Epoch [3220/10000], Loss: 0.1822\n",
      "Epoch [3230/10000], Loss: 0.1787\n",
      "Epoch [3240/10000], Loss: 0.1753\n",
      "Epoch [3250/10000], Loss: 0.1720\n",
      "Epoch [3260/10000], Loss: 0.1688\n",
      "Epoch [3270/10000], Loss: 0.1658\n",
      "Epoch [3280/10000], Loss: 0.1630\n",
      "Epoch [3290/10000], Loss: 0.1603\n",
      "Epoch [3300/10000], Loss: 0.1577\n",
      "Epoch [3310/10000], Loss: 0.1552\n",
      "Epoch [3320/10000], Loss: 0.1528\n",
      "Epoch [3330/10000], Loss: 0.1505\n",
      "Epoch [3340/10000], Loss: 0.1483\n",
      "Epoch [3350/10000], Loss: 0.1462\n",
      "Epoch [3360/10000], Loss: 0.1441\n",
      "Epoch [3370/10000], Loss: 0.1422\n",
      "Epoch [3380/10000], Loss: 0.1403\n",
      "Epoch [3390/10000], Loss: 0.1385\n",
      "Epoch [3400/10000], Loss: 0.1368\n",
      "Epoch [3410/10000], Loss: 0.1351\n",
      "Epoch [3420/10000], Loss: 0.1335\n",
      "Epoch [3430/10000], Loss: 0.1320\n",
      "Epoch [3440/10000], Loss: 0.1305\n",
      "Epoch [3450/10000], Loss: 0.1290\n",
      "Epoch [3460/10000], Loss: 0.1275\n",
      "Epoch [3470/10000], Loss: 0.1261\n",
      "Epoch [3480/10000], Loss: 0.1248\n",
      "Epoch [3490/10000], Loss: 0.1234\n",
      "Epoch [3500/10000], Loss: 0.1221\n",
      "Epoch [3510/10000], Loss: 0.1207\n",
      "Epoch [3520/10000], Loss: 0.1195\n",
      "Epoch [3530/10000], Loss: 0.1182\n",
      "Epoch [3540/10000], Loss: 0.1170\n",
      "Epoch [3550/10000], Loss: 0.1158\n",
      "Epoch [3560/10000], Loss: 0.1146\n",
      "Epoch [3570/10000], Loss: 0.1135\n",
      "Epoch [3580/10000], Loss: 0.1128\n",
      "Epoch [3590/10000], Loss: 15.8791\n",
      "Epoch [3600/10000], Loss: 41.9104\n",
      "Epoch [3610/10000], Loss: 79.8323\n",
      "Epoch [3620/10000], Loss: 60.1286\n",
      "Epoch [3630/10000], Loss: 0.6677\n",
      "Epoch [3640/10000], Loss: 0.6442\n",
      "Epoch [3650/10000], Loss: 0.6215\n",
      "Epoch [3660/10000], Loss: 0.5996\n",
      "Epoch [3670/10000], Loss: 0.5785\n",
      "Epoch [3680/10000], Loss: 0.5581\n",
      "Epoch [3690/10000], Loss: 0.5383\n",
      "Epoch [3700/10000], Loss: 0.5191\n",
      "Epoch [3710/10000], Loss: 0.5007\n",
      "Epoch [3720/10000], Loss: 0.4828\n",
      "Epoch [3730/10000], Loss: 0.4656\n",
      "Epoch [3740/10000], Loss: 0.4491\n",
      "Epoch [3750/10000], Loss: 0.4333\n",
      "Epoch [3760/10000], Loss: 0.4181\n",
      "Epoch [3770/10000], Loss: 0.4037\n",
      "Epoch [3780/10000], Loss: 0.3899\n",
      "Epoch [3790/10000], Loss: 0.3768\n",
      "Epoch [3800/10000], Loss: 0.3642\n",
      "Epoch [3810/10000], Loss: 0.3521\n",
      "Epoch [3820/10000], Loss: 0.3406\n",
      "Epoch [3830/10000], Loss: 0.3296\n",
      "Epoch [3840/10000], Loss: 0.3190\n",
      "Epoch [3850/10000], Loss: 0.3090\n",
      "Epoch [3860/10000], Loss: 0.2994\n",
      "Epoch [3870/10000], Loss: 0.2903\n",
      "Epoch [3880/10000], Loss: 0.2816\n",
      "Epoch [3890/10000], Loss: 0.2733\n",
      "Epoch [3900/10000], Loss: 0.2653\n",
      "Epoch [3910/10000], Loss: 0.2577\n",
      "Epoch [3920/10000], Loss: 0.2504\n",
      "Epoch [3930/10000], Loss: 0.2435\n",
      "Epoch [3940/10000], Loss: 0.2369\n",
      "Epoch [3950/10000], Loss: 0.2307\n",
      "Epoch [3960/10000], Loss: 0.2247\n",
      "Epoch [3970/10000], Loss: 0.2191\n",
      "Epoch [3980/10000], Loss: 0.2137\n",
      "Epoch [3990/10000], Loss: 0.2085\n",
      "Epoch [4000/10000], Loss: 0.2036\n",
      "Epoch [4010/10000], Loss: 0.1989\n",
      "Epoch [4020/10000], Loss: 0.1944\n",
      "Epoch [4030/10000], Loss: 0.1900\n",
      "Epoch [4040/10000], Loss: 0.1859\n",
      "Epoch [4050/10000], Loss: 0.1819\n",
      "Epoch [4060/10000], Loss: 0.1781\n",
      "Epoch [4070/10000], Loss: 0.1745\n",
      "Epoch [4080/10000], Loss: 0.1711\n",
      "Epoch [4090/10000], Loss: 0.1678\n",
      "Epoch [4100/10000], Loss: 0.1646\n",
      "Epoch [4110/10000], Loss: 0.1616\n",
      "Epoch [4120/10000], Loss: 0.1587\n",
      "Epoch [4130/10000], Loss: 0.1559\n",
      "Epoch [4140/10000], Loss: 0.1534\n",
      "Epoch [4150/10000], Loss: 0.1508\n",
      "Epoch [4160/10000], Loss: 0.1484\n",
      "Epoch [4170/10000], Loss: 0.1462\n",
      "Epoch [4180/10000], Loss: 0.1440\n",
      "Epoch [4190/10000], Loss: 0.1419\n",
      "Epoch [4200/10000], Loss: 0.1399\n",
      "Epoch [4210/10000], Loss: 0.1380\n",
      "Epoch [4220/10000], Loss: 0.1362\n",
      "Epoch [4230/10000], Loss: 0.1345\n",
      "Epoch [4240/10000], Loss: 0.1329\n",
      "Epoch [4250/10000], Loss: 0.1314\n",
      "Epoch [4260/10000], Loss: 0.1299\n",
      "Epoch [4270/10000], Loss: 0.1285\n",
      "Epoch [4280/10000], Loss: 0.1272\n",
      "Epoch [4290/10000], Loss: 0.1259\n",
      "Epoch [4300/10000], Loss: 0.1246\n",
      "Epoch [4310/10000], Loss: 0.1234\n",
      "Epoch [4320/10000], Loss: 0.1222\n",
      "Epoch [4330/10000], Loss: 0.1210\n",
      "Epoch [4340/10000], Loss: 0.1199\n",
      "Epoch [4350/10000], Loss: 0.1187\n",
      "Epoch [4360/10000], Loss: 0.1176\n",
      "Epoch [4370/10000], Loss: 0.1166\n",
      "Epoch [4380/10000], Loss: 0.1155\n",
      "Epoch [4390/10000], Loss: 0.1145\n",
      "Epoch [4400/10000], Loss: 0.1134\n",
      "Epoch [4410/10000], Loss: 0.1125\n",
      "Epoch [4420/10000], Loss: 0.1116\n",
      "Epoch [4430/10000], Loss: 0.1196\n",
      "Epoch [4440/10000], Loss: 77.5143\n",
      "Epoch [4450/10000], Loss: 80.8873\n",
      "Epoch [4460/10000], Loss: 81.2942\n",
      "Epoch [4470/10000], Loss: 62.1131\n",
      "Epoch [4480/10000], Loss: 0.6744\n",
      "Epoch [4490/10000], Loss: 0.6511\n",
      "Epoch [4500/10000], Loss: 0.6286\n",
      "Epoch [4510/10000], Loss: 0.6070\n",
      "Epoch [4520/10000], Loss: 0.5862\n",
      "Epoch [4530/10000], Loss: 0.5660\n",
      "Epoch [4540/10000], Loss: 0.5466\n",
      "Epoch [4550/10000], Loss: 0.5278\n",
      "Epoch [4560/10000], Loss: 0.5096\n",
      "Epoch [4570/10000], Loss: 0.4921\n",
      "Epoch [4580/10000], Loss: 0.4752\n",
      "Epoch [4590/10000], Loss: 0.4589\n",
      "Epoch [4600/10000], Loss: 0.4433\n",
      "Epoch [4610/10000], Loss: 0.4282\n",
      "Epoch [4620/10000], Loss: 0.4139\n",
      "Epoch [4630/10000], Loss: 0.4001\n",
      "Epoch [4640/10000], Loss: 0.3869\n",
      "Epoch [4650/10000], Loss: 0.3742\n",
      "Epoch [4660/10000], Loss: 0.3621\n",
      "Epoch [4670/10000], Loss: 0.3505\n",
      "Epoch [4680/10000], Loss: 0.3394\n",
      "Epoch [4690/10000], Loss: 0.3288\n",
      "Epoch [4700/10000], Loss: 0.3186\n",
      "Epoch [4710/10000], Loss: 0.3090\n",
      "Epoch [4720/10000], Loss: 0.2997\n",
      "Epoch [4730/10000], Loss: 0.2908\n",
      "Epoch [4740/10000], Loss: 0.2823\n",
      "Epoch [4750/10000], Loss: 0.2742\n",
      "Epoch [4760/10000], Loss: 0.2664\n",
      "Epoch [4770/10000], Loss: 0.2591\n",
      "Epoch [4780/10000], Loss: 0.2520\n",
      "Epoch [4790/10000], Loss: 0.2452\n",
      "Epoch [4800/10000], Loss: 0.2388\n",
      "Epoch [4810/10000], Loss: 0.2326\n",
      "Epoch [4820/10000], Loss: 0.2267\n",
      "Epoch [4830/10000], Loss: 0.2211\n",
      "Epoch [4840/10000], Loss: 0.2157\n",
      "Epoch [4850/10000], Loss: 0.2106\n",
      "Epoch [4860/10000], Loss: 0.2057\n",
      "Epoch [4870/10000], Loss: 0.2009\n",
      "Epoch [4880/10000], Loss: 0.1964\n",
      "Epoch [4890/10000], Loss: 0.1920\n",
      "Epoch [4900/10000], Loss: 0.1878\n",
      "Epoch [4910/10000], Loss: 0.1838\n",
      "Epoch [4920/10000], Loss: 0.1801\n",
      "Epoch [4930/10000], Loss: 0.1764\n",
      "Epoch [4940/10000], Loss: 0.1729\n",
      "Epoch [4950/10000], Loss: 0.1696\n",
      "Epoch [4960/10000], Loss: 0.1664\n",
      "Epoch [4970/10000], Loss: 0.1633\n",
      "Epoch [4980/10000], Loss: 0.1603\n",
      "Epoch [4990/10000], Loss: 0.1576\n",
      "Epoch [5000/10000], Loss: 0.1549\n",
      "Epoch [5010/10000], Loss: 0.1524\n",
      "Epoch [5020/10000], Loss: 0.1500\n",
      "Epoch [5030/10000], Loss: 0.1477\n",
      "Epoch [5040/10000], Loss: 0.1455\n",
      "Epoch [5050/10000], Loss: 0.1433\n",
      "Epoch [5060/10000], Loss: 0.1412\n",
      "Epoch [5070/10000], Loss: 0.1393\n",
      "Epoch [5080/10000], Loss: 0.1374\n",
      "Epoch [5090/10000], Loss: 0.1356\n",
      "Epoch [5100/10000], Loss: 0.1339\n",
      "Epoch [5110/10000], Loss: 0.1323\n",
      "Epoch [5120/10000], Loss: 0.1308\n",
      "Epoch [5130/10000], Loss: 0.1293\n",
      "Epoch [5140/10000], Loss: 0.1280\n",
      "Epoch [5150/10000], Loss: 0.1267\n",
      "Epoch [5160/10000], Loss: 0.1254\n",
      "Epoch [5170/10000], Loss: 0.1241\n",
      "Epoch [5180/10000], Loss: 0.1230\n",
      "Epoch [5190/10000], Loss: 0.1218\n",
      "Epoch [5200/10000], Loss: 0.1207\n",
      "Epoch [5210/10000], Loss: 0.1196\n",
      "Epoch [5220/10000], Loss: 0.1186\n",
      "Epoch [5230/10000], Loss: 0.1176\n",
      "Epoch [5240/10000], Loss: 0.1166\n",
      "Epoch [5250/10000], Loss: 0.1156\n",
      "Epoch [5260/10000], Loss: 0.1146\n",
      "Epoch [5270/10000], Loss: 0.1137\n",
      "Epoch [5280/10000], Loss: 0.1127\n",
      "Epoch [5290/10000], Loss: 0.1118\n",
      "Epoch [5300/10000], Loss: 0.1109\n",
      "Epoch [5310/10000], Loss: 0.1105\n",
      "Epoch [5320/10000], Loss: 61.9416\n",
      "Epoch [5330/10000], Loss: 4.8977\n",
      "Epoch [5340/10000], Loss: 20.9587\n",
      "Epoch [5350/10000], Loss: 0.4661\n",
      "Epoch [5360/10000], Loss: 0.4437\n",
      "Epoch [5370/10000], Loss: 0.4223\n",
      "Epoch [5380/10000], Loss: 0.4020\n",
      "Epoch [5390/10000], Loss: 0.3826\n",
      "Epoch [5400/10000], Loss: 0.3641\n",
      "Epoch [5410/10000], Loss: 0.3466\n",
      "Epoch [5420/10000], Loss: 0.3300\n",
      "Epoch [5430/10000], Loss: 0.3145\n",
      "Epoch [5440/10000], Loss: 0.2999\n",
      "Epoch [5450/10000], Loss: 0.2863\n",
      "Epoch [5460/10000], Loss: 0.2736\n",
      "Epoch [5470/10000], Loss: 0.2618\n",
      "Epoch [5480/10000], Loss: 0.2507\n",
      "Epoch [5490/10000], Loss: 0.2405\n",
      "Epoch [5500/10000], Loss: 0.2310\n",
      "Epoch [5510/10000], Loss: 0.2221\n",
      "Epoch [5520/10000], Loss: 0.2138\n",
      "Epoch [5530/10000], Loss: 0.2061\n",
      "Epoch [5540/10000], Loss: 0.1990\n",
      "Epoch [5550/10000], Loss: 0.1923\n",
      "Epoch [5560/10000], Loss: 0.1862\n",
      "Epoch [5570/10000], Loss: 0.1804\n",
      "Epoch [5580/10000], Loss: 0.1750\n",
      "Epoch [5590/10000], Loss: 0.1701\n",
      "Epoch [5600/10000], Loss: 0.1654\n",
      "Epoch [5610/10000], Loss: 0.1610\n",
      "Epoch [5620/10000], Loss: 0.1569\n",
      "Epoch [5630/10000], Loss: 0.1531\n",
      "Epoch [5640/10000], Loss: 0.1496\n",
      "Epoch [5650/10000], Loss: 0.1463\n",
      "Epoch [5660/10000], Loss: 0.1432\n",
      "Epoch [5670/10000], Loss: 0.1404\n",
      "Epoch [5680/10000], Loss: 0.1377\n",
      "Epoch [5690/10000], Loss: 0.1353\n",
      "Epoch [5700/10000], Loss: 0.1330\n",
      "Epoch [5710/10000], Loss: 0.1309\n",
      "Epoch [5720/10000], Loss: 0.1289\n",
      "Epoch [5730/10000], Loss: 0.1271\n",
      "Epoch [5740/10000], Loss: 0.1253\n",
      "Epoch [5750/10000], Loss: 0.1238\n",
      "Epoch [5760/10000], Loss: 0.1223\n",
      "Epoch [5770/10000], Loss: 0.1209\n",
      "Epoch [5780/10000], Loss: 0.1197\n",
      "Epoch [5790/10000], Loss: 0.1185\n",
      "Epoch [5800/10000], Loss: 0.1174\n",
      "Epoch [5810/10000], Loss: 0.1163\n",
      "Epoch [5820/10000], Loss: 0.1154\n",
      "Epoch [5830/10000], Loss: 0.1144\n",
      "Epoch [5840/10000], Loss: 0.1135\n",
      "Epoch [5850/10000], Loss: 0.1126\n",
      "Epoch [5860/10000], Loss: 0.1117\n",
      "Epoch [5870/10000], Loss: 0.1109\n",
      "Epoch [5880/10000], Loss: 0.1102\n",
      "Epoch [5890/10000], Loss: 0.1234\n",
      "Epoch [5900/10000], Loss: 85.2748\n",
      "Epoch [5910/10000], Loss: 12.2951\n",
      "Epoch [5920/10000], Loss: 43.3115\n",
      "Epoch [5930/10000], Loss: 0.6714\n",
      "Epoch [5940/10000], Loss: 0.6476\n",
      "Epoch [5950/10000], Loss: 0.6245\n",
      "Epoch [5960/10000], Loss: 0.6023\n",
      "Epoch [5970/10000], Loss: 0.5808\n",
      "Epoch [5980/10000], Loss: 0.5601\n",
      "Epoch [5990/10000], Loss: 0.5402\n",
      "Epoch [6000/10000], Loss: 0.5209\n",
      "Epoch [6010/10000], Loss: 0.5023\n",
      "Epoch [6020/10000], Loss: 0.4844\n",
      "Epoch [6030/10000], Loss: 0.4671\n",
      "Epoch [6040/10000], Loss: 0.4504\n",
      "Epoch [6050/10000], Loss: 0.4345\n",
      "Epoch [6060/10000], Loss: 0.4193\n",
      "Epoch [6070/10000], Loss: 0.4048\n",
      "Epoch [6080/10000], Loss: 0.3909\n",
      "Epoch [6090/10000], Loss: 0.3776\n",
      "Epoch [6100/10000], Loss: 0.3648\n",
      "Epoch [6110/10000], Loss: 0.3526\n",
      "Epoch [6120/10000], Loss: 0.3410\n",
      "Epoch [6130/10000], Loss: 0.3298\n",
      "Epoch [6140/10000], Loss: 0.3192\n",
      "Epoch [6150/10000], Loss: 0.3091\n",
      "Epoch [6160/10000], Loss: 0.2995\n",
      "Epoch [6170/10000], Loss: 0.2903\n",
      "Epoch [6180/10000], Loss: 0.2814\n",
      "Epoch [6190/10000], Loss: 0.2730\n",
      "Epoch [6200/10000], Loss: 0.2649\n",
      "Epoch [6210/10000], Loss: 0.2572\n",
      "Epoch [6220/10000], Loss: 0.2499\n",
      "Epoch [6230/10000], Loss: 0.2430\n",
      "Epoch [6240/10000], Loss: 0.2364\n",
      "Epoch [6250/10000], Loss: 0.2300\n",
      "Epoch [6260/10000], Loss: 0.2240\n",
      "Epoch [6270/10000], Loss: 0.2183\n",
      "Epoch [6280/10000], Loss: 0.2129\n",
      "Epoch [6290/10000], Loss: 0.2077\n",
      "Epoch [6300/10000], Loss: 0.2027\n",
      "Epoch [6310/10000], Loss: 0.1980\n",
      "Epoch [6320/10000], Loss: 0.1934\n",
      "Epoch [6330/10000], Loss: 0.1889\n",
      "Epoch [6340/10000], Loss: 0.1847\n",
      "Epoch [6350/10000], Loss: 0.1807\n",
      "Epoch [6360/10000], Loss: 0.1769\n",
      "Epoch [6370/10000], Loss: 0.1733\n",
      "Epoch [6380/10000], Loss: 0.1699\n",
      "Epoch [6390/10000], Loss: 0.1665\n",
      "Epoch [6400/10000], Loss: 0.1633\n",
      "Epoch [6410/10000], Loss: 0.1602\n",
      "Epoch [6420/10000], Loss: 0.1573\n",
      "Epoch [6430/10000], Loss: 0.1545\n",
      "Epoch [6440/10000], Loss: 0.1519\n",
      "Epoch [6450/10000], Loss: 0.1494\n",
      "Epoch [6460/10000], Loss: 0.1470\n",
      "Epoch [6470/10000], Loss: 0.1447\n",
      "Epoch [6480/10000], Loss: 0.1426\n",
      "Epoch [6490/10000], Loss: 0.1405\n",
      "Epoch [6500/10000], Loss: 0.1385\n",
      "Epoch [6510/10000], Loss: 0.1365\n",
      "Epoch [6520/10000], Loss: 0.1347\n",
      "Epoch [6530/10000], Loss: 0.1330\n",
      "Epoch [6540/10000], Loss: 0.1313\n",
      "Epoch [6550/10000], Loss: 0.1298\n",
      "Epoch [6560/10000], Loss: 0.1283\n",
      "Epoch [6570/10000], Loss: 0.1269\n",
      "Epoch [6580/10000], Loss: 0.1256\n",
      "Epoch [6590/10000], Loss: 0.1243\n",
      "Epoch [6600/10000], Loss: 0.1231\n",
      "Epoch [6610/10000], Loss: 0.1220\n",
      "Epoch [6620/10000], Loss: 0.1208\n",
      "Epoch [6630/10000], Loss: 0.1198\n",
      "Epoch [6640/10000], Loss: 0.1188\n",
      "Epoch [6650/10000], Loss: 0.1178\n",
      "Epoch [6660/10000], Loss: 0.1169\n",
      "Epoch [6670/10000], Loss: 0.1160\n",
      "Epoch [6680/10000], Loss: 0.1151\n",
      "Epoch [6690/10000], Loss: 0.1142\n",
      "Epoch [6700/10000], Loss: 0.1134\n",
      "Epoch [6710/10000], Loss: 0.1125\n",
      "Epoch [6720/10000], Loss: 0.1117\n",
      "Epoch [6730/10000], Loss: 0.1109\n",
      "Epoch [6740/10000], Loss: 0.1103\n",
      "Epoch [6750/10000], Loss: 0.1220\n",
      "Epoch [6760/10000], Loss: 86.4124\n",
      "Epoch [6770/10000], Loss: 29.7505\n",
      "Epoch [6780/10000], Loss: 0.5579\n",
      "Epoch [6790/10000], Loss: 0.5344\n",
      "Epoch [6800/10000], Loss: 0.5117\n",
      "Epoch [6810/10000], Loss: 0.4900\n",
      "Epoch [6820/10000], Loss: 0.4693\n",
      "Epoch [6830/10000], Loss: 0.4494\n",
      "Epoch [6840/10000], Loss: 0.4305\n",
      "Epoch [6850/10000], Loss: 0.4124\n",
      "Epoch [6860/10000], Loss: 0.3951\n",
      "Epoch [6870/10000], Loss: 0.3785\n",
      "Epoch [6880/10000], Loss: 0.3628\n",
      "Epoch [6890/10000], Loss: 0.3480\n",
      "Epoch [6900/10000], Loss: 0.3339\n",
      "Epoch [6910/10000], Loss: 0.3206\n",
      "Epoch [6920/10000], Loss: 0.3080\n",
      "Epoch [6930/10000], Loss: 0.2961\n",
      "Epoch [6940/10000], Loss: 0.2848\n",
      "Epoch [6950/10000], Loss: 0.2742\n",
      "Epoch [6960/10000], Loss: 0.2643\n",
      "Epoch [6970/10000], Loss: 0.2550\n",
      "Epoch [6980/10000], Loss: 0.2461\n",
      "Epoch [6990/10000], Loss: 0.2377\n",
      "Epoch [7000/10000], Loss: 0.2298\n",
      "Epoch [7010/10000], Loss: 0.2223\n",
      "Epoch [7020/10000], Loss: 0.2154\n",
      "Epoch [7030/10000], Loss: 0.2088\n",
      "Epoch [7040/10000], Loss: 0.2026\n",
      "Epoch [7050/10000], Loss: 0.1968\n",
      "Epoch [7060/10000], Loss: 0.1913\n",
      "Epoch [7070/10000], Loss: 0.1861\n",
      "Epoch [7080/10000], Loss: 0.1813\n",
      "Epoch [7090/10000], Loss: 0.1766\n",
      "Epoch [7100/10000], Loss: 0.1722\n",
      "Epoch [7110/10000], Loss: 0.1680\n",
      "Epoch [7120/10000], Loss: 0.1641\n",
      "Epoch [7130/10000], Loss: 0.1604\n",
      "Epoch [7140/10000], Loss: 0.1570\n",
      "Epoch [7150/10000], Loss: 0.1537\n",
      "Epoch [7160/10000], Loss: 0.1506\n",
      "Epoch [7170/10000], Loss: 0.1476\n",
      "Epoch [7180/10000], Loss: 0.1449\n",
      "Epoch [7190/10000], Loss: 0.1424\n",
      "Epoch [7200/10000], Loss: 0.1399\n",
      "Epoch [7210/10000], Loss: 0.1376\n",
      "Epoch [7220/10000], Loss: 0.1355\n",
      "Epoch [7230/10000], Loss: 0.1335\n",
      "Epoch [7240/10000], Loss: 0.1315\n",
      "Epoch [7250/10000], Loss: 0.1297\n",
      "Epoch [7260/10000], Loss: 0.1280\n",
      "Epoch [7270/10000], Loss: 0.1264\n",
      "Epoch [7280/10000], Loss: 0.1249\n",
      "Epoch [7290/10000], Loss: 0.1235\n",
      "Epoch [7300/10000], Loss: 0.1223\n",
      "Epoch [7310/10000], Loss: 0.1210\n",
      "Epoch [7320/10000], Loss: 0.1198\n",
      "Epoch [7330/10000], Loss: 0.1187\n",
      "Epoch [7340/10000], Loss: 0.1177\n",
      "Epoch [7350/10000], Loss: 0.1167\n",
      "Epoch [7360/10000], Loss: 0.1158\n",
      "Epoch [7370/10000], Loss: 0.1149\n",
      "Epoch [7380/10000], Loss: 0.1141\n",
      "Epoch [7390/10000], Loss: 0.1133\n",
      "Epoch [7400/10000], Loss: 0.1125\n",
      "Epoch [7410/10000], Loss: 0.1117\n",
      "Epoch [7420/10000], Loss: 0.1109\n",
      "Epoch [7430/10000], Loss: 0.1102\n",
      "Epoch [7440/10000], Loss: 0.1108\n",
      "Epoch [7450/10000], Loss: 0.1449\n",
      "Epoch [7460/10000], Loss: 0.1281\n",
      "Epoch [7470/10000], Loss: 0.1189\n",
      "Epoch [7480/10000], Loss: 0.1141\n",
      "Epoch [7490/10000], Loss: 0.1114\n",
      "Epoch [7500/10000], Loss: 0.1099\n",
      "Epoch [7510/10000], Loss: 0.1091\n",
      "Epoch [7520/10000], Loss: 0.1089\n",
      "Epoch [7530/10000], Loss: 62.2327\n",
      "Epoch [7540/10000], Loss: 5.1497\n",
      "Epoch [7550/10000], Loss: 25.2889\n",
      "Epoch [7560/10000], Loss: 0.4779\n",
      "Epoch [7570/10000], Loss: 0.4554\n",
      "Epoch [7580/10000], Loss: 0.4339\n",
      "Epoch [7590/10000], Loss: 0.4135\n",
      "Epoch [7600/10000], Loss: 0.3940\n",
      "Epoch [7610/10000], Loss: 0.3756\n",
      "Epoch [7620/10000], Loss: 0.3582\n",
      "Epoch [7630/10000], Loss: 0.3416\n",
      "Epoch [7640/10000], Loss: 0.3259\n",
      "Epoch [7650/10000], Loss: 0.3112\n",
      "Epoch [7660/10000], Loss: 0.2974\n",
      "Epoch [7670/10000], Loss: 0.2844\n",
      "Epoch [7680/10000], Loss: 0.2722\n",
      "Epoch [7690/10000], Loss: 0.2608\n",
      "Epoch [7700/10000], Loss: 0.2501\n",
      "Epoch [7710/10000], Loss: 0.2402\n",
      "Epoch [7720/10000], Loss: 0.2310\n",
      "Epoch [7730/10000], Loss: 0.2224\n",
      "Epoch [7740/10000], Loss: 0.2142\n",
      "Epoch [7750/10000], Loss: 0.2067\n",
      "Epoch [7760/10000], Loss: 0.1996\n",
      "Epoch [7770/10000], Loss: 0.1931\n",
      "Epoch [7780/10000], Loss: 0.1870\n",
      "Epoch [7790/10000], Loss: 0.1813\n",
      "Epoch [7800/10000], Loss: 0.1760\n",
      "Epoch [7810/10000], Loss: 0.1711\n",
      "Epoch [7820/10000], Loss: 0.1664\n",
      "Epoch [7830/10000], Loss: 0.1620\n",
      "Epoch [7840/10000], Loss: 0.1579\n",
      "Epoch [7850/10000], Loss: 0.1541\n",
      "Epoch [7860/10000], Loss: 0.1505\n",
      "Epoch [7870/10000], Loss: 0.1472\n",
      "Epoch [7880/10000], Loss: 0.1441\n",
      "Epoch [7890/10000], Loss: 0.1411\n",
      "Epoch [7900/10000], Loss: 0.1385\n",
      "Epoch [7910/10000], Loss: 0.1360\n",
      "Epoch [7920/10000], Loss: 0.1336\n",
      "Epoch [7930/10000], Loss: 0.1315\n",
      "Epoch [7940/10000], Loss: 0.1294\n",
      "Epoch [7950/10000], Loss: 0.1275\n",
      "Epoch [7960/10000], Loss: 0.1257\n",
      "Epoch [7970/10000], Loss: 0.1240\n",
      "Epoch [7980/10000], Loss: 0.1225\n",
      "Epoch [7990/10000], Loss: 0.1211\n",
      "Epoch [8000/10000], Loss: 0.1198\n",
      "Epoch [8010/10000], Loss: 0.1185\n",
      "Epoch [8020/10000], Loss: 0.1174\n",
      "Epoch [8030/10000], Loss: 0.1163\n",
      "Epoch [8040/10000], Loss: 0.1152\n",
      "Epoch [8050/10000], Loss: 0.1143\n",
      "Epoch [8060/10000], Loss: 0.1134\n",
      "Epoch [8070/10000], Loss: 0.1126\n",
      "Epoch [8080/10000], Loss: 0.1118\n",
      "Epoch [8090/10000], Loss: 0.1111\n",
      "Epoch [8100/10000], Loss: 0.1103\n",
      "Epoch [8110/10000], Loss: 0.1097\n",
      "Epoch [8120/10000], Loss: 0.1106\n",
      "Epoch [8130/10000], Loss: 39.6978\n",
      "Epoch [8140/10000], Loss: 9.5589\n",
      "Epoch [8150/10000], Loss: 77.9556\n",
      "Epoch [8160/10000], Loss: 0.6275\n",
      "Epoch [8170/10000], Loss: 0.6038\n",
      "Epoch [8180/10000], Loss: 0.5808\n",
      "Epoch [8190/10000], Loss: 0.5588\n",
      "Epoch [8200/10000], Loss: 0.5376\n",
      "Epoch [8210/10000], Loss: 0.5171\n",
      "Epoch [8220/10000], Loss: 0.4976\n",
      "Epoch [8230/10000], Loss: 0.4788\n",
      "Epoch [8240/10000], Loss: 0.4607\n",
      "Epoch [8250/10000], Loss: 0.4432\n",
      "Epoch [8260/10000], Loss: 0.4265\n",
      "Epoch [8270/10000], Loss: 0.4105\n",
      "Epoch [8280/10000], Loss: 0.3952\n",
      "Epoch [8290/10000], Loss: 0.3807\n",
      "Epoch [8300/10000], Loss: 0.3668\n",
      "Epoch [8310/10000], Loss: 0.3536\n",
      "Epoch [8320/10000], Loss: 0.3409\n",
      "Epoch [8330/10000], Loss: 0.3289\n",
      "Epoch [8340/10000], Loss: 0.3175\n",
      "Epoch [8350/10000], Loss: 0.3066\n",
      "Epoch [8360/10000], Loss: 0.2962\n",
      "Epoch [8370/10000], Loss: 0.2865\n",
      "Epoch [8380/10000], Loss: 0.2772\n",
      "Epoch [8390/10000], Loss: 0.2684\n",
      "Epoch [8400/10000], Loss: 0.2599\n",
      "Epoch [8410/10000], Loss: 0.2518\n",
      "Epoch [8420/10000], Loss: 0.2442\n",
      "Epoch [8430/10000], Loss: 0.2370\n",
      "Epoch [8440/10000], Loss: 0.2302\n",
      "Epoch [8450/10000], Loss: 0.2237\n",
      "Epoch [8460/10000], Loss: 0.2175\n",
      "Epoch [8470/10000], Loss: 0.2116\n",
      "Epoch [8480/10000], Loss: 0.2061\n",
      "Epoch [8490/10000], Loss: 0.2008\n",
      "Epoch [8500/10000], Loss: 0.1958\n",
      "Epoch [8510/10000], Loss: 0.1910\n",
      "Epoch [8520/10000], Loss: 0.1864\n",
      "Epoch [8530/10000], Loss: 0.1820\n",
      "Epoch [8540/10000], Loss: 0.1778\n",
      "Epoch [8550/10000], Loss: 0.1738\n",
      "Epoch [8560/10000], Loss: 0.1700\n",
      "Epoch [8570/10000], Loss: 0.1665\n",
      "Epoch [8580/10000], Loss: 0.1630\n",
      "Epoch [8590/10000], Loss: 0.1598\n",
      "Epoch [8600/10000], Loss: 0.1567\n",
      "Epoch [8610/10000], Loss: 0.1537\n",
      "Epoch [8620/10000], Loss: 0.1509\n",
      "Epoch [8630/10000], Loss: 0.1483\n",
      "Epoch [8640/10000], Loss: 0.1458\n",
      "Epoch [8650/10000], Loss: 0.1434\n",
      "Epoch [8660/10000], Loss: 0.1411\n",
      "Epoch [8670/10000], Loss: 0.1390\n",
      "Epoch [8680/10000], Loss: 0.1369\n",
      "Epoch [8690/10000], Loss: 0.1349\n",
      "Epoch [8700/10000], Loss: 0.1331\n",
      "Epoch [8710/10000], Loss: 0.1313\n",
      "Epoch [8720/10000], Loss: 0.1296\n",
      "Epoch [8730/10000], Loss: 0.1281\n",
      "Epoch [8740/10000], Loss: 0.1266\n",
      "Epoch [8750/10000], Loss: 0.1252\n",
      "Epoch [8760/10000], Loss: 0.1239\n",
      "Epoch [8770/10000], Loss: 0.1226\n",
      "Epoch [8780/10000], Loss: 0.1214\n",
      "Epoch [8790/10000], Loss: 0.1203\n",
      "Epoch [8800/10000], Loss: 0.1192\n",
      "Epoch [8810/10000], Loss: 0.1181\n",
      "Epoch [8820/10000], Loss: 0.1172\n",
      "Epoch [8830/10000], Loss: 0.1162\n",
      "Epoch [8840/10000], Loss: 0.1154\n",
      "Epoch [8850/10000], Loss: 0.1146\n",
      "Epoch [8860/10000], Loss: 0.1138\n",
      "Epoch [8870/10000], Loss: 0.1130\n",
      "Epoch [8880/10000], Loss: 0.1123\n",
      "Epoch [8890/10000], Loss: 0.1116\n",
      "Epoch [8900/10000], Loss: 0.1109\n",
      "Epoch [8910/10000], Loss: 0.1103\n",
      "Epoch [8920/10000], Loss: 0.1111\n",
      "Epoch [8930/10000], Loss: 48.3075\n",
      "Epoch [8940/10000], Loss: 78.2041\n",
      "Epoch [8950/10000], Loss: 83.0945\n",
      "Epoch [8960/10000], Loss: 30.8810\n",
      "Epoch [8970/10000], Loss: 0.7321\n",
      "Epoch [8980/10000], Loss: 0.7082\n",
      "Epoch [8990/10000], Loss: 0.6850\n",
      "Epoch [9000/10000], Loss: 0.6625\n",
      "Epoch [9010/10000], Loss: 0.6410\n",
      "Epoch [9020/10000], Loss: 0.6201\n",
      "Epoch [9030/10000], Loss: 0.5999\n",
      "Epoch [9040/10000], Loss: 0.5803\n",
      "Epoch [9050/10000], Loss: 0.5612\n",
      "Epoch [9060/10000], Loss: 0.5428\n",
      "Epoch [9070/10000], Loss: 0.5249\n",
      "Epoch [9080/10000], Loss: 0.5077\n",
      "Epoch [9090/10000], Loss: 0.4910\n",
      "Epoch [9100/10000], Loss: 0.4750\n",
      "Epoch [9110/10000], Loss: 0.4596\n",
      "Epoch [9120/10000], Loss: 0.4448\n",
      "Epoch [9130/10000], Loss: 0.4306\n",
      "Epoch [9140/10000], Loss: 0.4169\n",
      "Epoch [9150/10000], Loss: 0.4037\n",
      "Epoch [9160/10000], Loss: 0.3911\n",
      "Epoch [9170/10000], Loss: 0.3790\n",
      "Epoch [9180/10000], Loss: 0.3673\n",
      "Epoch [9190/10000], Loss: 0.3561\n",
      "Epoch [9200/10000], Loss: 0.3454\n",
      "Epoch [9210/10000], Loss: 0.3351\n",
      "Epoch [9220/10000], Loss: 0.3253\n",
      "Epoch [9230/10000], Loss: 0.3159\n",
      "Epoch [9240/10000], Loss: 0.3068\n",
      "Epoch [9250/10000], Loss: 0.2981\n",
      "Epoch [9260/10000], Loss: 0.2897\n",
      "Epoch [9270/10000], Loss: 0.2817\n",
      "Epoch [9280/10000], Loss: 0.2740\n",
      "Epoch [9290/10000], Loss: 0.2667\n",
      "Epoch [9300/10000], Loss: 0.2597\n",
      "Epoch [9310/10000], Loss: 0.2530\n",
      "Epoch [9320/10000], Loss: 0.2466\n",
      "Epoch [9330/10000], Loss: 0.2404\n",
      "Epoch [9340/10000], Loss: 0.2345\n",
      "Epoch [9350/10000], Loss: 0.2289\n",
      "Epoch [9360/10000], Loss: 0.2235\n",
      "Epoch [9370/10000], Loss: 0.2183\n",
      "Epoch [9380/10000], Loss: 0.2134\n",
      "Epoch [9390/10000], Loss: 0.2086\n",
      "Epoch [9400/10000], Loss: 0.2040\n",
      "Epoch [9410/10000], Loss: 0.1995\n",
      "Epoch [9420/10000], Loss: 0.1952\n",
      "Epoch [9430/10000], Loss: 0.1911\n",
      "Epoch [9440/10000], Loss: 0.1872\n",
      "Epoch [9450/10000], Loss: 0.1834\n",
      "Epoch [9460/10000], Loss: 0.1799\n",
      "Epoch [9470/10000], Loss: 0.1764\n",
      "Epoch [9480/10000], Loss: 0.1731\n",
      "Epoch [9490/10000], Loss: 0.1699\n",
      "Epoch [9500/10000], Loss: 0.1667\n",
      "Epoch [9510/10000], Loss: 0.1637\n",
      "Epoch [9520/10000], Loss: 0.1609\n",
      "Epoch [9530/10000], Loss: 0.1583\n",
      "Epoch [9540/10000], Loss: 0.1557\n",
      "Epoch [9550/10000], Loss: 0.1532\n",
      "Epoch [9560/10000], Loss: 0.1508\n",
      "Epoch [9570/10000], Loss: 0.1486\n",
      "Epoch [9580/10000], Loss: 0.1464\n",
      "Epoch [9590/10000], Loss: 0.1443\n",
      "Epoch [9600/10000], Loss: 0.1422\n",
      "Epoch [9610/10000], Loss: 0.1403\n",
      "Epoch [9620/10000], Loss: 0.1384\n",
      "Epoch [9630/10000], Loss: 0.1366\n",
      "Epoch [9640/10000], Loss: 0.1349\n",
      "Epoch [9650/10000], Loss: 0.1333\n",
      "Epoch [9660/10000], Loss: 0.1317\n",
      "Epoch [9670/10000], Loss: 0.1303\n",
      "Epoch [9680/10000], Loss: 0.1289\n",
      "Epoch [9690/10000], Loss: 0.1275\n",
      "Epoch [9700/10000], Loss: 0.1263\n",
      "Epoch [9710/10000], Loss: 0.1250\n",
      "Epoch [9720/10000], Loss: 0.1238\n",
      "Epoch [9730/10000], Loss: 0.1227\n",
      "Epoch [9740/10000], Loss: 0.1216\n",
      "Epoch [9750/10000], Loss: 0.1205\n",
      "Epoch [9760/10000], Loss: 0.1195\n",
      "Epoch [9770/10000], Loss: 0.1186\n",
      "Epoch [9780/10000], Loss: 0.1177\n",
      "Epoch [9790/10000], Loss: 0.1169\n",
      "Epoch [9800/10000], Loss: 0.1160\n",
      "Epoch [9810/10000], Loss: 0.1152\n",
      "Epoch [9820/10000], Loss: 0.1145\n",
      "Epoch [9830/10000], Loss: 0.1137\n",
      "Epoch [9840/10000], Loss: 0.1130\n",
      "Epoch [9850/10000], Loss: 0.1123\n",
      "Epoch [9860/10000], Loss: 0.1116\n",
      "Epoch [9870/10000], Loss: 0.1109\n",
      "Epoch [9880/10000], Loss: 0.1103\n",
      "Epoch [9890/10000], Loss: 0.1098\n",
      "Epoch [9900/10000], Loss: 0.1159\n",
      "Epoch [9910/10000], Loss: 1.8152\n",
      "Epoch [9920/10000], Loss: 45.6225\n",
      "Epoch [9930/10000], Loss: 76.7321\n",
      "Epoch [9940/10000], Loss: 0.5830\n",
      "Epoch [9950/10000], Loss: 0.5599\n",
      "Epoch [9960/10000], Loss: 0.5377\n",
      "Epoch [9970/10000], Loss: 0.5163\n",
      "Epoch [9980/10000], Loss: 0.4958\n",
      "Epoch [9990/10000], Loss: 0.4760\n",
      "Epoch [10000/10000], Loss: 0.4570\n",
      "Validation Accuracy: 0.00\n",
      "Fold 4/4\n",
      "Epoch [10/10000], Loss: 70.9874\n",
      "Epoch [20/10000], Loss: 38.4918\n",
      "Epoch [30/10000], Loss: 0.5909\n",
      "Epoch [40/10000], Loss: 0.5395\n",
      "Epoch [50/10000], Loss: 0.5166\n",
      "Epoch [60/10000], Loss: 0.4943\n",
      "Epoch [70/10000], Loss: 0.4727\n",
      "Epoch [80/10000], Loss: 0.4518\n",
      "Epoch [90/10000], Loss: 0.4316\n",
      "Epoch [100/10000], Loss: 0.4120\n",
      "Epoch [110/10000], Loss: 0.3930\n",
      "Epoch [120/10000], Loss: 0.3748\n",
      "Epoch [130/10000], Loss: 0.3572\n",
      "Epoch [140/10000], Loss: 0.3402\n",
      "Epoch [150/10000], Loss: 0.3239\n",
      "Epoch [160/10000], Loss: 0.3083\n",
      "Epoch [170/10000], Loss: 0.2934\n",
      "Epoch [180/10000], Loss: 0.2791\n",
      "Epoch [190/10000], Loss: 0.2655\n",
      "Epoch [200/10000], Loss: 0.2525\n",
      "Epoch [210/10000], Loss: 0.2401\n",
      "Epoch [220/10000], Loss: 0.2283\n",
      "Epoch [230/10000], Loss: 0.2172\n",
      "Epoch [240/10000], Loss: 0.2067\n",
      "Epoch [250/10000], Loss: 0.1969\n",
      "Epoch [260/10000], Loss: 0.1877\n",
      "Epoch [270/10000], Loss: 0.1792\n",
      "Epoch [280/10000], Loss: 56.8677\n",
      "Epoch [290/10000], Loss: 80.2297\n",
      "Epoch [300/10000], Loss: 32.9985\n",
      "Epoch [310/10000], Loss: 0.7048\n",
      "Epoch [320/10000], Loss: 0.6565\n",
      "Epoch [330/10000], Loss: 0.6333\n",
      "Epoch [340/10000], Loss: 0.6110\n",
      "Epoch [350/10000], Loss: 0.5893\n",
      "Epoch [360/10000], Loss: 0.5684\n",
      "Epoch [370/10000], Loss: 0.5482\n",
      "Epoch [380/10000], Loss: 0.5287\n",
      "Epoch [390/10000], Loss: 0.5100\n",
      "Epoch [400/10000], Loss: 0.4920\n",
      "Epoch [410/10000], Loss: 0.4746\n",
      "Epoch [420/10000], Loss: 0.4579\n",
      "Epoch [430/10000], Loss: 0.4417\n",
      "Epoch [440/10000], Loss: 0.4263\n",
      "Epoch [450/10000], Loss: 0.4116\n",
      "Epoch [460/10000], Loss: 0.3974\n",
      "Epoch [470/10000], Loss: 0.3837\n",
      "Epoch [480/10000], Loss: 0.3708\n",
      "Epoch [490/10000], Loss: 0.3582\n",
      "Epoch [500/10000], Loss: 0.3462\n",
      "Epoch [510/10000], Loss: 0.3347\n",
      "Epoch [520/10000], Loss: 0.3236\n",
      "Epoch [530/10000], Loss: 0.3129\n",
      "Epoch [540/10000], Loss: 0.3027\n",
      "Epoch [550/10000], Loss: 0.2928\n",
      "Epoch [560/10000], Loss: 0.2833\n",
      "Epoch [570/10000], Loss: 0.2743\n",
      "Epoch [580/10000], Loss: 0.2655\n",
      "Epoch [590/10000], Loss: 0.2571\n",
      "Epoch [600/10000], Loss: 0.2490\n",
      "Epoch [610/10000], Loss: 0.2411\n",
      "Epoch [620/10000], Loss: 0.2335\n",
      "Epoch [630/10000], Loss: 0.2262\n",
      "Epoch [640/10000], Loss: 0.2193\n",
      "Epoch [650/10000], Loss: 0.2126\n",
      "Epoch [660/10000], Loss: 0.2061\n",
      "Epoch [670/10000], Loss: 0.1999\n",
      "Epoch [680/10000], Loss: 0.1940\n",
      "Epoch [690/10000], Loss: 0.1882\n",
      "Epoch [700/10000], Loss: 0.1827\n",
      "Epoch [710/10000], Loss: 0.1774\n",
      "Epoch [720/10000], Loss: 0.1723\n",
      "Epoch [730/10000], Loss: 0.1674\n",
      "Epoch [740/10000], Loss: 0.1627\n",
      "Epoch [750/10000], Loss: 0.1581\n",
      "Epoch [760/10000], Loss: 0.1538\n",
      "Epoch [770/10000], Loss: 0.1497\n",
      "Epoch [780/10000], Loss: 0.1457\n",
      "Epoch [790/10000], Loss: 0.1420\n",
      "Epoch [800/10000], Loss: 0.1383\n",
      "Epoch [810/10000], Loss: 0.1349\n",
      "Epoch [820/10000], Loss: 0.1317\n",
      "Epoch [830/10000], Loss: 0.1286\n",
      "Epoch [840/10000], Loss: 0.1327\n",
      "Epoch [850/10000], Loss: 72.1900\n",
      "Epoch [860/10000], Loss: 57.8236\n",
      "Epoch [870/10000], Loss: 0.5891\n",
      "Epoch [880/10000], Loss: 0.5651\n",
      "Epoch [890/10000], Loss: 0.5423\n",
      "Epoch [900/10000], Loss: 0.5204\n",
      "Epoch [910/10000], Loss: 0.4993\n",
      "Epoch [920/10000], Loss: 0.4790\n",
      "Epoch [930/10000], Loss: 0.4595\n",
      "Epoch [940/10000], Loss: 0.4409\n",
      "Epoch [950/10000], Loss: 0.4232\n",
      "Epoch [960/10000], Loss: 0.4062\n",
      "Epoch [970/10000], Loss: 0.3898\n",
      "Epoch [980/10000], Loss: 0.3743\n",
      "Epoch [990/10000], Loss: 0.3596\n",
      "Epoch [1000/10000], Loss: 0.3456\n",
      "Epoch [1010/10000], Loss: 0.3322\n",
      "Epoch [1020/10000], Loss: 0.3196\n",
      "Epoch [1030/10000], Loss: 0.3077\n",
      "Epoch [1040/10000], Loss: 0.2965\n",
      "Epoch [1050/10000], Loss: 0.2858\n",
      "Epoch [1060/10000], Loss: 0.2758\n",
      "Epoch [1070/10000], Loss: 0.2663\n",
      "Epoch [1080/10000], Loss: 0.2573\n",
      "Epoch [1090/10000], Loss: 0.2489\n",
      "Epoch [1100/10000], Loss: 0.2409\n",
      "Epoch [1110/10000], Loss: 0.2335\n",
      "Epoch [1120/10000], Loss: 0.2264\n",
      "Epoch [1130/10000], Loss: 0.2198\n",
      "Epoch [1140/10000], Loss: 0.2135\n",
      "Epoch [1150/10000], Loss: 0.2075\n",
      "Epoch [1160/10000], Loss: 0.2019\n",
      "Epoch [1170/10000], Loss: 0.1966\n",
      "Epoch [1180/10000], Loss: 0.1916\n",
      "Epoch [1190/10000], Loss: 0.1868\n",
      "Epoch [1200/10000], Loss: 0.1823\n",
      "Epoch [1210/10000], Loss: 0.1780\n",
      "Epoch [1220/10000], Loss: 0.1739\n",
      "Epoch [1230/10000], Loss: 0.1700\n",
      "Epoch [1240/10000], Loss: 0.1663\n",
      "Epoch [1250/10000], Loss: 0.1627\n",
      "Epoch [1260/10000], Loss: 0.1592\n",
      "Epoch [1270/10000], Loss: 0.1558\n",
      "Epoch [1280/10000], Loss: 0.1526\n",
      "Epoch [1290/10000], Loss: 0.1495\n",
      "Epoch [1300/10000], Loss: 0.1466\n",
      "Epoch [1310/10000], Loss: 0.1437\n",
      "Epoch [1320/10000], Loss: 0.1410\n",
      "Epoch [1330/10000], Loss: 0.1383\n",
      "Epoch [1340/10000], Loss: 0.1357\n",
      "Epoch [1350/10000], Loss: 0.1332\n",
      "Epoch [1360/10000], Loss: 0.1308\n",
      "Epoch [1370/10000], Loss: 0.1286\n",
      "Epoch [1380/10000], Loss: 0.1263\n",
      "Epoch [1390/10000], Loss: 0.1242\n",
      "Epoch [1400/10000], Loss: 0.1221\n",
      "Epoch [1410/10000], Loss: 0.1202\n",
      "Epoch [1420/10000], Loss: 0.1189\n",
      "Epoch [1430/10000], Loss: 42.6321\n",
      "Epoch [1440/10000], Loss: 80.8537\n",
      "Epoch [1450/10000], Loss: 33.4842\n",
      "Epoch [1460/10000], Loss: 0.5753\n",
      "Epoch [1470/10000], Loss: 0.5520\n",
      "Epoch [1480/10000], Loss: 0.5297\n",
      "Epoch [1490/10000], Loss: 0.5082\n",
      "Epoch [1500/10000], Loss: 0.4877\n",
      "Epoch [1510/10000], Loss: 0.4681\n",
      "Epoch [1520/10000], Loss: 0.4492\n",
      "Epoch [1530/10000], Loss: 0.4311\n",
      "Epoch [1540/10000], Loss: 0.4139\n",
      "Epoch [1550/10000], Loss: 0.3974\n",
      "Epoch [1560/10000], Loss: 0.3816\n",
      "Epoch [1570/10000], Loss: 0.3666\n",
      "Epoch [1580/10000], Loss: 0.3524\n",
      "Epoch [1590/10000], Loss: 0.3389\n",
      "Epoch [1600/10000], Loss: 0.3259\n",
      "Epoch [1610/10000], Loss: 0.3137\n",
      "Epoch [1620/10000], Loss: 0.3020\n",
      "Epoch [1630/10000], Loss: 0.2909\n",
      "Epoch [1640/10000], Loss: 0.2804\n",
      "Epoch [1650/10000], Loss: 0.2704\n",
      "Epoch [1660/10000], Loss: 0.2610\n",
      "Epoch [1670/10000], Loss: 0.2521\n",
      "Epoch [1680/10000], Loss: 0.2437\n",
      "Epoch [1690/10000], Loss: 0.2358\n",
      "Epoch [1700/10000], Loss: 0.2284\n",
      "Epoch [1710/10000], Loss: 0.2214\n",
      "Epoch [1720/10000], Loss: 0.2148\n",
      "Epoch [1730/10000], Loss: 0.2086\n",
      "Epoch [1740/10000], Loss: 0.2026\n",
      "Epoch [1750/10000], Loss: 0.1971\n",
      "Epoch [1760/10000], Loss: 0.1919\n",
      "Epoch [1770/10000], Loss: 0.1870\n",
      "Epoch [1780/10000], Loss: 0.1824\n",
      "Epoch [1790/10000], Loss: 0.1781\n",
      "Epoch [1800/10000], Loss: 0.1741\n",
      "Epoch [1810/10000], Loss: 0.1703\n",
      "Epoch [1820/10000], Loss: 0.1667\n",
      "Epoch [1830/10000], Loss: 0.1633\n",
      "Epoch [1840/10000], Loss: 0.1601\n",
      "Epoch [1850/10000], Loss: 0.1570\n",
      "Epoch [1860/10000], Loss: 0.1541\n",
      "Epoch [1870/10000], Loss: 0.1513\n",
      "Epoch [1880/10000], Loss: 0.1487\n",
      "Epoch [1890/10000], Loss: 0.1462\n",
      "Epoch [1900/10000], Loss: 0.1438\n",
      "Epoch [1910/10000], Loss: 0.1415\n",
      "Epoch [1920/10000], Loss: 0.1393\n",
      "Epoch [1930/10000], Loss: 0.1371\n",
      "Epoch [1940/10000], Loss: 0.1350\n",
      "Epoch [1950/10000], Loss: 0.1330\n",
      "Epoch [1960/10000], Loss: 0.1310\n",
      "Epoch [1970/10000], Loss: 0.1291\n",
      "Epoch [1980/10000], Loss: 0.1272\n",
      "Epoch [1990/10000], Loss: 0.1254\n",
      "Epoch [2000/10000], Loss: 0.1237\n",
      "Epoch [2010/10000], Loss: 0.1220\n",
      "Epoch [2020/10000], Loss: 0.1203\n",
      "Epoch [2030/10000], Loss: 0.1187\n",
      "Epoch [2040/10000], Loss: 0.1171\n",
      "Epoch [2050/10000], Loss: 0.1156\n",
      "Epoch [2060/10000], Loss: 0.1143\n",
      "Epoch [2070/10000], Loss: 92.1610\n",
      "Epoch [2080/10000], Loss: 22.7821\n",
      "Epoch [2090/10000], Loss: 0.3381\n",
      "Epoch [2100/10000], Loss: 0.3160\n",
      "Epoch [2110/10000], Loss: 0.2959\n",
      "Epoch [2120/10000], Loss: 0.2772\n",
      "Epoch [2130/10000], Loss: 0.2600\n",
      "Epoch [2140/10000], Loss: 0.2443\n",
      "Epoch [2150/10000], Loss: 0.2299\n",
      "Epoch [2160/10000], Loss: 0.2170\n",
      "Epoch [2170/10000], Loss: 0.2054\n",
      "Epoch [2180/10000], Loss: 0.1949\n",
      "Epoch [2190/10000], Loss: 0.1854\n",
      "Epoch [2200/10000], Loss: 0.1769\n",
      "Epoch [2210/10000], Loss: 0.1693\n",
      "Epoch [2220/10000], Loss: 0.1625\n",
      "Epoch [2230/10000], Loss: 0.1565\n",
      "Epoch [2240/10000], Loss: 0.1510\n",
      "Epoch [2250/10000], Loss: 0.1463\n",
      "Epoch [2260/10000], Loss: 0.1421\n",
      "Epoch [2270/10000], Loss: 0.1385\n",
      "Epoch [2280/10000], Loss: 0.1352\n",
      "Epoch [2290/10000], Loss: 0.1323\n",
      "Epoch [2300/10000], Loss: 0.1298\n",
      "Epoch [2310/10000], Loss: 0.1275\n",
      "Epoch [2320/10000], Loss: 0.1255\n",
      "Epoch [2330/10000], Loss: 0.1237\n",
      "Epoch [2340/10000], Loss: 0.1219\n",
      "Epoch [2350/10000], Loss: 0.1203\n",
      "Epoch [2360/10000], Loss: 0.1187\n",
      "Epoch [2370/10000], Loss: 0.1172\n",
      "Epoch [2380/10000], Loss: 0.1158\n",
      "Epoch [2390/10000], Loss: 0.1144\n",
      "Epoch [2400/10000], Loss: 0.1131\n",
      "Epoch [2410/10000], Loss: 0.1122\n",
      "Epoch [2420/10000], Loss: 16.4632\n",
      "Epoch [2430/10000], Loss: 76.3048\n",
      "Epoch [2440/10000], Loss: 0.3914\n",
      "Epoch [2450/10000], Loss: 0.3688\n",
      "Epoch [2460/10000], Loss: 0.3477\n",
      "Epoch [2470/10000], Loss: 0.3279\n",
      "Epoch [2480/10000], Loss: 0.3093\n",
      "Epoch [2490/10000], Loss: 0.2920\n",
      "Epoch [2500/10000], Loss: 0.2759\n",
      "Epoch [2510/10000], Loss: 0.2610\n",
      "Epoch [2520/10000], Loss: 0.2473\n",
      "Epoch [2530/10000], Loss: 0.2346\n",
      "Epoch [2540/10000], Loss: 0.2230\n",
      "Epoch [2550/10000], Loss: 0.2122\n",
      "Epoch [2560/10000], Loss: 0.2023\n",
      "Epoch [2570/10000], Loss: 0.1933\n",
      "Epoch [2580/10000], Loss: 0.1851\n",
      "Epoch [2590/10000], Loss: 0.1776\n",
      "Epoch [2600/10000], Loss: 0.1709\n",
      "Epoch [2610/10000], Loss: 0.1648\n",
      "Epoch [2620/10000], Loss: 0.1592\n",
      "Epoch [2630/10000], Loss: 0.1542\n",
      "Epoch [2640/10000], Loss: 0.1497\n",
      "Epoch [2650/10000], Loss: 0.1457\n",
      "Epoch [2660/10000], Loss: 0.1421\n",
      "Epoch [2670/10000], Loss: 0.1388\n",
      "Epoch [2680/10000], Loss: 0.1358\n",
      "Epoch [2690/10000], Loss: 0.1330\n",
      "Epoch [2700/10000], Loss: 0.1306\n",
      "Epoch [2710/10000], Loss: 0.1284\n",
      "Epoch [2720/10000], Loss: 0.1264\n",
      "Epoch [2730/10000], Loss: 0.1246\n",
      "Epoch [2740/10000], Loss: 0.1229\n",
      "Epoch [2750/10000], Loss: 0.1213\n",
      "Epoch [2760/10000], Loss: 0.1198\n",
      "Epoch [2770/10000], Loss: 0.1183\n",
      "Epoch [2780/10000], Loss: 0.1169\n",
      "Epoch [2790/10000], Loss: 0.1156\n",
      "Epoch [2800/10000], Loss: 0.1143\n",
      "Epoch [2810/10000], Loss: 0.1130\n",
      "Epoch [2820/10000], Loss: 0.1118\n",
      "Epoch [2830/10000], Loss: 0.1106\n",
      "Epoch [2840/10000], Loss: 0.1096\n",
      "Epoch [2850/10000], Loss: 12.2786\n",
      "Epoch [2860/10000], Loss: 71.7433\n",
      "Epoch [2870/10000], Loss: 0.3710\n",
      "Epoch [2880/10000], Loss: 0.3487\n",
      "Epoch [2890/10000], Loss: 0.3278\n",
      "Epoch [2900/10000], Loss: 0.3083\n",
      "Epoch [2910/10000], Loss: 0.2902\n",
      "Epoch [2920/10000], Loss: 0.2734\n",
      "Epoch [2930/10000], Loss: 0.2578\n",
      "Epoch [2940/10000], Loss: 0.2436\n",
      "Epoch [2950/10000], Loss: 0.2305\n",
      "Epoch [2960/10000], Loss: 0.2184\n",
      "Epoch [2970/10000], Loss: 0.2074\n",
      "Epoch [2980/10000], Loss: 0.1973\n",
      "Epoch [2990/10000], Loss: 0.1881\n",
      "Epoch [3000/10000], Loss: 0.1797\n",
      "Epoch [3010/10000], Loss: 0.1722\n",
      "Epoch [3020/10000], Loss: 0.1654\n",
      "Epoch [3030/10000], Loss: 0.1592\n",
      "Epoch [3040/10000], Loss: 0.1537\n",
      "Epoch [3050/10000], Loss: 0.1487\n",
      "Epoch [3060/10000], Loss: 0.1443\n",
      "Epoch [3070/10000], Loss: 0.1404\n",
      "Epoch [3080/10000], Loss: 0.1369\n",
      "Epoch [3090/10000], Loss: 0.1337\n",
      "Epoch [3100/10000], Loss: 0.1308\n",
      "Epoch [3110/10000], Loss: 0.1282\n",
      "Epoch [3120/10000], Loss: 0.1259\n",
      "Epoch [3130/10000], Loss: 0.1238\n",
      "Epoch [3140/10000], Loss: 0.1220\n",
      "Epoch [3150/10000], Loss: 0.1203\n",
      "Epoch [3160/10000], Loss: 0.1188\n",
      "Epoch [3170/10000], Loss: 0.1173\n",
      "Epoch [3180/10000], Loss: 0.1160\n",
      "Epoch [3190/10000], Loss: 0.1147\n",
      "Epoch [3200/10000], Loss: 0.1135\n",
      "Epoch [3210/10000], Loss: 0.1123\n",
      "Epoch [3220/10000], Loss: 0.1112\n",
      "Epoch [3230/10000], Loss: 0.1101\n",
      "Epoch [3240/10000], Loss: 0.1110\n",
      "Epoch [3250/10000], Loss: 36.2774\n",
      "Epoch [3260/10000], Loss: 1.9434\n",
      "Epoch [3270/10000], Loss: 72.7043\n",
      "Epoch [3280/10000], Loss: 76.2888\n",
      "Epoch [3290/10000], Loss: 76.3695\n",
      "Epoch [3300/10000], Loss: 0.8990\n",
      "Epoch [3310/10000], Loss: 0.8748\n",
      "Epoch [3320/10000], Loss: 0.8512\n",
      "Epoch [3330/10000], Loss: 0.8282\n",
      "Epoch [3340/10000], Loss: 0.8058\n",
      "Epoch [3350/10000], Loss: 0.7839\n",
      "Epoch [3360/10000], Loss: 0.7626\n",
      "Epoch [3370/10000], Loss: 0.7419\n",
      "Epoch [3380/10000], Loss: 0.7216\n",
      "Epoch [3390/10000], Loss: 0.7019\n",
      "Epoch [3400/10000], Loss: 0.6826\n",
      "Epoch [3410/10000], Loss: 0.6638\n",
      "Epoch [3420/10000], Loss: 0.6455\n",
      "Epoch [3430/10000], Loss: 0.6278\n",
      "Epoch [3440/10000], Loss: 0.6106\n",
      "Epoch [3450/10000], Loss: 0.5938\n",
      "Epoch [3460/10000], Loss: 0.5775\n",
      "Epoch [3470/10000], Loss: 0.5617\n",
      "Epoch [3480/10000], Loss: 0.5464\n",
      "Epoch [3490/10000], Loss: 0.5315\n",
      "Epoch [3500/10000], Loss: 0.5172\n",
      "Epoch [3510/10000], Loss: 0.5032\n",
      "Epoch [3520/10000], Loss: 0.4896\n",
      "Epoch [3530/10000], Loss: 0.4766\n",
      "Epoch [3540/10000], Loss: 0.4639\n",
      "Epoch [3550/10000], Loss: 0.4517\n",
      "Epoch [3560/10000], Loss: 0.4397\n",
      "Epoch [3570/10000], Loss: 0.4281\n",
      "Epoch [3580/10000], Loss: 0.4170\n",
      "Epoch [3590/10000], Loss: 0.4061\n",
      "Epoch [3600/10000], Loss: 0.3956\n",
      "Epoch [3610/10000], Loss: 0.3853\n",
      "Epoch [3620/10000], Loss: 0.3755\n",
      "Epoch [3630/10000], Loss: 0.3659\n",
      "Epoch [3640/10000], Loss: 0.3566\n",
      "Epoch [3650/10000], Loss: 0.3477\n",
      "Epoch [3660/10000], Loss: 0.3390\n",
      "Epoch [3670/10000], Loss: 0.3305\n",
      "Epoch [3680/10000], Loss: 0.3224\n",
      "Epoch [3690/10000], Loss: 0.3145\n",
      "Epoch [3700/10000], Loss: 0.3070\n",
      "Epoch [3710/10000], Loss: 0.2998\n",
      "Epoch [3720/10000], Loss: 0.2927\n",
      "Epoch [3730/10000], Loss: 0.2859\n",
      "Epoch [3740/10000], Loss: 0.2794\n",
      "Epoch [3750/10000], Loss: 0.2730\n",
      "Epoch [3760/10000], Loss: 0.2668\n",
      "Epoch [3770/10000], Loss: 0.2607\n",
      "Epoch [3780/10000], Loss: 0.2549\n",
      "Epoch [3790/10000], Loss: 0.2493\n",
      "Epoch [3800/10000], Loss: 0.2438\n",
      "Epoch [3810/10000], Loss: 0.2386\n",
      "Epoch [3820/10000], Loss: 0.2336\n",
      "Epoch [3830/10000], Loss: 0.2288\n",
      "Epoch [3840/10000], Loss: 0.2242\n",
      "Epoch [3850/10000], Loss: 0.2197\n",
      "Epoch [3860/10000], Loss: 0.2154\n",
      "Epoch [3870/10000], Loss: 0.2113\n",
      "Epoch [3880/10000], Loss: 0.2073\n",
      "Epoch [3890/10000], Loss: 0.2034\n",
      "Epoch [3900/10000], Loss: 0.1997\n",
      "Epoch [3910/10000], Loss: 0.1961\n",
      "Epoch [3920/10000], Loss: 0.1926\n",
      "Epoch [3930/10000], Loss: 0.1893\n",
      "Epoch [3940/10000], Loss: 0.1860\n",
      "Epoch [3950/10000], Loss: 0.1828\n",
      "Epoch [3960/10000], Loss: 0.1798\n",
      "Epoch [3970/10000], Loss: 0.1768\n",
      "Epoch [3980/10000], Loss: 0.1739\n",
      "Epoch [3990/10000], Loss: 0.1711\n",
      "Epoch [4000/10000], Loss: 0.1684\n",
      "Epoch [4010/10000], Loss: 0.1658\n",
      "Epoch [4020/10000], Loss: 0.1634\n",
      "Epoch [4030/10000], Loss: 0.1610\n",
      "Epoch [4040/10000], Loss: 0.1587\n",
      "Epoch [4050/10000], Loss: 0.1565\n",
      "Epoch [4060/10000], Loss: 0.1544\n",
      "Epoch [4070/10000], Loss: 0.1524\n",
      "Epoch [4080/10000], Loss: 0.1504\n",
      "Epoch [4090/10000], Loss: 0.1485\n",
      "Epoch [4100/10000], Loss: 0.1467\n",
      "Epoch [4110/10000], Loss: 0.1449\n",
      "Epoch [4120/10000], Loss: 0.1431\n",
      "Epoch [4130/10000], Loss: 0.1413\n",
      "Epoch [4140/10000], Loss: 0.1397\n",
      "Epoch [4150/10000], Loss: 0.1381\n",
      "Epoch [4160/10000], Loss: 0.1365\n",
      "Epoch [4170/10000], Loss: 0.1350\n",
      "Epoch [4180/10000], Loss: 0.1335\n",
      "Epoch [4190/10000], Loss: 0.1321\n",
      "Epoch [4200/10000], Loss: 0.1307\n",
      "Epoch [4210/10000], Loss: 0.1293\n",
      "Epoch [4220/10000], Loss: 0.1280\n",
      "Epoch [4230/10000], Loss: 0.1267\n",
      "Epoch [4240/10000], Loss: 0.1255\n",
      "Epoch [4250/10000], Loss: 0.1242\n",
      "Epoch [4260/10000], Loss: 0.1230\n",
      "Epoch [4270/10000], Loss: 0.1218\n",
      "Epoch [4280/10000], Loss: 0.1207\n",
      "Epoch [4290/10000], Loss: 0.1195\n",
      "Epoch [4300/10000], Loss: 0.1184\n",
      "Epoch [4310/10000], Loss: 0.1174\n",
      "Epoch [4320/10000], Loss: 0.1163\n",
      "Epoch [4330/10000], Loss: 0.1153\n",
      "Epoch [4340/10000], Loss: 0.1143\n",
      "Epoch [4350/10000], Loss: 0.1133\n",
      "Epoch [4360/10000], Loss: 0.1123\n",
      "Epoch [4370/10000], Loss: 0.1113\n",
      "Epoch [4380/10000], Loss: 0.1104\n",
      "Epoch [4390/10000], Loss: 0.1095\n",
      "Epoch [4400/10000], Loss: 0.1086\n",
      "Epoch [4410/10000], Loss: 0.1078\n",
      "Epoch [4420/10000], Loss: 0.1101\n",
      "Epoch [4430/10000], Loss: 5.2801\n",
      "Epoch [4440/10000], Loss: 56.5634\n",
      "Epoch [4450/10000], Loss: 8.6826\n",
      "Epoch [4460/10000], Loss: 0.5953\n",
      "Epoch [4470/10000], Loss: 0.5719\n",
      "Epoch [4480/10000], Loss: 0.5493\n",
      "Epoch [4490/10000], Loss: 0.5275\n",
      "Epoch [4500/10000], Loss: 0.5067\n",
      "Epoch [4510/10000], Loss: 0.4866\n",
      "Epoch [4520/10000], Loss: 0.4673\n",
      "Epoch [4530/10000], Loss: 0.4488\n",
      "Epoch [4540/10000], Loss: 0.4310\n",
      "Epoch [4550/10000], Loss: 0.4140\n",
      "Epoch [4560/10000], Loss: 0.3978\n",
      "Epoch [4570/10000], Loss: 0.3823\n",
      "Epoch [4580/10000], Loss: 0.3675\n",
      "Epoch [4590/10000], Loss: 0.3535\n",
      "Epoch [4600/10000], Loss: 0.3401\n",
      "Epoch [4610/10000], Loss: 0.3272\n",
      "Epoch [4620/10000], Loss: 0.3149\n",
      "Epoch [4630/10000], Loss: 0.3033\n",
      "Epoch [4640/10000], Loss: 0.2922\n",
      "Epoch [4650/10000], Loss: 0.2817\n",
      "Epoch [4660/10000], Loss: 0.2717\n",
      "Epoch [4670/10000], Loss: 0.2623\n",
      "Epoch [4680/10000], Loss: 0.2533\n",
      "Epoch [4690/10000], Loss: 0.2448\n",
      "Epoch [4700/10000], Loss: 0.2368\n",
      "Epoch [4710/10000], Loss: 0.2292\n",
      "Epoch [4720/10000], Loss: 0.2220\n",
      "Epoch [4730/10000], Loss: 0.2153\n",
      "Epoch [4740/10000], Loss: 0.2089\n",
      "Epoch [4750/10000], Loss: 0.2028\n",
      "Epoch [4760/10000], Loss: 0.1970\n",
      "Epoch [4770/10000], Loss: 0.1916\n",
      "Epoch [4780/10000], Loss: 0.1865\n",
      "Epoch [4790/10000], Loss: 0.1817\n",
      "Epoch [4800/10000], Loss: 0.1771\n",
      "Epoch [4810/10000], Loss: 0.1729\n",
      "Epoch [4820/10000], Loss: 0.1688\n",
      "Epoch [4830/10000], Loss: 0.1650\n",
      "Epoch [4840/10000], Loss: 0.1614\n",
      "Epoch [4850/10000], Loss: 0.1580\n",
      "Epoch [4860/10000], Loss: 0.1548\n",
      "Epoch [4870/10000], Loss: 0.1517\n",
      "Epoch [4880/10000], Loss: 0.1487\n",
      "Epoch [4890/10000], Loss: 0.1460\n",
      "Epoch [4900/10000], Loss: 0.1434\n",
      "Epoch [4910/10000], Loss: 0.1409\n",
      "Epoch [4920/10000], Loss: 0.1386\n",
      "Epoch [4930/10000], Loss: 0.1365\n",
      "Epoch [4940/10000], Loss: 0.1344\n",
      "Epoch [4950/10000], Loss: 0.1325\n",
      "Epoch [4960/10000], Loss: 0.1307\n",
      "Epoch [4970/10000], Loss: 0.1290\n",
      "Epoch [4980/10000], Loss: 0.1273\n",
      "Epoch [4990/10000], Loss: 0.1257\n",
      "Epoch [5000/10000], Loss: 0.1242\n",
      "Epoch [5010/10000], Loss: 0.1229\n",
      "Epoch [5020/10000], Loss: 0.1216\n",
      "Epoch [5030/10000], Loss: 0.1203\n",
      "Epoch [5040/10000], Loss: 0.1192\n",
      "Epoch [5050/10000], Loss: 0.1181\n",
      "Epoch [5060/10000], Loss: 0.1170\n",
      "Epoch [5070/10000], Loss: 0.1160\n",
      "Epoch [5080/10000], Loss: 0.1150\n",
      "Epoch [5090/10000], Loss: 0.1140\n",
      "Epoch [5100/10000], Loss: 0.1131\n",
      "Epoch [5110/10000], Loss: 0.1121\n",
      "Epoch [5120/10000], Loss: 0.1112\n",
      "Epoch [5130/10000], Loss: 0.1103\n",
      "Epoch [5140/10000], Loss: 0.1095\n",
      "Epoch [5150/10000], Loss: 0.1086\n",
      "Epoch [5160/10000], Loss: 0.1078\n",
      "Epoch [5170/10000], Loss: 0.1070\n",
      "Epoch [5180/10000], Loss: 0.1085\n",
      "Epoch [5190/10000], Loss: 43.8446\n",
      "Epoch [5200/10000], Loss: 85.8877\n",
      "Epoch [5210/10000], Loss: 32.9866\n",
      "Epoch [5220/10000], Loss: 0.5341\n",
      "Epoch [5230/10000], Loss: 0.5113\n",
      "Epoch [5240/10000], Loss: 0.4893\n",
      "Epoch [5250/10000], Loss: 0.4682\n",
      "Epoch [5260/10000], Loss: 0.4479\n",
      "Epoch [5270/10000], Loss: 0.4284\n",
      "Epoch [5280/10000], Loss: 0.4098\n",
      "Epoch [5290/10000], Loss: 0.3922\n",
      "Epoch [5300/10000], Loss: 0.3753\n",
      "Epoch [5310/10000], Loss: 0.3592\n",
      "Epoch [5320/10000], Loss: 0.3440\n",
      "Epoch [5330/10000], Loss: 0.3296\n",
      "Epoch [5340/10000], Loss: 0.3159\n",
      "Epoch [5350/10000], Loss: 0.3029\n",
      "Epoch [5360/10000], Loss: 0.2906\n",
      "Epoch [5370/10000], Loss: 0.2790\n",
      "Epoch [5380/10000], Loss: 0.2681\n",
      "Epoch [5390/10000], Loss: 0.2578\n",
      "Epoch [5400/10000], Loss: 0.2481\n",
      "Epoch [5410/10000], Loss: 0.2389\n",
      "Epoch [5420/10000], Loss: 0.2303\n",
      "Epoch [5430/10000], Loss: 0.2222\n",
      "Epoch [5440/10000], Loss: 0.2147\n",
      "Epoch [5450/10000], Loss: 0.2076\n",
      "Epoch [5460/10000], Loss: 0.2009\n",
      "Epoch [5470/10000], Loss: 0.1947\n",
      "Epoch [5480/10000], Loss: 0.1887\n",
      "Epoch [5490/10000], Loss: 0.1832\n",
      "Epoch [5500/10000], Loss: 0.1779\n",
      "Epoch [5510/10000], Loss: 0.1731\n",
      "Epoch [5520/10000], Loss: 0.1685\n",
      "Epoch [5530/10000], Loss: 0.1643\n",
      "Epoch [5540/10000], Loss: 0.1603\n",
      "Epoch [5550/10000], Loss: 0.1566\n",
      "Epoch [5560/10000], Loss: 0.1531\n",
      "Epoch [5570/10000], Loss: 0.1498\n",
      "Epoch [5580/10000], Loss: 0.1467\n",
      "Epoch [5590/10000], Loss: 0.1437\n",
      "Epoch [5600/10000], Loss: 0.1410\n",
      "Epoch [5610/10000], Loss: 0.1384\n",
      "Epoch [5620/10000], Loss: 0.1361\n",
      "Epoch [5630/10000], Loss: 0.1338\n",
      "Epoch [5640/10000], Loss: 0.1317\n",
      "Epoch [5650/10000], Loss: 0.1298\n",
      "Epoch [5660/10000], Loss: 0.1280\n",
      "Epoch [5670/10000], Loss: 0.1262\n",
      "Epoch [5680/10000], Loss: 0.1246\n",
      "Epoch [5690/10000], Loss: 0.1230\n",
      "Epoch [5700/10000], Loss: 0.1216\n",
      "Epoch [5710/10000], Loss: 0.1202\n",
      "Epoch [5720/10000], Loss: 0.1190\n",
      "Epoch [5730/10000], Loss: 0.1178\n",
      "Epoch [5740/10000], Loss: 0.1167\n",
      "Epoch [5750/10000], Loss: 0.1156\n",
      "Epoch [5760/10000], Loss: 0.1146\n",
      "Epoch [5770/10000], Loss: 0.1137\n",
      "Epoch [5780/10000], Loss: 0.1127\n",
      "Epoch [5790/10000], Loss: 0.1119\n",
      "Epoch [5800/10000], Loss: 0.1110\n",
      "Epoch [5810/10000], Loss: 0.1101\n",
      "Epoch [5820/10000], Loss: 0.1093\n",
      "Epoch [5830/10000], Loss: 0.1084\n",
      "Epoch [5840/10000], Loss: 0.1076\n",
      "Epoch [5850/10000], Loss: 0.1070\n",
      "Epoch [5860/10000], Loss: 0.1306\n",
      "Epoch [5870/10000], Loss: 13.2147\n",
      "Epoch [5880/10000], Loss: 72.4692\n",
      "Epoch [5890/10000], Loss: 76.1957\n",
      "Epoch [5900/10000], Loss: 76.3713\n",
      "Epoch [5910/10000], Loss: 70.4362\n",
      "Epoch [5920/10000], Loss: 0.8719\n",
      "Epoch [5930/10000], Loss: 0.8481\n",
      "Epoch [5940/10000], Loss: 0.8250\n",
      "Epoch [5950/10000], Loss: 0.8024\n",
      "Epoch [5960/10000], Loss: 0.7804\n",
      "Epoch [5970/10000], Loss: 0.7589\n",
      "Epoch [5980/10000], Loss: 0.7379\n",
      "Epoch [5990/10000], Loss: 0.7176\n",
      "Epoch [6000/10000], Loss: 0.6977\n",
      "Epoch [6010/10000], Loss: 0.6783\n",
      "Epoch [6020/10000], Loss: 0.6594\n",
      "Epoch [6030/10000], Loss: 0.6409\n",
      "Epoch [6040/10000], Loss: 0.6230\n",
      "Epoch [6050/10000], Loss: 0.6056\n",
      "Epoch [6060/10000], Loss: 0.5888\n",
      "Epoch [6070/10000], Loss: 0.5723\n",
      "Epoch [6080/10000], Loss: 0.5564\n",
      "Epoch [6090/10000], Loss: 0.5409\n",
      "Epoch [6100/10000], Loss: 0.5260\n",
      "Epoch [6110/10000], Loss: 0.5116\n",
      "Epoch [6120/10000], Loss: 0.4975\n",
      "Epoch [6130/10000], Loss: 0.4839\n",
      "Epoch [6140/10000], Loss: 0.4707\n",
      "Epoch [6150/10000], Loss: 0.4580\n",
      "Epoch [6160/10000], Loss: 0.4457\n",
      "Epoch [6170/10000], Loss: 0.4337\n",
      "Epoch [6180/10000], Loss: 0.4221\n",
      "Epoch [6190/10000], Loss: 0.4109\n",
      "Epoch [6200/10000], Loss: 0.4000\n",
      "Epoch [6210/10000], Loss: 0.3895\n",
      "Epoch [6220/10000], Loss: 0.3793\n",
      "Epoch [6230/10000], Loss: 0.3694\n",
      "Epoch [6240/10000], Loss: 0.3598\n",
      "Epoch [6250/10000], Loss: 0.3506\n",
      "Epoch [6260/10000], Loss: 0.3416\n",
      "Epoch [6270/10000], Loss: 0.3330\n",
      "Epoch [6280/10000], Loss: 0.3246\n",
      "Epoch [6290/10000], Loss: 0.3165\n",
      "Epoch [6300/10000], Loss: 0.3087\n",
      "Epoch [6310/10000], Loss: 0.3012\n",
      "Epoch [6320/10000], Loss: 0.2939\n",
      "Epoch [6330/10000], Loss: 0.2870\n",
      "Epoch [6340/10000], Loss: 0.2802\n",
      "Epoch [6350/10000], Loss: 0.2737\n",
      "Epoch [6360/10000], Loss: 0.2673\n",
      "Epoch [6370/10000], Loss: 0.2611\n",
      "Epoch [6380/10000], Loss: 0.2551\n",
      "Epoch [6390/10000], Loss: 0.2494\n",
      "Epoch [6400/10000], Loss: 0.2438\n",
      "Epoch [6410/10000], Loss: 0.2384\n",
      "Epoch [6420/10000], Loss: 0.2333\n",
      "Epoch [6430/10000], Loss: 0.2283\n",
      "Epoch [6440/10000], Loss: 0.2235\n",
      "Epoch [6450/10000], Loss: 0.2190\n",
      "Epoch [6460/10000], Loss: 0.2146\n",
      "Epoch [6470/10000], Loss: 0.2103\n",
      "Epoch [6480/10000], Loss: 0.2062\n",
      "Epoch [6490/10000], Loss: 0.2023\n",
      "Epoch [6500/10000], Loss: 0.1986\n",
      "Epoch [6510/10000], Loss: 0.1949\n",
      "Epoch [6520/10000], Loss: 0.1914\n",
      "Epoch [6530/10000], Loss: 0.1879\n",
      "Epoch [6540/10000], Loss: 0.1846\n",
      "Epoch [6550/10000], Loss: 0.1814\n",
      "Epoch [6560/10000], Loss: 0.1783\n",
      "Epoch [6570/10000], Loss: 0.1753\n",
      "Epoch [6580/10000], Loss: 0.1723\n",
      "Epoch [6590/10000], Loss: 0.1695\n",
      "Epoch [6600/10000], Loss: 0.1667\n",
      "Epoch [6610/10000], Loss: 0.1641\n",
      "Epoch [6620/10000], Loss: 0.1616\n",
      "Epoch [6630/10000], Loss: 0.1593\n",
      "Epoch [6640/10000], Loss: 0.1570\n",
      "Epoch [6650/10000], Loss: 0.1548\n",
      "Epoch [6660/10000], Loss: 0.1526\n",
      "Epoch [6670/10000], Loss: 0.1506\n",
      "Epoch [6680/10000], Loss: 0.1486\n",
      "Epoch [6690/10000], Loss: 0.1466\n",
      "Epoch [6700/10000], Loss: 0.1448\n",
      "Epoch [6710/10000], Loss: 0.1430\n",
      "Epoch [6720/10000], Loss: 0.1412\n",
      "Epoch [6730/10000], Loss: 0.1395\n",
      "Epoch [6740/10000], Loss: 0.1378\n",
      "Epoch [6750/10000], Loss: 0.1362\n",
      "Epoch [6760/10000], Loss: 0.1346\n",
      "Epoch [6770/10000], Loss: 0.1331\n",
      "Epoch [6780/10000], Loss: 0.1317\n",
      "Epoch [6790/10000], Loss: 0.1303\n",
      "Epoch [6800/10000], Loss: 0.1289\n",
      "Epoch [6810/10000], Loss: 0.1277\n",
      "Epoch [6820/10000], Loss: 0.1265\n",
      "Epoch [6830/10000], Loss: 0.1253\n",
      "Epoch [6840/10000], Loss: 0.1242\n",
      "Epoch [6850/10000], Loss: 0.1231\n",
      "Epoch [6860/10000], Loss: 0.1221\n",
      "Epoch [6870/10000], Loss: 0.1211\n",
      "Epoch [6880/10000], Loss: 0.1201\n",
      "Epoch [6890/10000], Loss: 0.1191\n",
      "Epoch [6900/10000], Loss: 0.1182\n",
      "Epoch [6910/10000], Loss: 0.1173\n",
      "Epoch [6920/10000], Loss: 0.1163\n",
      "Epoch [6930/10000], Loss: 0.1154\n",
      "Epoch [6940/10000], Loss: 0.1145\n",
      "Epoch [6950/10000], Loss: 0.1137\n",
      "Epoch [6960/10000], Loss: 0.1128\n",
      "Epoch [6970/10000], Loss: 0.1119\n",
      "Epoch [6980/10000], Loss: 0.1111\n",
      "Epoch [6990/10000], Loss: 0.1103\n",
      "Epoch [7000/10000], Loss: 0.1095\n",
      "Epoch [7010/10000], Loss: 0.1087\n",
      "Epoch [7020/10000], Loss: 0.1080\n",
      "Epoch [7030/10000], Loss: 0.1073\n",
      "Epoch [7040/10000], Loss: 0.1066\n",
      "Epoch [7050/10000], Loss: 0.1151\n",
      "Epoch [7060/10000], Loss: 35.2047\n",
      "Epoch [7070/10000], Loss: 1.6191\n",
      "Epoch [7080/10000], Loss: 0.4143\n",
      "Epoch [7090/10000], Loss: 0.3921\n",
      "Epoch [7100/10000], Loss: 0.3710\n",
      "Epoch [7110/10000], Loss: 0.3511\n",
      "Epoch [7120/10000], Loss: 0.3323\n",
      "Epoch [7130/10000], Loss: 0.3147\n",
      "Epoch [7140/10000], Loss: 0.2981\n",
      "Epoch [7150/10000], Loss: 0.2827\n",
      "Epoch [7160/10000], Loss: 0.2684\n",
      "Epoch [7170/10000], Loss: 0.2551\n",
      "Epoch [7180/10000], Loss: 0.2426\n",
      "Epoch [7190/10000], Loss: 0.2311\n",
      "Epoch [7200/10000], Loss: 0.2203\n",
      "Epoch [7210/10000], Loss: 0.2104\n",
      "Epoch [7220/10000], Loss: 0.2012\n",
      "Epoch [7230/10000], Loss: 0.1928\n",
      "Epoch [7240/10000], Loss: 0.1851\n",
      "Epoch [7250/10000], Loss: 0.1779\n",
      "Epoch [7260/10000], Loss: 0.1715\n",
      "Epoch [7270/10000], Loss: 0.1656\n",
      "Epoch [7280/10000], Loss: 0.1602\n",
      "Epoch [7290/10000], Loss: 0.1553\n",
      "Epoch [7300/10000], Loss: 0.1508\n",
      "Epoch [7310/10000], Loss: 0.1467\n",
      "Epoch [7320/10000], Loss: 0.1430\n",
      "Epoch [7330/10000], Loss: 0.1396\n",
      "Epoch [7340/10000], Loss: 0.1364\n",
      "Epoch [7350/10000], Loss: 0.1335\n",
      "Epoch [7360/10000], Loss: 0.1308\n",
      "Epoch [7370/10000], Loss: 0.1284\n",
      "Epoch [7380/10000], Loss: 0.1262\n",
      "Epoch [7390/10000], Loss: 0.1241\n",
      "Epoch [7400/10000], Loss: 0.1223\n",
      "Epoch [7410/10000], Loss: 0.1206\n",
      "Epoch [7420/10000], Loss: 0.1190\n",
      "Epoch [7430/10000], Loss: 0.1175\n",
      "Epoch [7440/10000], Loss: 0.1162\n",
      "Epoch [7450/10000], Loss: 0.1150\n",
      "Epoch [7460/10000], Loss: 0.1139\n",
      "Epoch [7470/10000], Loss: 0.1129\n",
      "Epoch [7480/10000], Loss: 0.1119\n",
      "Epoch [7490/10000], Loss: 0.1110\n",
      "Epoch [7500/10000], Loss: 0.1101\n",
      "Epoch [7510/10000], Loss: 0.1093\n",
      "Epoch [7520/10000], Loss: 0.1086\n",
      "Epoch [7530/10000], Loss: 0.1078\n",
      "Epoch [7540/10000], Loss: 0.1070\n",
      "Epoch [7550/10000], Loss: 0.1063\n",
      "Epoch [7560/10000], Loss: 0.1058\n",
      "Epoch [7570/10000], Loss: 28.6052\n",
      "Epoch [7580/10000], Loss: 13.4825\n",
      "Epoch [7590/10000], Loss: 72.6734\n",
      "Epoch [7600/10000], Loss: 75.9092\n",
      "Epoch [7610/10000], Loss: 76.4251\n",
      "Epoch [7620/10000], Loss: 52.8286\n",
      "Epoch [7630/10000], Loss: 0.8993\n",
      "Epoch [7640/10000], Loss: 0.8753\n",
      "Epoch [7650/10000], Loss: 0.8519\n",
      "Epoch [7660/10000], Loss: 0.8291\n",
      "Epoch [7670/10000], Loss: 0.8069\n",
      "Epoch [7680/10000], Loss: 0.7852\n",
      "Epoch [7690/10000], Loss: 0.7640\n",
      "Epoch [7700/10000], Loss: 0.7434\n",
      "Epoch [7710/10000], Loss: 0.7232\n",
      "Epoch [7720/10000], Loss: 0.7035\n",
      "Epoch [7730/10000], Loss: 0.6843\n",
      "Epoch [7740/10000], Loss: 0.6655\n",
      "Epoch [7750/10000], Loss: 0.6473\n",
      "Epoch [7760/10000], Loss: 0.6296\n",
      "Epoch [7770/10000], Loss: 0.6124\n",
      "Epoch [7780/10000], Loss: 0.5956\n",
      "Epoch [7790/10000], Loss: 0.5793\n",
      "Epoch [7800/10000], Loss: 0.5635\n",
      "Epoch [7810/10000], Loss: 0.5482\n",
      "Epoch [7820/10000], Loss: 0.5334\n",
      "Epoch [7830/10000], Loss: 0.5190\n",
      "Epoch [7840/10000], Loss: 0.5051\n",
      "Epoch [7850/10000], Loss: 0.4916\n",
      "Epoch [7860/10000], Loss: 0.4785\n",
      "Epoch [7870/10000], Loss: 0.4659\n",
      "Epoch [7880/10000], Loss: 0.4536\n",
      "Epoch [7890/10000], Loss: 0.4416\n",
      "Epoch [7900/10000], Loss: 0.4301\n",
      "Epoch [7910/10000], Loss: 0.4189\n",
      "Epoch [7920/10000], Loss: 0.4080\n",
      "Epoch [7930/10000], Loss: 0.3975\n",
      "Epoch [7940/10000], Loss: 0.3872\n",
      "Epoch [7950/10000], Loss: 0.3773\n",
      "Epoch [7960/10000], Loss: 0.3677\n",
      "Epoch [7970/10000], Loss: 0.3584\n",
      "Epoch [7980/10000], Loss: 0.3494\n",
      "Epoch [7990/10000], Loss: 0.3406\n",
      "Epoch [8000/10000], Loss: 0.3322\n",
      "Epoch [8010/10000], Loss: 0.3240\n",
      "Epoch [8020/10000], Loss: 0.3160\n",
      "Epoch [8030/10000], Loss: 0.3084\n",
      "Epoch [8040/10000], Loss: 0.3011\n",
      "Epoch [8050/10000], Loss: 0.2940\n",
      "Epoch [8060/10000], Loss: 0.2871\n",
      "Epoch [8070/10000], Loss: 0.2805\n",
      "Epoch [8080/10000], Loss: 0.2740\n",
      "Epoch [8090/10000], Loss: 0.2678\n",
      "Epoch [8100/10000], Loss: 0.2617\n",
      "Epoch [8110/10000], Loss: 0.2558\n",
      "Epoch [8120/10000], Loss: 0.2502\n",
      "Epoch [8130/10000], Loss: 0.2447\n",
      "Epoch [8140/10000], Loss: 0.2394\n",
      "Epoch [8150/10000], Loss: 0.2343\n",
      "Epoch [8160/10000], Loss: 0.2294\n",
      "Epoch [8170/10000], Loss: 0.2248\n",
      "Epoch [8180/10000], Loss: 0.2202\n",
      "Epoch [8190/10000], Loss: 0.2159\n",
      "Epoch [8200/10000], Loss: 0.2117\n",
      "Epoch [8210/10000], Loss: 0.2077\n",
      "Epoch [8220/10000], Loss: 0.2038\n",
      "Epoch [8230/10000], Loss: 0.2001\n",
      "Epoch [8240/10000], Loss: 0.1964\n",
      "Epoch [8250/10000], Loss: 0.1929\n",
      "Epoch [8260/10000], Loss: 0.1895\n",
      "Epoch [8270/10000], Loss: 0.1862\n",
      "Epoch [8280/10000], Loss: 0.1829\n",
      "Epoch [8290/10000], Loss: 0.1798\n",
      "Epoch [8300/10000], Loss: 0.1768\n",
      "Epoch [8310/10000], Loss: 0.1739\n",
      "Epoch [8320/10000], Loss: 0.1710\n",
      "Epoch [8330/10000], Loss: 0.1683\n",
      "Epoch [8340/10000], Loss: 0.1656\n",
      "Epoch [8350/10000], Loss: 0.1631\n",
      "Epoch [8360/10000], Loss: 0.1607\n",
      "Epoch [8370/10000], Loss: 0.1583\n",
      "Epoch [8380/10000], Loss: 0.1561\n",
      "Epoch [8390/10000], Loss: 0.1540\n",
      "Epoch [8400/10000], Loss: 0.1519\n",
      "Epoch [8410/10000], Loss: 0.1498\n",
      "Epoch [8420/10000], Loss: 0.1479\n",
      "Epoch [8430/10000], Loss: 0.1460\n",
      "Epoch [8440/10000], Loss: 0.1441\n",
      "Epoch [8450/10000], Loss: 0.1423\n",
      "Epoch [8460/10000], Loss: 0.1406\n",
      "Epoch [8470/10000], Loss: 0.1389\n",
      "Epoch [8480/10000], Loss: 0.1373\n",
      "Epoch [8490/10000], Loss: 0.1357\n",
      "Epoch [8500/10000], Loss: 0.1341\n",
      "Epoch [8510/10000], Loss: 0.1326\n",
      "Epoch [8520/10000], Loss: 0.1312\n",
      "Epoch [8530/10000], Loss: 0.1299\n",
      "Epoch [8540/10000], Loss: 0.1286\n",
      "Epoch [8550/10000], Loss: 0.1273\n",
      "Epoch [8560/10000], Loss: 0.1261\n",
      "Epoch [8570/10000], Loss: 0.1250\n",
      "Epoch [8580/10000], Loss: 0.1239\n",
      "Epoch [8590/10000], Loss: 0.1228\n",
      "Epoch [8600/10000], Loss: 0.1218\n",
      "Epoch [8610/10000], Loss: 0.1208\n",
      "Epoch [8620/10000], Loss: 0.1198\n",
      "Epoch [8630/10000], Loss: 0.1189\n",
      "Epoch [8640/10000], Loss: 0.1180\n",
      "Epoch [8650/10000], Loss: 0.1170\n",
      "Epoch [8660/10000], Loss: 0.1162\n",
      "Epoch [8670/10000], Loss: 0.1153\n",
      "Epoch [8680/10000], Loss: 0.1145\n",
      "Epoch [8690/10000], Loss: 0.1136\n",
      "Epoch [8700/10000], Loss: 0.1128\n",
      "Epoch [8710/10000], Loss: 0.1120\n",
      "Epoch [8720/10000], Loss: 0.1113\n",
      "Epoch [8730/10000], Loss: 0.1105\n",
      "Epoch [8740/10000], Loss: 0.1098\n",
      "Epoch [8750/10000], Loss: 0.1090\n",
      "Epoch [8760/10000], Loss: 0.1083\n",
      "Epoch [8770/10000], Loss: 0.1077\n",
      "Epoch [8780/10000], Loss: 0.1089\n",
      "Epoch [8790/10000], Loss: 7.2393\n",
      "Epoch [8800/10000], Loss: 40.3065\n",
      "Epoch [8810/10000], Loss: 18.2202\n",
      "Epoch [8820/10000], Loss: 0.5673\n",
      "Epoch [8830/10000], Loss: 0.5441\n",
      "Epoch [8840/10000], Loss: 0.5217\n",
      "Epoch [8850/10000], Loss: 0.5002\n",
      "Epoch [8860/10000], Loss: 0.4795\n",
      "Epoch [8870/10000], Loss: 0.4597\n",
      "Epoch [8880/10000], Loss: 0.4407\n",
      "Epoch [8890/10000], Loss: 0.4226\n",
      "Epoch [8900/10000], Loss: 0.4052\n",
      "Epoch [8910/10000], Loss: 0.3886\n",
      "Epoch [8920/10000], Loss: 0.3729\n",
      "Epoch [8930/10000], Loss: 0.3579\n",
      "Epoch [8940/10000], Loss: 0.3437\n",
      "Epoch [8950/10000], Loss: 0.3302\n",
      "Epoch [8960/10000], Loss: 0.3172\n",
      "Epoch [8970/10000], Loss: 0.3049\n",
      "Epoch [8980/10000], Loss: 0.2933\n",
      "Epoch [8990/10000], Loss: 0.2823\n",
      "Epoch [9000/10000], Loss: 0.2718\n",
      "Epoch [9010/10000], Loss: 0.2619\n",
      "Epoch [9020/10000], Loss: 0.2525\n",
      "Epoch [9030/10000], Loss: 0.2437\n",
      "Epoch [9040/10000], Loss: 0.2353\n",
      "Epoch [9050/10000], Loss: 0.2274\n",
      "Epoch [9060/10000], Loss: 0.2200\n",
      "Epoch [9070/10000], Loss: 0.2130\n",
      "Epoch [9080/10000], Loss: 0.2064\n",
      "Epoch [9090/10000], Loss: 0.2002\n",
      "Epoch [9100/10000], Loss: 0.1943\n",
      "Epoch [9110/10000], Loss: 0.1888\n",
      "Epoch [9120/10000], Loss: 0.1836\n",
      "Epoch [9130/10000], Loss: 0.1787\n",
      "Epoch [9140/10000], Loss: 0.1741\n",
      "Epoch [9150/10000], Loss: 0.1698\n",
      "Epoch [9160/10000], Loss: 0.1658\n",
      "Epoch [9170/10000], Loss: 0.1620\n",
      "Epoch [9180/10000], Loss: 0.1584\n",
      "Epoch [9190/10000], Loss: 0.1550\n",
      "Epoch [9200/10000], Loss: 0.1518\n",
      "Epoch [9210/10000], Loss: 0.1488\n",
      "Epoch [9220/10000], Loss: 0.1459\n",
      "Epoch [9230/10000], Loss: 0.1432\n",
      "Epoch [9240/10000], Loss: 0.1406\n",
      "Epoch [9250/10000], Loss: 0.1383\n",
      "Epoch [9260/10000], Loss: 0.1361\n",
      "Epoch [9270/10000], Loss: 0.1340\n",
      "Epoch [9280/10000], Loss: 0.1320\n",
      "Epoch [9290/10000], Loss: 0.1302\n",
      "Epoch [9300/10000], Loss: 0.1284\n",
      "Epoch [9310/10000], Loss: 0.1268\n",
      "Epoch [9320/10000], Loss: 0.1252\n",
      "Epoch [9330/10000], Loss: 0.1237\n",
      "Epoch [9340/10000], Loss: 0.1223\n",
      "Epoch [9350/10000], Loss: 0.1211\n",
      "Epoch [9360/10000], Loss: 0.1198\n",
      "Epoch [9370/10000], Loss: 0.1187\n",
      "Epoch [9380/10000], Loss: 0.1176\n",
      "Epoch [9390/10000], Loss: 0.1166\n",
      "Epoch [9400/10000], Loss: 0.1156\n",
      "Epoch [9410/10000], Loss: 0.1146\n",
      "Epoch [9420/10000], Loss: 0.1137\n",
      "Epoch [9430/10000], Loss: 0.1129\n",
      "Epoch [9440/10000], Loss: 0.1121\n",
      "Epoch [9450/10000], Loss: 0.1113\n",
      "Epoch [9460/10000], Loss: 0.1105\n",
      "Epoch [9470/10000], Loss: 0.1097\n",
      "Epoch [9480/10000], Loss: 0.1090\n",
      "Epoch [9490/10000], Loss: 0.1083\n",
      "Epoch [9500/10000], Loss: 0.1077\n",
      "Epoch [9510/10000], Loss: 0.1073\n",
      "Epoch [9520/10000], Loss: 3.5008\n",
      "Epoch [9530/10000], Loss: 35.6684\n",
      "Epoch [9540/10000], Loss: 0.7481\n",
      "Epoch [9550/10000], Loss: 0.5134\n",
      "Epoch [9560/10000], Loss: 0.4903\n",
      "Epoch [9570/10000], Loss: 0.4681\n",
      "Epoch [9580/10000], Loss: 0.4469\n",
      "Epoch [9590/10000], Loss: 0.4266\n",
      "Epoch [9600/10000], Loss: 0.4073\n",
      "Epoch [9610/10000], Loss: 0.3888\n",
      "Epoch [9620/10000], Loss: 0.3713\n",
      "Epoch [9630/10000], Loss: 0.3546\n",
      "Epoch [9640/10000], Loss: 0.3389\n",
      "Epoch [9650/10000], Loss: 0.3241\n",
      "Epoch [9660/10000], Loss: 0.3102\n",
      "Epoch [9670/10000], Loss: 0.2969\n",
      "Epoch [9680/10000], Loss: 0.2844\n",
      "Epoch [9690/10000], Loss: 0.2726\n",
      "Epoch [9700/10000], Loss: 0.2615\n",
      "Epoch [9710/10000], Loss: 0.2510\n",
      "Epoch [9720/10000], Loss: 0.2411\n",
      "Epoch [9730/10000], Loss: 0.2319\n",
      "Epoch [9740/10000], Loss: 0.2232\n",
      "Epoch [9750/10000], Loss: 0.2151\n",
      "Epoch [9760/10000], Loss: 0.2076\n",
      "Epoch [9770/10000], Loss: 0.2005\n",
      "Epoch [9780/10000], Loss: 0.1939\n",
      "Epoch [9790/10000], Loss: 0.1878\n",
      "Epoch [9800/10000], Loss: 0.1820\n",
      "Epoch [9810/10000], Loss: 0.1766\n",
      "Epoch [9820/10000], Loss: 0.1716\n",
      "Epoch [9830/10000], Loss: 0.1669\n",
      "Epoch [9840/10000], Loss: 0.1626\n",
      "Epoch [9850/10000], Loss: 0.1585\n",
      "Epoch [9860/10000], Loss: 0.1547\n",
      "Epoch [9870/10000], Loss: 0.1512\n",
      "Epoch [9880/10000], Loss: 0.1479\n",
      "Epoch [9890/10000], Loss: 0.1448\n",
      "Epoch [9900/10000], Loss: 0.1419\n",
      "Epoch [9910/10000], Loss: 0.1391\n",
      "Epoch [9920/10000], Loss: 0.1366\n",
      "Epoch [9930/10000], Loss: 0.1343\n",
      "Epoch [9940/10000], Loss: 0.1320\n",
      "Epoch [9950/10000], Loss: 0.1300\n",
      "Epoch [9960/10000], Loss: 0.1281\n",
      "Epoch [9970/10000], Loss: 0.1263\n",
      "Epoch [9980/10000], Loss: 0.1247\n",
      "Epoch [9990/10000], Loss: 0.1231\n",
      "Epoch [10000/10000], Loss: 0.1216\n",
      "Validation Accuracy: 0.50\n",
      "Best Validation Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(X_tensor)):\n",
    "    print(f\"Fold {fold+1}/{n_folds}\")\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X_tensor[train_ids], X_tensor[val_ids]\n",
    "    y_train, y_val = y_tensor[train_ids], y_tensor[val_ids]\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = SoftmaxRegression(input_dim, output_dim)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = ElasticNetLoss(model, alpha=0.01, l1_ratio=0.5)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_outputs = model(X_val)\n",
    "        _, y_pred_tensor = torch.max(val_outputs, 1)\n",
    "        y_pred = y_pred_tensor.numpy()\n",
    "        y_true = y_val.numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        # If this model is better than the previous best, update the best model and accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "\n",
    "# Save the best model\n",
    "# torch.save(best_model.state_dict(), \"softmax_classifier_best.pth\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train: ['aMS1', 'aMS3', 'aMS4', 'aMS5', 'sMS2', 'sMS5'], Test: ['aMS2', 'sMS1', 'sMS4']\n",
      "--------------------\n",
      "Fold 2\n",
      "Train: ['aMS2', 'aMS3', 'aMS4', 'aMS5', 'sMS1', 'sMS2', 'sMS4'], Test: ['aMS1', 'sMS5']\n",
      "--------------------\n",
      "Fold 3\n",
      "Train: ['aMS1', 'aMS2', 'aMS4', 'sMS1', 'sMS2', 'sMS4', 'sMS5'], Test: ['aMS3', 'aMS5']\n",
      "--------------------\n",
      "Fold 4\n",
      "Train: ['aMS1', 'aMS2', 'aMS3', 'aMS5', 'sMS1', 'sMS4', 'sMS5'], Test: ['aMS4', 'sMS2']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Use split to generate indices for each fold\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(y_tensor)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(\n",
    "        f\"Train: {list(df.columns[train_index])}, Test: {list(df.columns[test_index])}\"\n",
    "    )\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.3.1-cuda12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
